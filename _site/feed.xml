<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-07-04T06:00:45+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Data Perspectives</title><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><entry><title type="html">Fitting complex models</title><link href="http://localhost:4000/statistics/complex_models" rel="alternate" type="text/html" title="Fitting complex models" /><published>2026-04-03T00:00:00+00:00</published><updated>2026-04-03T00:00:00+00:00</updated><id>http://localhost:4000/statistics/complex_models</id><content type="html" xml:base="http://localhost:4000/statistics/complex_models"><![CDATA[<p>The aim of this post is a little bit different from all the previous
posts, and it’s to illustrate how we can use PyMC to fit complex models.
To do so, we will use the Diebold-Li model, which is a model commonly
used in finance to fit the yield of bonds and other fixed income securities.
A bond is characterized by its duration, which usually goes from one
month to 30 years, and they are sold on a regular basis.
The US federal bank provides the daily values of all the US treasure bonds,
and our aim is to fit these curves.
The dataset can be obtained from
<a href="https://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve&amp;field_tdr_date_value=2025">this link</a>.</p>]]></content><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><category term="/statistics/" /><category term="/complex/" /><summary type="html"><![CDATA[When the going gets tough]]></summary></entry><entry><title type="html">Directional statistics</title><link href="http://localhost:4000/statistics/directional" rel="alternate" type="text/html" title="Directional statistics" /><published>2026-03-27T00:00:00+00:00</published><updated>2026-03-27T00:00:00+00:00</updated><id>http://localhost:4000/statistics/directional</id><content type="html" xml:base="http://localhost:4000/statistics/directional"><![CDATA[<p>If you are familiar with this blog, you already know that
we strongly believe that a model should encode
all the relevant features of the data.</p>

<p>A special kind of variable we haven’t discussed up to now is
the family of angular variables, that is variables which are 
defined on non-planar topologies.</p>

<p>This kind of variable is very common in contexts like
movement analysis or spatial analysis, so we will dedicate them a post.</p>

<p>As usual, we only want to give an overview to the topic,
and the interested reader will find some literature at the end of the post.</p>

<h2 id="wind-direction-analysis">Wind direction analysis</h2>

<p>Let us consider the dataset provided in
<a href="https://energydata.info/dataset/maldives-wind-measurement-data">this website</a>
where a large set of variables is provided to analyze the wind
speed in a meteorological station at the Maldives.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'wind-measurements_maldives_hoarafushi_wb-esmap-qc.csv'</span><span class="p">)</span>

<span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<div class="code">
103884
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[[</span><span class="s">'time'</span><span class="p">,</span> <span class="s">'a11_wind_speed_mean'</span><span class="p">,</span> <span class="s">'d11_wind_direction_mean'</span><span class="p">]].</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">time</th>
      <th style="text-align: right">a11_wind_speed_mean</th>
      <th style="text-align: right">d11_wind_direction_mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">10/04/2017 14:00</td>
      <td style="text-align: right">9999</td>
      <td style="text-align: right">9999</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">10/04/2017 14:10</td>
      <td style="text-align: right">3.174</td>
      <td style="text-align: right">285.696</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">10/04/2017 14:20</td>
      <td style="text-align: right">2.621</td>
      <td style="text-align: right">296.953</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">10/04/2017 14:30</td>
      <td style="text-align: right">2.697</td>
      <td style="text-align: right">288.454</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">10/04/2017 14:40</td>
      <td style="text-align: right">9999</td>
      <td style="text-align: right">9999</td>
    </tr>
  </tbody>
</table>

<p>Let us first of all clean a little bit the dataset</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_red</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'a11_wind_speed_mean'</span><span class="p">]</span><span class="o">&lt;</span><span class="mi">9990</span><span class="p">].</span><span class="n">copy</span><span class="p">()</span>
<span class="n">df_red</span><span class="p">[</span><span class="s">'time'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df_red</span><span class="p">[</span><span class="s">'time'</span><span class="p">],</span> <span class="nb">format</span><span class="o">=</span><span class="s">'%d/%m/%Y %H:%M'</span><span class="p">)</span>
<span class="n">df_red</span><span class="p">[</span><span class="s">'direction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_red</span><span class="p">[</span><span class="s">'d11_wind_direction_mean'</span><span class="p">]</span><span class="o">/</span><span class="mi">360</span><span class="o">*</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span>
</code></pre></div></div>

<p>The dataset has a time frequency of 10 minutes, which is way too much
for our purposes.
We therefore want to average over the day, and the first obvious choice
would be to take the arithmetic mean.
This is however not the best choice, since is this way we wouldn’t take
the circular topology into account.
A proper statistics should in fact remain unchanged by replacing
each angle with the same angle plus $2 \pi$,
and the arithmetic mean does not have this property.
A better approach is to switch to cartesian coordinates,
average over the single components and only then
re-compute the angle.
An alternative approach could be to use the <a href="https://en.wikipedia.org/wiki/Circular_mean">circular mean</a>,
which is the same approach just described performed assuming that
the wind absolute value of the speed is always one.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_red</span><span class="p">[</span><span class="s">'cos'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'a11_wind_speed_mean'</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">df_red</span><span class="p">[</span><span class="s">'direction'</span><span class="p">])</span>
<span class="n">df_red</span><span class="p">[</span><span class="s">'sin'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'a11_wind_speed_mean'</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">df_red</span><span class="p">[</span><span class="s">'direction'</span><span class="p">])</span>

<span class="n">df_red</span><span class="p">[</span><span class="s">'Date'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df_red</span><span class="p">[</span><span class="s">'time'</span><span class="p">])</span> <span class="o">-</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_timedelta</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s">'d'</span><span class="p">)</span>
<span class="n">df_g</span> <span class="o">=</span> <span class="n">df_red</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'Date'</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s">'W-MON'</span><span class="p">))[[</span><span class="s">'cos'</span><span class="p">,</span> <span class="s">'sin'</span><span class="p">]].</span><span class="n">mean</span><span class="p">().</span><span class="n">reset_index</span><span class="p">().</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Date'</span><span class="p">)</span>
<span class="n">df_g</span><span class="p">[</span><span class="s">'phi'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">df_g</span><span class="p">[</span><span class="s">'sin'</span><span class="p">],</span> <span class="n">df_g</span><span class="p">[</span><span class="s">'cos'</span><span class="p">])</span>
</code></pre></div></div>

<p>We can now visualize the result as follows</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">subplot_kw</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s">'polar'</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">df_g</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'phi'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">''</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">''</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/directional/windhist.webp" alt="" /></p>

<p>We can now try and build our model, and we must account for the
non-trivial topology of our data here as we just did for the mean.
A common choice in this case is the <a href="https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.VonMises.html">Von Mises</a>
distribution, which continuous and periodic over the entire circle.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'mu'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'kappa'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">VonMises</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="n">kappa</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df_g</span><span class="p">[</span><span class="s">'phi'</span><span class="p">])</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
             <span class="n">draws</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span>
             <span class="n">tune</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span>
              <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
             <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
             <span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">)</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
   
<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/directional/trace_vm.webp" alt="" /></p>

<p>The trace looks good, let us now inspect the posterior predictive</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">subplot_kw</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s">'polar'</span><span class="p">))</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">num_pp_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/directional/pp_vm.webp" alt="" /></p>

<p>Our dataset is not appropriately described by a simple Von Mises model,
and this can be easily understood by the multi modality of the data.
It is in fact well known that the oceanic winds have a strong seasonal
component, and this can be seen by the fact that the above histogram
has a strong south component as well as a broader north-east one.</p>

<p>We don’t want to fix a priori the number of components, so we will
use a DP mixture model.
Von-Mises mixture has however an identifiability issue,
since they are periodic over the circle.
We will try and circumvent this issue by imposing that the variance
is strictly growing with the component index.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">K</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s">"component"</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">K</span><span class="p">),</span> <span class="s">"obs_id"</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_by_day</span><span class="p">))})</span> <span class="k">as</span> <span class="n">model_dp</span><span class="p">:</span>
    <span class="n">alpha_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s">"alpha_c"</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">w_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">StickBreakingWeights</span><span class="p">(</span><span class="s">'w_c'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_c</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">lam_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s">"lam_c"</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">))</span>
    <span class="n">mu_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">TruncatedNormal</span><span class="p">(</span><span class="s">"mu_c"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">),</span> <span class="n">lower</span><span class="o">=-</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span>
    <span class="n">z_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s">'z_c'</span><span class="p">,</span> <span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">lam_c</span><span class="p">))</span>
    <span class="n">y_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Mixture</span><span class="p">(</span>
        <span class="s">"y_c"</span><span class="p">,</span> <span class="n">w_c</span><span class="p">,</span> <span class="n">pm</span><span class="p">.</span><span class="n">VonMises</span><span class="p">.</span><span class="n">dist</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="n">mu_c</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="n">z_c</span><span class="p">),</span> <span class="n">observed</span><span class="o">=</span><span class="n">df_g</span><span class="p">[</span><span class="s">'phi'</span><span class="p">])</span>

<span class="k">with</span> <span class="n">model_dp</span><span class="p">:</span>
    <span class="n">idata_dp</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_dp</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'alpha_c'</span><span class="p">,</span> <span class="s">'mu_c'</span><span class="p">,</span> <span class="s">'lam_c'</span><span class="p">])</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/directional/trace_dp.webp" alt="" /></p>

<p>We still have some issue, but this is not a great problem for us.
Let us now inspect the posterior predictive.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model_dp</span><span class="p">:</span>
    <span class="n">idata_dp</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata_dp</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">subplot_kw</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s">'polar'</span><span class="p">))</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">idata_dp</span><span class="p">,</span> <span class="n">num_pp_samples</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/directional/pp_dp.webp" alt="" /></p>

<p>The improvement in the description of the data is clear,
and again a simple model constructed by only encoding some
relevant domain knowledge has shown appropriate in the description
of the data.</p>

<p>Let us finally inspect the parameters</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">idata_dp</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'w_c'</span><span class="p">],</span> <span class="n">combined</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">idata_dp</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'mu_c'</span><span class="p">],</span> <span class="n">combined</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">idata_dp</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'z_c'</span><span class="p">],</span> <span class="n">combined</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'w_c'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'mu_c'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'z_c'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="sa">f</span><span class="s">"[</span><span class="si">{</span><span class="n">elem</span><span class="si">}</span><span class="s">]"</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)][::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">r</span><span class="s">'94.0% HDI'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/directional/forest_dp.webp" alt="" /></p>

<h2 id="gp-regression">GP regression</h2>

<p>We can also easily perform regression on directional data. We already know
(or, at least, believe) that our data has a yearly periodic behavior,
and we can encode this feature in the regression model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_g</span><span class="p">[</span><span class="s">'X'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_g</span><span class="p">[</span><span class="s">'Date'</span><span class="p">]</span><span class="o">-</span><span class="n">df_g</span><span class="p">[</span><span class="s">'Date'</span><span class="p">].</span><span class="nb">min</span><span class="p">()).</span><span class="n">dt</span><span class="p">.</span><span class="n">days</span><span class="o">/</span><span class="mi">365</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_gp</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Data</span><span class="p">(</span><span class="s">'X'</span><span class="p">,</span> <span class="n">df_g</span><span class="p">[</span><span class="s">'X'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="c1"># mu = pm.Normal('mu', mu=0, sigma=10)
</span>    <span class="n">scale</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">"scale"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">cov_func</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">gp</span><span class="p">.</span><span class="n">cov</span><span class="p">.</span><span class="n">Periodic</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">period</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="c1"># Specify the approximation with 25 basis vectors
</span>    <span class="n">gp</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">gp</span><span class="p">.</span><span class="n">HSGPPeriodic</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">cov_func</span><span class="o">=</span><span class="n">cov_func</span><span class="p">)</span>

    <span class="c1"># Place a GP prior over the function f.
</span>    <span class="n">mu</span> <span class="o">=</span> <span class="n">gp</span><span class="p">.</span><span class="n">prior</span><span class="p">(</span><span class="s">"mu"</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'kappa'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">VonMises</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="n">kappa</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df_g</span><span class="p">[</span><span class="s">'phi'</span><span class="p">])</span>

<span class="k">with</span> <span class="n">model_gp</span><span class="p">:</span>
    <span class="n">idata_gp</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    
<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_gp</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/directional/trace_gp.webp" alt="" /></p>

<p>The trace does not show any relevant issue, so we can take a look at our fit.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_g</span><span class="p">[</span><span class="s">'X'</span><span class="p">],</span> <span class="n">df_g</span><span class="p">[</span><span class="s">'phi'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'x'</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_hdi</span><span class="p">(</span><span class="n">df_g</span><span class="p">[</span><span class="s">'X'</span><span class="p">],</span> <span class="n">idata_gp</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'mu'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">df_g</span><span class="p">[</span><span class="s">'X'</span><span class="p">].</span><span class="nb">max</span><span class="p">()])</span>
<span class="n">xticks</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">get_xticks</span><span class="p">()</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">df_g</span><span class="p">.</span><span class="n">iloc</span><span class="p">[[</span><span class="n">np</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">df_g</span><span class="p">[</span><span class="s">'X'</span><span class="p">].</span><span class="n">values</span><span class="o">-</span><span class="n">elem</span><span class="p">))</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">xticks</span><span class="p">]][</span><span class="s">'Date'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">strftime</span><span class="p">(</span><span class="s">'%Y-%m-%d'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/directional/pp_gp.webp" alt="" /></p>

<h2 id="conclusions">Conclusions</h2>

<p>We have seen an easy way to fit circular quantities in PyMC by using
the Von Mises distribution, as well as how to encode periodicity
in a regression problem by using the Hilbert Space Periodic GP.</p>

<h2 id="suggested-readings">Suggested readings</h2>
<ul>
  <li><cite>Ley, C., Verdebout, T. (2017). Modern Directional Statistics. Stati Uniti: CRC Press.</cite></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span>
</code></pre></div></div>

<div class="code">
Last updated: Fri May 02 2025
<br />
<br />Python implementation: CPython
<br />Python version       : 3.12.8
<br />IPython version      : 8.31.0
<br />
<br />xarray : 2025.1.1
<br />numpyro: 0.16.1
<br />
<br />numpy     : 2.2.5
<br />matplotlib: 3.10.1
<br />pymc      : 5.22.0
<br />seaborn   : 0.13.2
<br />arviz     : 0.21.0
<br />pandas    : 2.2.3
<br />
<br />Watermark: 2.5.0
</div>]]></content><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><category term="/statistics/" /><category term="/horseshoe/" /><summary type="html"><![CDATA[Inference for angular variables]]></summary></entry><entry><title type="html">Horseshoe priors</title><link href="http://localhost:4000/statistics/horseshoe" rel="alternate" type="text/html" title="Horseshoe priors" /><published>2026-03-20T00:00:00+00:00</published><updated>2026-03-20T00:00:00+00:00</updated><id>http://localhost:4000/statistics/horseshoe</id><content type="html" xml:base="http://localhost:4000/statistics/horseshoe"><![CDATA[<p>When you perform multilinear regression with many independent variables,
having highly correlated regressors might have the undesired drawback that 
most of the associated parameters are barely different from zero.
As an example, you might want to find an approximation for some quantity,
and you want to include as fewer regressors as possible, maybe because
measuring each of them requires effort.
Alternatively, if your aim is to assess the impact of some regressor
on your model, the instabilities originated by multi-collinearity
might lead you to drawing wrong conclusions.</p>

<p>In the frequentist framework, this issue is generally solved by adding
regularizing priors, as in the case of LASSO regression.
In the Bayesian one, the natural way to overcome this problem
is by means of an appropriate choice of the priors for the regressors,
and the Bayesian community proposed the family of <strong>sparsifying priors</strong>.
Here we will only discuss the horseshoe prior, but many more have been
proposed, and we will provide some link the topic.</p>

<h2 id="the-body-fat-dataset">The Body Fat dataset</h2>
<p>In this example, we will use the Body Fat dataset,
which is discussed in <a href="https://stat-ata-asu.github.io/PredictiveModelBuilding/BFdata.html">this blog</a>.</p>

<p>The body fat percentage is the mass of the fat of the body
divided by the total mass. This quantity can be accurately estimated
by using some dedicated instrument, which are however time-consuming
and require some knowledge in order to be used.
In order to have a less precise measurement, we can try and estimate
it by relating it to some other quantity which is easier to perform,
such as weight or length measurements.
While it is reasonable to use the body weight, it is however less clear
which length measurement we should use in order to find a good
proxy for the desired quantity.
We could use the total height, but we could also use many more
length measurements, such as the neck circumference or the abdomen one.</p>

<p>A starting point can be to use a multilinear regression in order to
find out which quantity better predicts the body fat percentage.
However, a more robust person will have large values for all
of them, we can therefore expect that our dataset will show a quite
strong multicollinearity.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">df_bf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'http://jse.amstat.org/datasets/fat.dat.txt'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="sa">r</span><span class="s">"\s+"</span><span class="p">)</span>

<span class="n">df_bf</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">"case"</span><span class="p">,</span> <span class="s">"brozek"</span><span class="p">,</span> <span class="s">"siri"</span><span class="p">,</span> 
                                    <span class="s">"density"</span><span class="p">,</span> <span class="s">"age"</span><span class="p">,</span> 
                                    <span class="s">"weight_lbs"</span><span class="p">,</span> 
                                    <span class="s">"height_in"</span><span class="p">,</span> <span class="s">"bmi"</span><span class="p">,</span> 
                                    <span class="s">"fat_free_weight"</span><span class="p">,</span> <span class="s">"neck_cm"</span><span class="p">,</span> 
                                    <span class="s">"chest_cm"</span><span class="p">,</span> <span class="s">"abdomen_cm"</span><span class="p">,</span> 
                                    <span class="s">"hip_cm"</span><span class="p">,</span> <span class="s">"thigh_cm"</span><span class="p">,</span> 
                                    <span class="s">"knee_cm"</span><span class="p">,</span> <span class="s">"ankle_cm"</span><span class="p">,</span> 
                                    <span class="s">"biceps_cm"</span><span class="p">,</span> <span class="s">"forearm_cm"</span><span class="p">,</span>
                                    <span class="s">"wrist_cm"</span><span class="p">]</span>
</code></pre></div></div>

<p>There are at least two formulas to estimate the body fat percentage,
and we will use the “Brozek” formula.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: right">case</th>
      <th style="text-align: right">brozek</th>
      <th style="text-align: right">siri</th>
      <th style="text-align: right">density</th>
      <th style="text-align: right">age</th>
      <th style="text-align: right">weight_lbs</th>
      <th style="text-align: right">height_in</th>
      <th style="text-align: right">bmi</th>
      <th style="text-align: right">fat_free_weight</th>
      <th style="text-align: right">neck_cm</th>
      <th style="text-align: right">chest_cm</th>
      <th style="text-align: right">abdomen_cm</th>
      <th style="text-align: right">hip_cm</th>
      <th style="text-align: right">thigh_cm</th>
      <th style="text-align: right">knee_cm</th>
      <th style="text-align: right">ankle_cm</th>
      <th style="text-align: right">biceps_cm</th>
      <th style="text-align: right">forearm_cm</th>
      <th style="text-align: right">wrist_cm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">12.6</td>
      <td style="text-align: right">12.3</td>
      <td style="text-align: right">1.0708</td>
      <td style="text-align: right">23</td>
      <td style="text-align: right">154.25</td>
      <td style="text-align: right">67.75</td>
      <td style="text-align: right">23.7</td>
      <td style="text-align: right">134.9</td>
      <td style="text-align: right">36.2</td>
      <td style="text-align: right">93.1</td>
      <td style="text-align: right">85.2</td>
      <td style="text-align: right">94.5</td>
      <td style="text-align: right">59</td>
      <td style="text-align: right">37.3</td>
      <td style="text-align: right">21.9</td>
      <td style="text-align: right">32</td>
      <td style="text-align: right">27.4</td>
      <td style="text-align: right">17.1</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">2</td>
      <td style="text-align: right">6.9</td>
      <td style="text-align: right">6.1</td>
      <td style="text-align: right">1.0853</td>
      <td style="text-align: right">22</td>
      <td style="text-align: right">173.25</td>
      <td style="text-align: right">72.25</td>
      <td style="text-align: right">23.4</td>
      <td style="text-align: right">161.3</td>
      <td style="text-align: right">38.5</td>
      <td style="text-align: right">93.6</td>
      <td style="text-align: right">83</td>
      <td style="text-align: right">98.7</td>
      <td style="text-align: right">58.7</td>
      <td style="text-align: right">37.3</td>
      <td style="text-align: right">23.4</td>
      <td style="text-align: right">30.5</td>
      <td style="text-align: right">28.9</td>
      <td style="text-align: right">18.2</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">3</td>
      <td style="text-align: right">24.6</td>
      <td style="text-align: right">25.3</td>
      <td style="text-align: right">1.0414</td>
      <td style="text-align: right">22</td>
      <td style="text-align: right">154</td>
      <td style="text-align: right">66.25</td>
      <td style="text-align: right">24.7</td>
      <td style="text-align: right">116</td>
      <td style="text-align: right">34</td>
      <td style="text-align: right">95.8</td>
      <td style="text-align: right">87.9</td>
      <td style="text-align: right">99.2</td>
      <td style="text-align: right">59.6</td>
      <td style="text-align: right">38.9</td>
      <td style="text-align: right">24</td>
      <td style="text-align: right">28.8</td>
      <td style="text-align: right">25.2</td>
      <td style="text-align: right">16.6</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">4</td>
      <td style="text-align: right">10.9</td>
      <td style="text-align: right">10.4</td>
      <td style="text-align: right">1.0751</td>
      <td style="text-align: right">26</td>
      <td style="text-align: right">184.75</td>
      <td style="text-align: right">72.25</td>
      <td style="text-align: right">24.9</td>
      <td style="text-align: right">164.7</td>
      <td style="text-align: right">37.4</td>
      <td style="text-align: right">101.8</td>
      <td style="text-align: right">86.4</td>
      <td style="text-align: right">101.2</td>
      <td style="text-align: right">60.1</td>
      <td style="text-align: right">37.3</td>
      <td style="text-align: right">22.8</td>
      <td style="text-align: right">32.4</td>
      <td style="text-align: right">29.4</td>
      <td style="text-align: right">18.2</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">5</td>
      <td style="text-align: right">27.8</td>
      <td style="text-align: right">28.7</td>
      <td style="text-align: right">1.034</td>
      <td style="text-align: right">24</td>
      <td style="text-align: right">184.25</td>
      <td style="text-align: right">71.25</td>
      <td style="text-align: right">25.6</td>
      <td style="text-align: right">133.1</td>
      <td style="text-align: right">34.4</td>
      <td style="text-align: right">97.3</td>
      <td style="text-align: right">100</td>
      <td style="text-align: right">101.9</td>
      <td style="text-align: right">63.2</td>
      <td style="text-align: right">42.2</td>
      <td style="text-align: right">24</td>
      <td style="text-align: right">32.2</td>
      <td style="text-align: right">27.7</td>
      <td style="text-align: right">17.7</td>
    </tr>
  </tbody>
</table>

<p>We will use only a subset of variables as regressors,
and in order to make evident the effect of the multicollinearity,
we will only use the first 40 measurements.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">indx</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df_bf</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">40</span><span class="p">]</span>

<span class="n">yobs</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'brozek'</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">indx</span><span class="p">]]</span>

<span class="n">Xnorm</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>

<span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">Xnorm</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/horseshoe/pairplot.webp" alt="The pairplot of the regressors" /></p>

<p>As you can see by the above plot, the regressors dataset shows
a pronounced multi-collinearity, since they are not
pairwise-independent.
In order to facilitate the comparison across coefficients, we will
use the (Gelman’s version of the) standardized coefficients.
Since the choice of a suitable scale for the prior is very important,
we scaled the observation by a factor 100,
and in this way the target variable ranges from 0 to 1.</p>

<p>Let us first try and see what happens if we only include one variable
into a linear regression model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">starting_models</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)):</span>
    <span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">mod</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span><span class="o">*</span><span class="n">Xnorm</span><span class="p">[</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="p">)</span>
        <span class="n">idata</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
        <span class="c1"># pm.compute_log_likelihood(idata)
</span>        <span class="c1"># idata.extend(pm.sample_posterior_predictive(idata, random_seed=rng))
</span>        <span class="n">starting_models</span><span class="p">.</span><span class="n">append</span><span class="p">([{</span><span class="s">'vars'</span><span class="p">:</span> <span class="p">[</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="s">'model'</span><span class="p">:</span> <span class="n">mod</span><span class="p">,</span> <span class="s">'idata'</span><span class="p">:</span> <span class="n">idata</span><span class="p">}])</span>

<span class="n">traces</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s">'idata'</span><span class="p">]</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">starting_models</span><span class="p">]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s">'vars'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">starting_models</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">traces</span><span class="p">,</span> <span class="n">model_names</span><span class="o">=</span><span class="n">names</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'beta'</span><span class="p">],</span> <span class="n">combined</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/horseshoe/forest_single.webp" alt="The forest plot for
the regression coefficients across the different models" /></p>

<p>From the above credible intervals, we conclude that height_in, ankle_cm, forearm_cm
are wrist_cm compatible with 0.
Let us include all except these variables into a multilinear regression.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">indx_pos</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">trace</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">traces</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">az</span><span class="p">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'beta'</span><span class="p">])[</span><span class="s">'hdi_3%'</span><span class="p">]</span><span class="o">*</span><span class="n">az</span><span class="p">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'beta'</span><span class="p">])[</span><span class="s">'hdi_97%'</span><span class="p">]).</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">]</span>

<span class="n">Xtmp</span> <span class="o">=</span> <span class="n">Xnorm</span><span class="p">[[</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">indx_pos</span><span class="p">]]</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s">'cols'</span><span class="p">:</span> <span class="n">Xtmp</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="s">'idx'</span><span class="p">:</span> <span class="n">Xtmp</span><span class="p">.</span><span class="n">index</span><span class="p">})</span> <span class="k">as</span> <span class="n">model_2</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s">'cols'</span><span class="p">])</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">Xtmp</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="p">)</span>

<span class="k">with</span> <span class="n">model_2</span><span class="p">:</span>
    <span class="n">idata_2</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_2</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/horseshoe/trace_2.webp" alt="" /></p>

<p>We only have few non-zero regression coefficients:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">idata_2</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'beta'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">combined</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/horseshoe/forest_2.webp" alt="" /></p>

<p>Only two of them appear to be different from zero.
This kind of iterative procedure to prune away the irrelevant variables
is a possible way to proceed. At this point, we could only include 
weight and abdomen, and maybe include one more regressor per time.
This is however both time-consuming and questionable: one might
ask why did you proceed in such an order, and whether using
a different order might have changed the result.
Let us as an example start by using all the variables.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s">'ind'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="s">'col'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">})</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s">'col'</span><span class="p">])</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">Xnorm</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="p">)</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/horseshoe/trace_full.webp" alt="The trace of the full model" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'beta'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgrey'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/horseshoe/forest_full.webp" alt="" /></p>

<p>As you can see, we would have a different result.</p>

<p>As previously anticipated, there is an alternative way to proceed, and
is by using an appropriate set of priors.
A reasonable choice is given by</p>

\[\begin{align}
\beta_i \sim &amp; \mathcal{N}(0, \sigma \tau_i)\\
\tau_i \sim &amp; \mathcal{HalfCauchy}(0, 1)\\
\end{align}\]

<p>The reason for this is quite simple: the half-Cauchy distribution
has a large amount of mass close to zero, but it also has
fat tails. In this way, the posterior is either shrunk to zero,
or far away from zero, and intermediate results are somehow
“discouraged” by the prior.</p>

<p>How to properly choose $\sigma$ is not trivial, and a recommended choice
is</p>

\[\sigma \sim \mathcal{HalfCauchy}(0, a)\]

<p>A large value of $a$ will not strongly affect the posterior,
while a small value will shrink the posterior to 0.
In our case, we choose $a=1\,,$ which is quite a large value
if we compare it to the expected effect of the regression
coefficients.
We leave to the reader the sensitivity analysis of the inference
depending on the choice of $a$.
You should keep in mind that your conclusions might strongly depend
on the choice of $a$, so in this case a proper sensitivity analysis
is strongly recommended.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s">'ind'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="s">'col'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">})</span> <span class="k">as</span> <span class="n">model_hh</span><span class="p">:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">sig_beta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s">'sig_beta'</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s">'col'</span><span class="p">])</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s">'sig'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">mu_beta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'mu_beta'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s">'beta'</span><span class="p">,</span> <span class="n">mu_beta</span><span class="o">+</span><span class="n">sigma</span><span class="o">*</span><span class="n">sig_beta</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s">'col'</span><span class="p">])</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">Xnorm</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="s">'ind'</span><span class="p">])</span>

<span class="k">with</span> <span class="n">model_hh</span><span class="p">:</span>
    <span class="n">idata_hh</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_hh</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/horseshoe/trace_hh.webp" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="c1"># az.plot_forest({'std': idata, 'hh': idata_hh}, var_names=['beta'], ax=ax, model_names=['std', 'hh'])
</span><span class="n">az</span><span class="p">.</span><span class="n">plot_forest</span><span class="p">([</span><span class="n">idata</span><span class="p">,</span> <span class="n">idata_hh</span><span class="p">],</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'beta'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">model_names</span><span class="o">=</span><span class="p">[</span><span class="s">'std'</span><span class="p">,</span> <span class="s">'hh'</span><span class="p">],</span> <span class="n">combined</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgrey'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p>We can now compare the forest plot of the two models
containing all the variables.</p>

<p><img src="/docs/assets/images/statistics/horseshoe/forest_compare.webp" alt="" /></p>

<p>The error bars of the horseshoe model are much smaller than the ones
of the standard model, and the net result
of using the horseshoe is that the posterior distribution
of the regression coefficients are more sparse than
the ones of the standard multilinear model.
If you perform a sensitivity analysis, you should obtain
the same results for quite a large range of choices for the
scale parameter.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We have seen how an appropriate choice of the prior distribution
allows us to enforce sparsity in the regression coefficients
of a multilinear model.
There are of course other possible approach to the problem,
such as <a href="https://www.pymc.io/projects/examples/en/latest/case_studies/factor_analysis.html">factor analysis</a>
or only adding one regressor per time,
as we did in the beginning.
However, according to my own view, an appropriate choice of
the prior to enforce some
desired condition is the best way to leverage
the Bayesian workflow to
tackle any issue, including multi-collinearity.</p>

<h2 id="suggested-readings">Suggested readings</h2>

<ul>
  <li><cite>Piironen, J., &amp; Vehtari, A. (2017). Sparsity information and regularization in the horseshoe and other shrinkage priors. arXiv: Methodology.</cite></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Sun Nov 17 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.7
<br />
IPython version      : 8.24.0
<br />

<br />
xarray : 2024.9.0
<br />
numpyro: 0.15.0
<br />
jax    : 0.4.28
<br />
jaxlib : 0.4.28
<br />

<br />
arviz     : 0.20.0
<br />
numpy     : 1.26.4
<br />
matplotlib: 3.9.2
<br />
seaborn   : 0.13.2
<br />
pandas    : 2.2.3
<br />
pymc      : 5.17.0
<br />

<br />
Watermark: 2.4.3
<br />
</div>]]></content><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><category term="/statistics/" /><category term="/horseshoe/" /><summary type="html"><![CDATA[Dealing with multi-collinearity]]></summary></entry><entry><title type="html">MRP</title><link href="http://localhost:4000/statistics/mrp" rel="alternate" type="text/html" title="MRP" /><published>2026-03-13T00:00:00+00:00</published><updated>2026-03-13T00:00:00+00:00</updated><id>http://localhost:4000/statistics/mrp</id><content type="html" xml:base="http://localhost:4000/statistics/mrp"><![CDATA[<p>MRP stands for <strong>Multilevel Regression and Post-stratification</strong>, and is a very
popular way to make inference based on surveys, especially with the ones
with selected samples.</p>

<p>The main issue with sampling is how to deal with non-responders,
and MrP allows you to correct for this issue if it is properly done.
You can consider MrP as a two-stage procedure:</p>

<ol>
  <li>Perform a multilevel regression on your sample</li>
  <li>re-weight the probabilities of each of your subpopulations with weights extracted from a census to obtain the population probability.</li>
</ol>

<p>Using multilevel regression allows you to share information across subpopulations, so the variance distribution will have a smoother behavior across them with respect to a single-level model.
Post-stratification is instead needed because, even if your sample is a random sample of your population,
non-respondence might be no random at all, and this could introduce a sampling bias into the respondent sample.
You should however always be very careful with surveys. In fact, 
as J. Ornstein reminds us in <a href="https://link.springer.com/chapter/10.1007/978-3-031-12982-7_5">Causality in Policy Studies</a>:</p>

<p><br /></p>

<blockquote>
  <p>MRP is not a panacea, and one should be skeptical of estimates produced from small-sample surveys, 
regardless of how they are operationalized.</p>

  <p>Joseph T. Ornstein</p>
</blockquote>

<p><br /></p>

<p>In the following we will use MRP to analyze the data collected in 
<a href="https://www.sciencedirect.com/science/article/pii/S2352340919304986#bib10">this study on conspiracy believes of the Italian population</a>,
and the dataset can be downloaded from
<a href="https://ars.els-cdn.com/content/image/1-s2.0-S2352340919304986-mmc1.zip">this link</a>.
We will adapt the MRP model as shown in
<a href="https://bookdown.org/jl5522/MRP-case-studies/">“MRP case studies” by Juan Lopez-Martin, Justin H. Phillips, and Andrew Gelman</a>.</p>

<h2 id="data-import-and-initial-transformations">Data import and initial transformations</h2>

<p>In this first part we will re-organize the data prepare the datasets
for the fit.
This part is quite technical, 
and I decided to keep it because it might be useful
to see that the data preparation can be a rather cumbersome procedure,
but the uninterested reader can safely skip it.
The population dataset has been obtained from the
<a href="https://esploradati.istat.it/databrowser/#/it/dw/categories/IT1,Z0820EDU,1.0/DCCV_POPTIT1_UNT2020/IT1,52_1194_DF_DCCV_POPTIT1_UNT2020_1,1.0">ISTAT -the official italian statistics institute- webpage</a>.</p>

<p>We used this dataset because, as it is well known, education is a very relevant factor in
conspiracy beliefs, so we used the dataset where the italian population
is given by age, sex, geographic area and education level.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">df_anag</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/istruzione.csv'</span><span class="p">)</span>

<span class="n">df_anag</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: right">Anno</th>
      <th style="text-align: left">Regione</th>
      <th style="text-align: left">Sesso</th>
      <th style="text-align: left">Fascia</th>
      <th style="text-align: right">Elementare</th>
      <th style="text-align: right">Media</th>
      <th style="text-align: right">Professionale</th>
      <th style="text-align: right">Maturita</th>
      <th style="text-align: right">Laurea</th>
      <th style="text-align: right">Totale</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: right">2020</td>
      <td style="text-align: left">N</td>
      <td style="text-align: left">M</td>
      <td style="text-align: left">15-24 anni</td>
      <td style="text-align: right">12</td>
      <td style="text-align: right">667</td>
      <td style="text-align: right">90</td>
      <td style="text-align: right">518</td>
      <td style="text-align: right">63</td>
      <td style="text-align: right">1350</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">2020</td>
      <td style="text-align: left">N</td>
      <td style="text-align: left">M</td>
      <td style="text-align: left">25-29 anni</td>
      <td style="text-align: right">6</td>
      <td style="text-align: right">121</td>
      <td style="text-align: right">80</td>
      <td style="text-align: right">300</td>
      <td style="text-align: right">190</td>
      <td style="text-align: right">698</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">2020</td>
      <td style="text-align: left">N</td>
      <td style="text-align: left">M</td>
      <td style="text-align: left">30-34 anni</td>
      <td style="text-align: right">8</td>
      <td style="text-align: right">184</td>
      <td style="text-align: right">84</td>
      <td style="text-align: right">271</td>
      <td style="text-align: right">189</td>
      <td style="text-align: right">737</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">2020</td>
      <td style="text-align: left">N</td>
      <td style="text-align: left">M</td>
      <td style="text-align: left">35-39 anni</td>
      <td style="text-align: right">9</td>
      <td style="text-align: right">227</td>
      <td style="text-align: right">92</td>
      <td style="text-align: right">282</td>
      <td style="text-align: right">201</td>
      <td style="text-align: right">811</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">2020</td>
      <td style="text-align: left">N</td>
      <td style="text-align: left">M</td>
      <td style="text-align: left">40-44 anni</td>
      <td style="text-align: right">20</td>
      <td style="text-align: right">298</td>
      <td style="text-align: right">108</td>
      <td style="text-align: right">356</td>
      <td style="text-align: right">184</td>
      <td style="text-align: right">965</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_spss</span><span class="p">(</span><span class="s">'./data/dib_104144_dataset.sav'</span><span class="p">)</span>

<span class="n">df_data</span> <span class="o">=</span> <span class="n">df_data</span><span class="p">[[</span><span class="s">'region'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'edu'</span><span class="p">,</span> <span class="s">'cb11'</span><span class="p">]]</span>

<span class="n">df_data</span><span class="p">[</span><span class="s">'y0'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_data</span><span class="p">[</span><span class="s">'cb11'</span><span class="p">].</span><span class="n">replace</span><span class="p">({</span><span class="s">'Completely disagree'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'Completely agree'</span><span class="p">:</span> <span class="mi">5</span><span class="p">})</span>

<span class="n">df_data</span><span class="p">.</span><span class="n">to_markdown</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">region</th>
      <th style="text-align: left">sex</th>
      <th style="text-align: right">age</th>
      <th style="text-align: left">edu</th>
      <th style="text-align: left">cb11</th>
      <th style="text-align: right">y0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Center</td>
      <td style="text-align: left">Female</td>
      <td style="text-align: right">37</td>
      <td style="text-align: left">degree</td>
      <td style="text-align: left">Completely disagree</td>
      <td style="text-align: right">1</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">Center</td>
      <td style="text-align: left">Female</td>
      <td style="text-align: right">20</td>
      <td style="text-align: left">high school</td>
      <td style="text-align: left">Completely disagree</td>
      <td style="text-align: right">1</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">Center</td>
      <td style="text-align: left">Female</td>
      <td style="text-align: right">19</td>
      <td style="text-align: left">high school</td>
      <td style="text-align: left">Completely disagree</td>
      <td style="text-align: right">1</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">Center</td>
      <td style="text-align: left">Female</td>
      <td style="text-align: right">19</td>
      <td style="text-align: left">high school</td>
      <td style="text-align: left">Completely disagree</td>
      <td style="text-align: right">1</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">North</td>
      <td style="text-align: left">Female</td>
      <td style="text-align: right">31</td>
      <td style="text-align: left">high school</td>
      <td style="text-align: left">Completely disagree</td>
      <td style="text-align: right">1</td>
    </tr>
  </tbody>
</table>

<p>The target variable is the answer to the question
“Vaccines are useless and dangerous, they are only instrumental to the financial interests of pharmaceutical
companies”
from <a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886918303751">Avoidant attachment style and conspiracy ideation</a>
and the answer goes from 1 (completely disagree) to 5 (completely agree).
We will transform it and make it binary, and the transformed variable will be 1
if the respondent answered 4 or 5 to the above question.
As regressors, we will use as starting point:</p>
<ul>
  <li>the region, marked N for North, C for center and M for south or islands.</li>
  <li>the sex (M/F)</li>
  <li>the age (integer)</li>
  <li>the education level</li>
</ul>

<p>Let us look to the education</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_data</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'edu'</span><span class="p">).</span><span class="n">count</span><span class="p">()[</span><span class="s">'region'</span><span class="p">]</span>
</code></pre></div></div>

<div class="code">
edu
<br />
0.0                    6
<br />
degree               306
<br />
high school          350
<br />
no qualifications      2
<br />
post graduate         73
<br />
primary school         3
<br />
secondary school      34
<br />
Name: region, dtype: int64
<br />
</div>

<p>Since in Italy the vast majority of the adult population has at least a high school degree,
we will only use the university degree as regressor, otherwise we wouldn’t
have a sufficient number of subject in order to get a reliable estimate of the regression
coefficients.</p>

<p>Let us now stratify the age, since it doesn’t make much sense to the bare age as regressor.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_a0</span> <span class="o">=</span> <span class="n">df_anag</span><span class="p">[</span><span class="n">df_anag</span><span class="p">[</span><span class="s">'Fascia'</span><span class="p">].</span><span class="n">isin</span><span class="p">([</span><span class="s">'15-24 anni'</span><span class="p">,</span> <span class="s">'25-29 anni'</span><span class="p">])].</span><span class="n">groupby</span><span class="p">(</span>
    <span class="p">[</span><span class="s">'Regione'</span><span class="p">,</span> <span class="s">'Sesso'</span><span class="p">]).</span><span class="nb">sum</span><span class="p">()[[</span><span class="s">'Maturita'</span><span class="p">,</span> <span class="s">'Laurea'</span><span class="p">,</span> <span class="s">'Totale'</span><span class="p">]].</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df_a1</span> <span class="o">=</span> <span class="n">df_anag</span><span class="p">[</span><span class="n">df_anag</span><span class="p">[</span><span class="s">'Fascia'</span><span class="p">].</span><span class="n">isin</span><span class="p">([</span><span class="s">'30-34 anni'</span><span class="p">,</span> <span class="s">'35-39 anni'</span><span class="p">])].</span><span class="n">groupby</span><span class="p">(</span>
    <span class="p">[</span><span class="s">'Regione'</span><span class="p">,</span> <span class="s">'Sesso'</span><span class="p">]).</span><span class="nb">sum</span><span class="p">()[[</span><span class="s">'Maturita'</span><span class="p">,</span> <span class="s">'Laurea'</span><span class="p">,</span> <span class="s">'Totale'</span><span class="p">]].</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df_a2</span> <span class="o">=</span> <span class="n">df_anag</span><span class="p">[</span><span class="n">df_anag</span><span class="p">[</span><span class="s">'Fascia'</span><span class="p">].</span><span class="n">isin</span><span class="p">([</span><span class="s">'40-44 anni'</span><span class="p">,</span> <span class="s">'45-49 anni'</span><span class="p">])].</span><span class="n">groupby</span><span class="p">(</span>
    <span class="p">[</span><span class="s">'Regione'</span><span class="p">,</span> <span class="s">'Sesso'</span><span class="p">]).</span><span class="nb">sum</span><span class="p">()[[</span><span class="s">'Maturita'</span><span class="p">,</span> <span class="s">'Laurea'</span><span class="p">,</span> <span class="s">'Totale'</span><span class="p">]].</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df_a3</span> <span class="o">=</span> <span class="n">df_anag</span><span class="p">[</span><span class="n">df_anag</span><span class="p">[</span><span class="s">'Fascia'</span><span class="p">].</span><span class="n">isin</span><span class="p">([</span><span class="s">'50-54 anni'</span><span class="p">,</span> <span class="s">'55-59 anni'</span><span class="p">])].</span><span class="n">groupby</span><span class="p">(</span>
    <span class="p">[</span><span class="s">'Regione'</span><span class="p">,</span> <span class="s">'Sesso'</span><span class="p">]).</span><span class="nb">sum</span><span class="p">()[[</span><span class="s">'Maturita'</span><span class="p">,</span> <span class="s">'Laurea'</span><span class="p">,</span> <span class="s">'Totale'</span><span class="p">]].</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df_a4</span> <span class="o">=</span> <span class="n">df_anag</span><span class="p">[</span><span class="n">df_anag</span><span class="p">[</span><span class="s">'Fascia'</span><span class="p">].</span><span class="n">isin</span><span class="p">([</span><span class="s">'60-64 anni'</span><span class="p">,</span> <span class="s">'65 anni e più'</span><span class="p">])].</span><span class="n">groupby</span><span class="p">(</span>
    <span class="p">[</span><span class="s">'Regione'</span><span class="p">,</span> <span class="s">'Sesso'</span><span class="p">]).</span><span class="nb">sum</span><span class="p">()[[</span><span class="s">'Maturita'</span><span class="p">,</span> <span class="s">'Laurea'</span><span class="p">,</span> <span class="s">'Totale'</span><span class="p">]].</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">df_a0</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">df_a1</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">df_a2</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">df_a3</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">df_a4</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">df_anag_new</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_a0</span><span class="p">,</span> <span class="n">df_a1</span><span class="p">,</span> <span class="n">df_a2</span><span class="p">,</span> <span class="n">df_a3</span><span class="p">,</span> <span class="n">df_a4</span><span class="p">])</span>
</code></pre></div></div>

<p>We can now transform the sample dataframe</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_fit</span> <span class="o">=</span> <span class="n">df_data</span><span class="p">[[</span><span class="s">'region'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'edu'</span><span class="p">,</span> <span class="s">'y0'</span><span class="p">]]</span>
<span class="n">df_fit</span><span class="p">[</span><span class="s">'Centro'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'region'</span><span class="p">]</span><span class="o">==</span><span class="s">'Center'</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df_fit</span><span class="p">[</span><span class="s">'Mezzogiorno'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'region'</span><span class="p">].</span><span class="n">isin</span><span class="p">([</span><span class="s">'South'</span><span class="p">,</span> <span class="s">'Islands'</span><span class="p">])).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df_fit</span><span class="p">[</span><span class="s">'is_male'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'sex'</span><span class="p">]</span><span class="o">==</span><span class="s">'Male'</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df_fit</span><span class="p">[</span><span class="s">'has_degree'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_fit</span><span class="p">[</span><span class="s">'edu'</span><span class="p">].</span><span class="n">isin</span><span class="p">([</span><span class="s">'degree'</span><span class="p">,</span> <span class="s">'post graduate'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df_fit</span> <span class="o">=</span> <span class="n">df_fit</span><span class="p">[</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'age'</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># if the age is not reported "age" has value -99
</span>
<span class="k">def</span> <span class="nf">map_age</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">30</span> <span class="ow">and</span> <span class="n">x</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">30</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">40</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">40</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">50</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">50</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">60</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">3</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">60</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">4</span>

<span class="n">df_fit</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_fit</span><span class="p">[</span><span class="s">'age'</span><span class="p">].</span><span class="nb">map</span><span class="p">(</span><span class="n">map_age</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">df_fit</span><span class="p">[</span><span class="s">'y'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'y0'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">3</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="explorative-analysis">Explorative analysis</h2>

<p>We can now look for differences between the survey sample and the italian population.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_anag_new</span><span class="p">[</span><span class="s">'NoLaurea'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_anag_new</span><span class="p">[</span><span class="s">'Totale'</span><span class="p">]</span><span class="o">-</span><span class="n">df_anag_new</span><span class="p">[</span><span class="s">'Laurea'</span><span class="p">]</span>
<span class="n">df_anag_deg</span> <span class="o">=</span> <span class="n">df_anag_new</span><span class="p">.</span><span class="n">melt</span><span class="p">(</span><span class="n">value_vars</span><span class="o">=</span><span class="p">[</span><span class="s">'Laurea'</span><span class="p">,</span> <span class="s">'NoLaurea'</span><span class="p">],</span>
                               <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s">'Regione'</span><span class="p">,</span> <span class="s">'Sesso'</span><span class="p">,</span> <span class="s">'Gruppo'</span><span class="p">,</span> <span class="s">'Totale'</span><span class="p">],</span>
                               <span class="n">value_name</span><span class="o">=</span><span class="s">'number'</span><span class="p">,</span> <span class="n">var_name</span><span class="o">=</span><span class="s">'has_degree'</span><span class="p">)</span>
<span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'has_degree'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'has_degree'</span><span class="p">]</span><span class="o">==</span><span class="s">'Laurea'</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'frac'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'number'</span><span class="p">]</span><span class="o">/</span><span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'number'</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span>

<span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'Centro'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'Regione'</span><span class="p">]</span><span class="o">==</span><span class="s">'C'</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'Mezzogiorno'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'Regione'</span><span class="p">]</span><span class="o">==</span><span class="s">'M'</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'is_male'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'Sesso'</span><span class="p">]</span><span class="o">==</span><span class="s">'M'</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">df_means_by_group</span> <span class="o">=</span> <span class="n">df_fit</span><span class="p">[[</span><span class="s">'Centro'</span><span class="p">,</span> <span class="s">'Mezzogiorno'</span><span class="p">,</span> <span class="s">'is_male'</span><span class="p">,</span> <span class="s">'Gruppo'</span><span class="p">,</span> <span class="s">'has_degree'</span><span class="p">,</span> <span class="s">'y'</span><span class="p">]].</span><span class="n">groupby</span><span class="p">(</span>
    <span class="p">[</span><span class="s">'Centro'</span><span class="p">,</span> <span class="s">'Mezzogiorno'</span><span class="p">,</span> <span class="s">'is_male'</span><span class="p">,</span> <span class="s">'Gruppo'</span><span class="p">,</span> <span class="s">'has_degree'</span><span class="p">]).</span><span class="n">mean</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df_n_by_group</span> <span class="o">=</span> <span class="n">df_fit</span><span class="p">[[</span><span class="s">'Centro'</span><span class="p">,</span> <span class="s">'Mezzogiorno'</span><span class="p">,</span> <span class="s">'is_male'</span><span class="p">,</span> <span class="s">'Gruppo'</span><span class="p">,</span> <span class="s">'has_degree'</span><span class="p">,</span> <span class="s">'y'</span><span class="p">]].</span><span class="n">groupby</span><span class="p">(</span>
    <span class="p">[</span><span class="s">'Centro'</span><span class="p">,</span> <span class="s">'Mezzogiorno'</span><span class="p">,</span> <span class="s">'is_male'</span><span class="p">,</span> <span class="s">'Gruppo'</span><span class="p">,</span> <span class="s">'has_degree'</span><span class="p">]).</span><span class="n">count</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
</code></pre></div></div>

<p>We prepared two auxiliary datasets, and the last one counts
how many units for each stratum are present in the dataset.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">df_n_by_group</span><span class="p">[</span><span class="s">'y'</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>
<div class="code">
0
</div>

<p>There is at least one unit for each stratum, and this is a first indicator
that our age groups are large enough.
Let us compare the population percentages for each regression variable
with the corresponding sample percentage.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_n_by_group</span><span class="p">[</span><span class="s">'Regione'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">df_n_by_group</span><span class="p">[</span><span class="s">'Centro'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span>
                                    <span class="s">'C'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">df_n_by_group</span><span class="p">[</span><span class="s">'Mezzogiorno'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="s">'M'</span><span class="p">,</span> <span class="s">'N'</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">df_anag_deg</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'Gruppo'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'frac'</span><span class="p">].</span><span class="n">reset_index</span><span class="p">().</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'frac'</span><span class="p">:</span> <span class="s">'y'</span><span class="p">}),</span>
             <span class="n">x</span><span class="o">=</span><span class="s">'Gruppo'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'y'</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">((</span><span class="n">df_n_by_group</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'Gruppo'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'y'</span><span class="p">]</span><span class="o">/</span><span class="n">df_n_by_group</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'Gruppo'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'y'</span><span class="p">].</span><span class="nb">sum</span><span class="p">()).</span><span class="n">reset_index</span><span class="p">(),</span>
             <span class="n">x</span><span class="o">=</span><span class="s">'Gruppo'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'y'</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">df_anag_deg</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'has_degree'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'frac'</span><span class="p">].</span><span class="n">reset_index</span><span class="p">().</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'frac'</span><span class="p">:</span> <span class="s">'y'</span><span class="p">}),</span>
             <span class="n">x</span><span class="o">=</span><span class="s">'has_degree'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'y'</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'Population'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">((</span><span class="n">df_n_by_group</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'has_degree'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'y'</span><span class="p">]</span><span class="o">/</span><span class="n">df_n_by_group</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'has_degree'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'y'</span><span class="p">].</span><span class="nb">sum</span><span class="p">()).</span><span class="n">reset_index</span><span class="p">(),</span>
             <span class="n">x</span><span class="o">=</span><span class="s">'has_degree'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'y'</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Sample'</span><span class="p">)</span>

<span class="n">legend</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper right'</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
<span class="n">legend</span><span class="p">.</span><span class="n">get_frame</span><span class="p">().</span><span class="n">set_alpha</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">df_anag_deg</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'Regione'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'frac'</span><span class="p">].</span><span class="n">reset_index</span><span class="p">().</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'frac'</span><span class="p">:</span> <span class="s">'y'</span><span class="p">}),</span>
             <span class="n">x</span><span class="o">=</span><span class="s">'Regione'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'y'</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">((</span><span class="n">df_n_by_group</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'Regione'</span><span class="p">]).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'y'</span><span class="p">]</span><span class="o">/</span><span class="n">df_n_by_group</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="nb">sum</span><span class="p">()).</span><span class="n">reset_index</span><span class="p">(),</span>
             <span class="n">x</span><span class="o">=</span><span class="s">'Regione'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'y'</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">df_anag_deg</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'is_male'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'frac'</span><span class="p">].</span><span class="n">reset_index</span><span class="p">().</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'frac'</span><span class="p">:</span> <span class="s">'y'</span><span class="p">}),</span>
             <span class="n">x</span><span class="o">=</span><span class="s">'is_male'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'y'</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">((</span><span class="n">df_n_by_group</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'is_male'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'y'</span><span class="p">]</span><span class="o">/</span><span class="n">df_n_by_group</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'is_male'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[</span><span class="s">'y'</span><span class="p">].</span><span class="nb">sum</span><span class="p">()).</span><span class="n">reset_index</span><span class="p">(),</span>
             <span class="n">x</span><span class="o">=</span><span class="s">'is_male'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'y'</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>


<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/mrp/percentages.webp" alt="" /></p>

<p>There are very large differences between the sample and the population,
and this might lead to an unreliable estimate for our target variable.</p>

<h2 id="fitting-the-model">Fitting the model</h2>

<p>We will use a hierarchical model with the previously mentioned regressors,
and the implemented model is the following one:</p>

\[\begin{align*}
logit P(y^i=1) = &amp;  \theta^i \\
\\
\theta^i = &amp; \alpha + \gamma_{C} X^i_{Centro}+ \gamma_{M} X^i_{Mezzogiorno} \\
&amp; + \beta_{Male} X^i_{Male} + \beta_{Group}^{g[i]}+ \beta_{Degree}^{g[i]} X^{i}_{Degree} \\
&amp; + \beta_{Male, Edu}^{g[i]}X^i_{Male} X^{i}_{Degree}
\end{align*}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">sigma_group</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s">'sigma_group'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">sigma_degree</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s">'sigma_degree'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">sigma_male_edu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s">'sigma_male_edu'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">alpha_degree</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha_degree'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">alpha_male_edu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha_male_edu'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">beta_group_std</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta_group_std'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">].</span><span class="n">drop_duplicates</span><span class="p">()))</span>
    <span class="n">beta_group</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s">'beta_group'</span><span class="p">,</span> <span class="n">sigma_group</span><span class="o">*</span><span class="n">beta_group_std</span><span class="p">)</span>
    <span class="n">beta_male</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta_male'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">beta_male_edu_std</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta_male_edu_std'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">].</span><span class="n">drop_duplicates</span><span class="p">()))</span>
    <span class="n">beta_degree_std</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta_degree_std'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">].</span><span class="n">drop_duplicates</span><span class="p">()))</span>
    <span class="n">beta_degree</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s">'beta_degree'</span><span class="p">,</span> <span class="n">alpha_degree</span><span class="o">+</span><span class="n">beta_degree_std</span><span class="o">*</span><span class="n">sigma_degree</span><span class="p">)</span>
    <span class="n">beta_male_edu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s">'beta_male_edu'</span><span class="p">,</span> <span class="n">alpha_male_edu</span><span class="o">+</span><span class="n">beta_male_edu_std</span><span class="o">*</span><span class="n">sigma_male_edu</span><span class="p">)</span>
    <span class="n">gamma_centro</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'gamma_centro'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">gamma_mezzogiorno</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'gamma_mezzogiorno'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">beta_group</span><span class="p">[</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]]</span> <span class="o">+</span> <span class="n">beta_male</span><span class="o">*</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'is_male'</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_degree</span><span class="p">[</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]]</span><span class="o">*</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'has_degree'</span><span class="p">]</span> <span class="o">+</span> <span class="n">gamma_centro</span><span class="o">*</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'Centro'</span><span class="p">]</span><span class="o">+</span> <span class="n">gamma_mezzogiorno</span><span class="o">*</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'Mezzogiorno'</span><span class="p">]</span>
         <span class="o">+</span> <span class="n">beta_male_edu</span><span class="p">[</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]]</span><span class="o">*</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'is_male'</span><span class="p">]</span><span class="o">*</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'has_degree'</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">logit_p</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df_fit</span><span class="p">[</span><span class="s">'y'</span><span class="p">])</span>

<span class="n">pm</span><span class="p">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/mrp/model.webp" alt="" /></p>

<p>As you can see, we slightly modified our parametrization to improve the convergence.
We are now ready to sample the posterior.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
                      <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/mrp/trace.webp" alt="" /></p>

<p>The traces look fine, but since this is quite a messy model, it is better to also inspect
the $\hat{R}$ statistics</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">summary</span><span class="p">(</span><span class="n">idata</span><span class="p">)[</span><span class="s">'r_hat'</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span>
</code></pre></div></div>

<div class="code">
1.0
</div>

<p>$\hat{R}$ is fine too, so we can assume that there are no issues with our model.
Let us take a look at the separation plot</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">))</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_separation</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'y'</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/mrp/separation.webp" alt="" /></p>

<p>The result is far from being perfect, but the darker blue lines are mostly
on the right hand side, so the model is doing quite a decent job.
We can now verify the results of our model.
Let us implement two routines to perform the model predictions,
with and without post-stratification:</p>

\[\begin{align*}
\theta_{PS} = &amp; \frac{\sum_i N_i \theta_i}{\sum_i N_i} \\
\theta_{Raw} = &amp; \frac{\sum_i  N_i^{sample} \theta_i}{\sum_i N_i^{sample}}
\end{align*}\]

<p>where $N_i$ is the number of individuals in the group i (or equivalently the percentage),
and $\theta_i$ the corresponding estimate.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fcalc</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">idata</span><span class="p">.</span><span class="n">posterior</span>
    <span class="n">logit_p</span> <span class="o">=</span> <span class="p">(</span><span class="n">dt</span><span class="p">[</span><span class="s">'alpha'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">dt</span><span class="p">[</span><span class="s">'beta_group'</span><span class="p">].</span><span class="n">sel</span><span class="p">(</span><span class="n">beta_group_dim_0</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]).</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
               <span class="o">+</span> <span class="n">dt</span><span class="p">[</span><span class="s">'beta_male'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">df</span><span class="p">[</span><span class="s">'is_male'</span><span class="p">]</span>
               <span class="o">+</span> <span class="n">dt</span><span class="p">[</span><span class="s">'beta_degree'</span><span class="p">].</span><span class="n">sel</span><span class="p">(</span><span class="n">beta_degree_dim_0</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]).</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">df</span><span class="p">[</span><span class="s">'has_degree'</span><span class="p">]</span>
               <span class="o">+</span> <span class="n">dt</span><span class="p">[</span><span class="s">'beta_male_edu'</span><span class="p">].</span><span class="n">sel</span><span class="p">(</span><span class="n">beta_male_edu_dim_0</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]).</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">df</span><span class="p">[</span><span class="s">'has_degree'</span><span class="p">]</span><span class="o">*</span><span class="n">df</span><span class="p">[</span><span class="s">'is_male'</span><span class="p">]</span>
               <span class="o">+</span> <span class="n">dt</span><span class="p">[</span><span class="s">'gamma_mezzogiorno'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">df</span><span class="p">[</span><span class="s">'Mezzogiorno'</span><span class="p">]</span>
               <span class="o">+</span> <span class="n">dt</span><span class="p">[</span><span class="s">'gamma_centro'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">df</span><span class="p">[</span><span class="s">'Centro'</span><span class="p">]</span>
              <span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logit_p</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logit_p</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">p</span>

<span class="k">def</span> <span class="nf">get_proba</span><span class="p">(</span><span class="n">df_filt</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">'frac'</span><span class="p">):</span>
    <span class="n">out_mean</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">out_ql</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">out_qh</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">df_filt</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df_filt</span><span class="p">.</span><span class="n">iterrows</span><span class="p">():</span>
        <span class="n">dt</span> <span class="o">+=</span> <span class="n">fcalc</span><span class="p">(</span><span class="n">row</span><span class="p">)</span><span class="o">*</span><span class="n">row</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">/</span><span class="n">norm</span>
    <span class="n">out_mean</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>
    <span class="n">out_ql</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">out_qh</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">out_mean</span><span class="p">,</span> <span class="n">out_ql</span><span class="p">,</span> <span class="n">out_qh</span><span class="p">]</span>
</code></pre></div></div>

<p>We can now compare the results of the post-stratification with the corresponding
raw estimate</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nat_proba</span> <span class="o">=</span> <span class="n">get_proba</span><span class="p">(</span><span class="n">df_anag_deg</span><span class="p">)</span>

<span class="n">grp_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">region</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s">'N'</span><span class="p">,</span> <span class="s">'C'</span><span class="p">,</span> <span class="s">'M'</span><span class="p">]):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">nat_proba</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'grey'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">nat_proba</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'grey'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">nat_proba</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'grey'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
    
    <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">get_proba</span><span class="p">(</span><span class="n">df_anag_deg</span><span class="p">[((</span><span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'Regione'</span><span class="p">]</span><span class="o">==</span><span class="n">region</span><span class="p">)</span> <span class="p">)])</span>
           <span class="k">for</span> <span class="n">grp</span> <span class="ow">in</span> <span class="n">grp_list</span><span class="p">]).</span><span class="n">T</span>
    <span class="n">asymmetric_error</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob</span><span class="p">[</span><span class="mi">0</span><span class="p">])))).</span><span class="n">T</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">errorbar</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">grp_list</span><span class="p">)</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prob</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">yerr</span><span class="o">=</span><span class="n">asymmetric_error</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'None'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">grp_list</span><span class="p">)</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prob</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s">'PS'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'None'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'x'</span><span class="p">)</span>

    <span class="n">prob1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">get_proba</span><span class="p">(</span><span class="n">df_n_by_group</span><span class="p">[((</span><span class="n">df_n_by_group</span><span class="p">[</span><span class="s">'Regione'</span><span class="p">]</span><span class="o">==</span><span class="n">region</span><span class="p">))],</span> <span class="n">col</span><span class="o">=</span><span class="s">'y'</span><span class="p">)</span>
           <span class="k">for</span> <span class="n">grp</span> <span class="ow">in</span> <span class="n">grp_list</span><span class="p">]).</span><span class="n">T</span>
    <span class="n">asymmetric_error1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob1</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob1</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob1</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob1</span><span class="p">[</span><span class="mi">0</span><span class="p">])))).</span><span class="n">T</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">errorbar</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">grp_list</span><span class="p">)</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prob1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">yerr</span><span class="o">=</span><span class="n">asymmetric_error1</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'None'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">grp_list</span><span class="p">)</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prob1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s">'Raw'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'None'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'x'</span><span class="p">)</span>

    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s">"Region=</span><span class="si">{</span><span class="n">region</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="n">legend</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper right'</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.94</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">))</span>
    <span class="n">legend</span><span class="p">.</span><span class="n">get_frame</span><span class="p">().</span><span class="n">set_alpha</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s">'&lt;30'</span><span class="p">,</span> <span class="s">'30-39'</span><span class="p">,</span> <span class="s">'40-49'</span><span class="p">,</span> <span class="s">'50-59'</span><span class="p">,</span> <span class="s">'60+'</span><span class="p">])</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

</code></pre></div></div>
<p><img src="/docs/assets/images/statistics/mrp/PS_compare.webp" alt="" /></p>

<p>We recall that the percentages of people with a degree in our sample is very different
from the one in the Italian population, and this implies that there are
large differences between the post-stratified estimates and the raw estimates.</p>

<p>We can now inspect the effect of the education for each region and age group.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grp_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">region</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s">'N'</span><span class="p">,</span> <span class="s">'C'</span><span class="p">,</span> <span class="s">'M'</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">deg</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]:</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">nat_proba</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'grey'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">nat_proba</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'grey'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">nat_proba</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'grey'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
        
        <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">get_proba</span><span class="p">(</span><span class="n">df_anag_deg</span><span class="p">[((</span><span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'Regione'</span><span class="p">]</span><span class="o">==</span><span class="n">region</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'has_degree'</span><span class="p">]</span><span class="o">==</span><span class="n">deg</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_anag_deg</span><span class="p">[</span><span class="s">'Gruppo'</span><span class="p">]</span> <span class="o">==</span> <span class="n">grp</span><span class="p">))])</span>
               <span class="k">for</span> <span class="n">grp</span> <span class="ow">in</span> <span class="n">grp_list</span><span class="p">]).</span><span class="n">T</span>
        <span class="n">asymmetric_error</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">prob</span><span class="p">[</span><span class="mi">0</span><span class="p">])))).</span><span class="n">T</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">errorbar</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">grp_list</span><span class="p">)</span><span class="o">+</span><span class="mf">0.05</span><span class="o">*</span><span class="n">deg</span><span class="p">,</span> <span class="n">prob</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">yerr</span><span class="o">=</span><span class="n">asymmetric_error</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'None'</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">grp_list</span><span class="p">)</span><span class="o">+</span><span class="mf">0.05</span><span class="o">*</span><span class="n">deg</span><span class="p">,</span> <span class="n">prob</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s">'Has degree=</span><span class="si">{</span><span class="nb">bool</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'None'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'x'</span><span class="p">)</span>


    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s">"Region=</span><span class="si">{</span><span class="n">region</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="n">legend</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper right'</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.94</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">))</span>
    <span class="n">legend</span><span class="p">.</span><span class="n">get_frame</span><span class="p">().</span><span class="n">set_alpha</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s">'&lt;30'</span><span class="p">,</span> <span class="s">'30-39'</span><span class="p">,</span> <span class="s">'40-49'</span><span class="p">,</span> <span class="s">'50-59'</span><span class="p">,</span> <span class="s">'60+'</span><span class="p">])</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/mrp/estimates.webp" alt="" /></p>

<p>We can finally provide a national-level estimate for the target probability</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nat_proba_raw</span> <span class="o">=</span> <span class="n">get_proba</span><span class="p">(</span><span class="n">df_n_by_group</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">'y'</span><span class="p">)</span>

<span class="n">dt_mean</span> <span class="o">=</span> <span class="p">[</span><span class="n">nat_proba</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nat_proba_raw</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">dt_low</span> <span class="o">=</span> <span class="p">[</span><span class="n">nat_proba</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nat_proba_raw</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">dt_high</span> <span class="o">=</span> <span class="p">[</span><span class="n">nat_proba</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">nat_proba_raw</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>

<span class="n">asymmetric_error</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">dt_mean</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">dt_low</span><span class="p">),</span>
                                     <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">dt_high</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">dt_mean</span><span class="p">)))).</span><span class="n">T</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="p">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dt_mean</span><span class="p">)),</span> <span class="n">dt_mean</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><span class="n">asymmetric_error</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'None'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'x'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dt_mean</span><span class="p">)))</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s">'Post-stratified'</span><span class="p">,</span> <span class="s">'Raw estimate'</span><span class="p">])</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/mrp/national_estimate.webp" alt="" /></p>

<p>The mean difference between the stratified estimate and the raw one
is of the order of the 10%,
and it’s of the same order of magnitude of the 90% CI,
therefore the raw estimate is totally unreliable.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We discussed MRP, and we have seen how to implement it in Python in order to provide
reliable estimates for surveys, especially when they are performed on a selected population.</p>

<h2 id="suggested-readings">Suggested readings</h2>

<ul>
  <li><a href="https://bookdown.org/jl5522/MRP-case-studies/">“MRP case studies” and references therein, by Juan Lopez-Martin, Justin H. Phillips, and Andrew Gelman</a></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>
<div class="code">
Last updated: Wed Aug 28 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />

<br />
xarray : 2024.5.0
<br />
numpyro: 0.15.0
<br />
jax    : 0.4.28
<br />
jaxlib : 0.4.28
<br />

<br />
numpy     : 1.26.4
<br />
pymc      : 5.16.2
<br />
pandas    : 2.2.2
<br />
seaborn   : 0.13.2
<br />
matplotlib: 3.9.0
<br />
arviz     : 0.18.0
<br />

<br />
Watermark: 2.4.3
<br />
</div>]]></content><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><category term="/statistics/" /><category term="/mrp/" /><summary type="html"><![CDATA[The one who guessed US election results]]></summary></entry><entry><title type="html">Application of the Lotka-Volterra model</title><link href="http://localhost:4000/statistics/lotka_volterra" rel="alternate" type="text/html" title="Application of the Lotka-Volterra model" /><published>2026-03-06T00:00:00+00:00</published><updated>2026-03-06T00:00:00+00:00</updated><id>http://localhost:4000/statistics/lotka_volterra</id><content type="html" xml:base="http://localhost:4000/statistics/lotka_volterra"><![CDATA[<p>In the last post we saw how to implement an ODE solver in PyMC, and we did so
by using a dataset by Gause.
In this post we will go a little bit forward, and we will see how 
we could use the above concepts to try and falsify the model proposed in Gause’s textbook.
We will use another dataset provided in the same repo, in particular
the one containing the data shown in fig. 25 of the same book.
In this example Gause considers two paramecium species, one named
Paramecium Caudatum and the other named Paramecium Aurelia.
Gause first measured how the volume occupied by each specie varied with time 
by keeping them separate but with the same environment, then
he put them together without varying the environment.
In the first case (labelled as “Monoculture”),
the volume occupied should follow the logistic model for each specie.</p>

\[\frac{dy_i(t)}{dt} = \lambda_i y_i(t) \left(1-\frac{y_i(t)}{K_i}\right)\]

<p>while in the latter (labelled as “Mixed”) we should observe a competition between the two species</p>

\[\frac{dy_i(t)}{dt} = \lambda_i y_i(t) \left(1-\frac{y_i(t)-\gamma y_{-i}(t)}{K_i}\right)\,.\]

<p>First of all, we notice that the parameters $\lambda_i$ and $K_i$
should not vary in the two cases, since they only depend on the specie and on the
environment.
This implies that if we only fit the monoculture dataset, we should obtain
an estimate for the above parameters which is compatible with the combined fit of the
two cases.</p>

<p>We will also test the predictive power of the model, by only using
the initial data for the mixed case, and we will then verify if our prediction 
is compatible with the observed data.</p>

<h2 id="data-import-and-preprocessing">Data import and preprocessing</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pyreadr</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pytensor</span> <span class="k">as</span> <span class="n">pt</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">421124</span><span class="p">)</span>

<span class="n">df_0</span> <span class="o">=</span> <span class="n">pyreadr</span><span class="p">.</span><span class="n">read_r</span><span class="p">(</span><span class="s">'data/gause_1934_book_f25.rda'</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df_0</span><span class="p">[</span><span class="s">'gause_1934_book_f25'</span><span class="p">]</span>

<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">Paper</th>
      <th style="text-align: right">Figure</th>
      <th style="text-align: left">Species</th>
      <th style="text-align: right">Time</th>
      <th style="text-align: right">Volume</th>
      <th style="text-align: left">Treatment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">25</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">0.988805</td>
      <td style="text-align: right">7.581</td>
      <td style="text-align: left">Monoculture</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">25</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">1.96537</td>
      <td style="text-align: right">31.4395</td>
      <td style="text-align: left">Monoculture</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">25</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">2.9918</td>
      <td style="text-align: right">46.2918</td>
      <td style="text-align: left">Monoculture</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">25</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">4.02315</td>
      <td style="text-align: right">76.0357</td>
      <td style="text-align: left">Monoculture</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">25</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">5.00452</td>
      <td style="text-align: right">114.439</td>
      <td style="text-align: left">Monoculture</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">target</span> <span class="o">=</span> <span class="s">'Volume'</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium caudatum'</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'Treatment'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium aurelia'</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'Treatment'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Paramecium caudatum'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Paramecium aurelia'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/lotka_volterra/data.webp" alt="The imported dataset" /></p>

<p>You should notice that the measurements start at different time and are not
equally spaced. This will require a little bit of work in order to set a proper integration
step and in order to ensure consistent boundary conditions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">dfb1_all</span> <span class="o">=</span> <span class="n">df</span><span class="p">[((</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium caudatum'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Treatment'</span><span class="p">]</span><span class="o">==</span><span class="s">'Mixture'</span><span class="p">))].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="n">dfb2_extra</span> <span class="o">=</span> <span class="n">df</span><span class="p">[((</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium aurelia'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Treatment'</span><span class="p">]</span><span class="o">==</span><span class="s">'Mixture'</span><span class="p">))].</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Time'</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span><span class="mi">7</span><span class="p">:]</span>

<span class="n">dfb2_all</span> <span class="o">=</span> <span class="n">df</span><span class="p">[((</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium aurelia'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Treatment'</span><span class="p">]</span><span class="o">==</span><span class="s">'Mixture'</span><span class="p">))].</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Time'</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="n">dfa1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[((</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium caudatum'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Treatment'</span><span class="p">]</span><span class="o">==</span><span class="s">'Monoculture'</span><span class="p">))].</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Time'</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">dfa2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[((</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium aurelia'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Treatment'</span><span class="p">]</span><span class="o">==</span><span class="s">'Monoculture'</span><span class="p">))].</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Time'</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

<span class="n">dfb2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[((</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium aurelia'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Treatment'</span><span class="p">]</span><span class="o">==</span><span class="s">'Mixture'</span><span class="p">))].</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Time'</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>
<span class="n">dfb1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[((</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium caudatum'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Treatment'</span><span class="p">]</span><span class="o">==</span><span class="s">'Mixture'</span><span class="p">))].</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Time'</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">1</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">dfb2</span><span class="p">)]</span>
</code></pre></div></div>

<p>The last four datasets will be the fitted ones,
while the other ones are build in order to have an easy comparison.
We skipped some initial point because we want a similar initial condition
in the monoculture treatment and in the mixed one for each of the two species.
For the sake of convenience, we will assume a step equal to 1 for all the observations, except for the mixed aurelia
above Time equal to 8, where we assume a step equal to 2.
Finally, we will use an integration step of 1/5 in order to ensure 
the convergence of the discretized integration.</p>

<h2 id="fitting-the-data">Fitting the data</h2>

<p>As we anticipated, we will initially only consider the monoculture case,
and we will use the same model of the last post.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s">'specie'</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">].</span><span class="n">drop_duplicates</span><span class="p">()})</span> <span class="k">as</span> <span class="n">model_mono</span><span class="p">:</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'lam'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="s">'specie'</span><span class="p">))</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'kappa'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="s">'specie'</span><span class="p">))</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'nu'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="s">'specie'</span><span class="p">))</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">dn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">n</span><span class="o">*</span><span class="n">lam</span><span class="o">*</span><span class="p">(</span><span class="n">kappa</span><span class="o">-</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">kappa</span>
    <span class="k">def</span> <span class="nf">f_update</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">n</span><span class="o">+</span><span class="n">h</span><span class="o">*</span><span class="n">dn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">)</span>
    <span class="n">mu1</span><span class="p">,</span> <span class="n">update1</span> <span class="o">=</span> <span class="n">pt</span><span class="p">.</span><span class="n">scan</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">f_update</span><span class="p">,</span> 
                     <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">nu</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
                    <span class="n">non_sequences</span><span class="o">=</span><span class="p">[</span><span class="n">lam</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kappa</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_steps</span><span class="p">],</span>
                    <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">dfa1</span><span class="p">))</span>
    <span class="n">mu2</span><span class="p">,</span> <span class="n">update2</span> <span class="o">=</span> <span class="n">pt</span><span class="p">.</span><span class="n">scan</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">f_update</span><span class="p">,</span> 
                     <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">nu</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
                    <span class="n">non_sequences</span><span class="o">=</span><span class="p">[</span><span class="n">lam</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">kappa</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_steps</span><span class="p">],</span>
                    <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">dfa2</span><span class="p">))</span>
    <span class="n">y1</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y1'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu1</span><span class="p">[::</span><span class="n">n_steps</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">dfa1</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">y2</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y2'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu2</span><span class="p">[::</span><span class="n">n_steps</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">dfa2</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">))</span>

<span class="k">with</span> <span class="n">model_mono</span><span class="p">:</span>
    <span class="n">idata_mono</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_mono</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/lotka_volterra/trace_mono.webp" alt="The trace of the monoculture model" /></p>

<p>The trace looks fine, let us inspect the posterior predictive distribution</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model_mono</span><span class="p">:</span>
    <span class="n">idata_mono</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata_mono</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">fill_between</span><span class="p">(</span><span class="n">dfa1</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_mono</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y1'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_mono</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y1'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">dfa1</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_mono</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y1'</span><span class="p">]).</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
       <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="c1"># ax.plot(df_data['Time'], yobs)
</span><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">dfa1</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
               <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">fill_between</span><span class="p">(</span><span class="n">dfa2</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_mono</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y2'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_mono</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y2'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">dfa2</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_mono</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y2'</span><span class="p">]).</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
       <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="c1"># ax.plot(df_data['Time'], yobs)
</span><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">dfa2</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
               <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/lotka_volterra/ppc_mono.webp" alt="The posterior predictive distribution for the monoculture model" /></p>

<p>The data seems compatible with the model fit.
Let us now switch to the combined model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s">'specie'</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">].</span><span class="n">drop_duplicates</span><span class="p">()})</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'lam'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="s">'specie'</span><span class="p">))</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'kappa'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="s">'specie'</span><span class="p">))</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'gamma'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="s">'specie'</span><span class="p">))</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'nu'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="s">'specie'</span><span class="p">))</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">dn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">n</span><span class="o">*</span><span class="n">lam</span><span class="o">*</span><span class="p">(</span><span class="n">kappa</span><span class="o">-</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">kappa</span>
    <span class="k">def</span> <span class="nf">f_update</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">n</span><span class="o">+</span><span class="n">h</span><span class="o">*</span><span class="n">dn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">)</span>
    <span class="n">mu1</span><span class="p">,</span> <span class="n">update1</span> <span class="o">=</span> <span class="n">pt</span><span class="p">.</span><span class="n">scan</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">f_update</span><span class="p">,</span> 
                     <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">nu</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
                    <span class="n">non_sequences</span><span class="o">=</span><span class="p">[</span><span class="n">lam</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kappa</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_steps</span><span class="p">],</span>
                    <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">dfa1</span><span class="p">))</span>
    <span class="n">mu2</span><span class="p">,</span> <span class="n">update2</span> <span class="o">=</span> <span class="n">pt</span><span class="p">.</span><span class="n">scan</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">f_update</span><span class="p">,</span> 
                     <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">nu</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
                    <span class="n">non_sequences</span><span class="o">=</span><span class="p">[</span><span class="n">lam</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">kappa</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_steps</span><span class="p">],</span>
                    <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">dfa2</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">f_update_inter</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">lam1</span><span class="p">,</span> <span class="n">lam2</span><span class="p">,</span> <span class="n">kappa1</span><span class="p">,</span> <span class="n">kappa2</span><span class="p">,</span> <span class="n">gamma1</span><span class="p">,</span> <span class="n">gamma2</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">n1</span><span class="o">+</span><span class="n">h</span><span class="o">*</span><span class="n">n1</span><span class="o">*</span><span class="n">lam1</span><span class="o">*</span><span class="p">(</span><span class="n">kappa1</span><span class="o">-</span><span class="n">n1</span><span class="o">-</span><span class="n">gamma1</span><span class="o">*</span><span class="n">n2</span><span class="p">)</span><span class="o">/</span><span class="n">kappa1</span><span class="p">,</span> <span class="n">n2</span><span class="o">+</span><span class="n">h</span><span class="o">*</span><span class="n">n2</span><span class="o">*</span><span class="n">lam2</span><span class="o">*</span><span class="p">(</span><span class="n">kappa2</span><span class="o">-</span><span class="n">n2</span><span class="o">-</span><span class="n">gamma2</span><span class="o">*</span><span class="n">n1</span><span class="p">)</span><span class="o">/</span><span class="n">kappa2</span><span class="p">)</span>

    <span class="n">mu_inter</span><span class="p">,</span> <span class="n">update_inter</span> <span class="o">=</span> <span class="n">pt</span><span class="p">.</span><span class="n">scan</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">f_update_inter</span><span class="p">,</span> 
                     <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">nu</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nu</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
                    <span class="n">non_sequences</span><span class="o">=</span><span class="p">[</span><span class="n">lam</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lam</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">kappa</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kappa</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">gamma</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">gamma</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_steps</span><span class="p">],</span>
                    <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">dfb1_all</span><span class="p">))</span>
    
    <span class="n">y1</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y1'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu1</span><span class="p">[::</span><span class="n">n_steps</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">observed</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">dfa1</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">y2</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y2'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu2</span><span class="p">[::</span><span class="n">n_steps</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">observed</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">dfa2</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">y1n</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y1n'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu_inter</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">dfb1</span><span class="p">):</span><span class="n">n_steps</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">observed</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">dfb1</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">y1nall</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y1nall'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu_inter</span><span class="p">[</span><span class="mi">0</span><span class="p">][::</span><span class="n">n_steps</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">y2e</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y2e'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu_inter</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">dfb2</span><span class="p">[</span><span class="n">target</span><span class="p">])::</span><span class="mi">2</span><span class="o">*</span><span class="n">n_steps</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">y2n</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y2n'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu_inter</span><span class="p">[</span><span class="mi">1</span><span class="p">][:</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">dfb2</span><span class="p">[</span><span class="n">target</span><span class="p">]):</span><span class="n">n_steps</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">observed</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">dfb2</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">))</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'kappa'</span><span class="p">,</span> <span class="s">'lam'</span><span class="p">,</span> <span class="s">'nu'</span><span class="p">,</span> <span class="s">'gamma'</span><span class="p">,</span> <span class="s">'sigma'</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/lotka_volterra/trace.webp" alt="The trace of the combined model" /></p>

<p>Also in this case the traces are fine.
Before moving to the posterior predictive check, we can verify if the relevant common
parameters between the two models are compatible.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_forest</span><span class="p">([</span><span class="n">idata_mono</span><span class="p">,</span> <span class="n">idata</span><span class="p">],</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'lam'</span><span class="p">,</span> <span class="s">'kappa'</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/lotka_volterra/forest.webp" alt="" /></p>

<p>The parameters are almost identical. 
On the one hand, this is a good indication that the parameters
are proper of the specie and of the environment and do not depend on the
other species. On the other, we should keep in mind that in the case of mixed
species, the observations looks much more noisy than in the monoculture case,
and this might hide the presence of a change in the values of the parameters,
so we don’t consider the conclusion as too robust.</p>

<p>Let us now inspect the posterior predictive distribution.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata</span><span class="p">))</span>

<span class="n">y2mean</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y2n'</span><span class="p">]).</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'y2e'</span><span class="p">]).</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">))])</span>
<span class="n">y2l</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y2n'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'y2e'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">))])</span>
<span class="n">y2h</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y2n'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'y2e'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">))])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">fill_between</span><span class="p">(</span><span class="n">dfa1</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y1'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y1'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">dfa1</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y1'</span><span class="p">]).</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
       <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="c1"># ax.plot(df_data['Time'], yobs)
</span><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">dfa1</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
               <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">fill_between</span><span class="p">(</span><span class="n">dfa2</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y2'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y2'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">dfa2</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y2'</span><span class="p">]).</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
       <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="c1"># ax.plot(df_data['Time'], yobs)
</span><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">dfa2</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
               <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>


<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">fill_between</span><span class="p">(</span><span class="n">dfb1_all</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'y1nall'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'y1nall'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">dfb1_all</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'y1nall'</span><span class="p">]).</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
       <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="c1"># ax.plot(df_data['Time'], yobs)
</span><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">dfb1_all</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
               <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">dfb1</span><span class="p">[</span><span class="s">'Time'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'grey'</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">fill_between</span><span class="p">(</span><span class="n">t2all</span><span class="p">,</span> <span class="n">y2l</span><span class="p">,</span> <span class="n">y2h</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">dfb2_all</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="n">y2mean</span><span class="p">,</span>
       <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">dfb2</span><span class="p">[</span><span class="s">'Time'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'grey'</span><span class="p">)</span>
<span class="c1"># ax.plot(df_data['Time'], yobs)
</span><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">dfb2_all</span> <span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
               <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/lotka_volterra/ppc.webp" alt="The posterior predictive check for the combined model" /></p>

<p>The grey dashed line represents the last fitted point, and we see that we have a very
nice agreement both in the fitted region, both in the predicted region.</p>

<h2 id="conclusions">Conclusions</h2>

<p>In this example, we tried and use PyMC to show how we could test Gause’s hypothesis,
and we used a numerical algorithm to solve the Lotka-Volterra model to do so.
The Lotka-Volterra model seems to be appropriate in describing the observed data,
but of course this is just one experiment, and many more would be needed (and have already
been done) do draw some sensible conclusion.</p>

<h2 id="suggested-readings">Suggested readings</h2>

<ul>
  <li>Gause, G. F. (2019). The Struggle for Existence: A Classic of Mathematical Biology and Ecology. Dover Publications.</li>
  <li><a href="http://numerical.recipes/oldverswitcher.html">Press, W. H. (2007). Numerical Recipes 3rd Edition: The Art of Scientific Computing. Cambridge University Press.</a></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Thu Aug 29 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.5
<br />
IPython version      : 8.24.0
<br />

<br />
xarray : 2024.5.0
<br />
numpyro: 0.15.0
<br />
jax    : 0.4.28
<br />
jaxlib : 0.4.28
<br />

<br />
pytensor  : 2.25.3
<br />
pyreadr   : 0.5.2
<br />
pymc      : 5.16.2
<br />
matplotlib: 3.9.0
<br />
seaborn   : 0.13.2
<br />
arviz     : 0.18.0
<br />
pandas    : 2.2.2
<br />
numpy     : 1.26.4
<br />

<br />
Watermark: 2.4.3
<br />
</div>]]></content><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><category term="/statistics/" /><category term="/mrp/" /><summary type="html"><![CDATA[Testing the predictive power of a scientific model]]></summary></entry><entry><title type="html">Differential equations</title><link href="http://localhost:4000/statistics/ode" rel="alternate" type="text/html" title="Differential equations" /><published>2026-02-27T00:00:00+00:00</published><updated>2026-02-27T00:00:00+00:00</updated><id>http://localhost:4000/statistics/ode</id><content type="html" xml:base="http://localhost:4000/statistics/ode"><![CDATA[<p>Few days ago I started reading
Gause’s book <a href="https://www.google.it/books/edition/The_Struggle_for_Existence/zQegDwAAQBAJ?hl=it&amp;gbpv=1&amp;dq=The+Struggle+for+Existence:+A+Classic+of+Mathematical+Biology+and+Ecology&amp;printsec=frontcover">The Struggle for Existence: A Classic of Mathematical Biology and Ecology</a>.
It’s a beautiful textbook on mathematical ecology, and even if its almost 100 years old
and some concepts might be outdated, I think it contains many useful
examples which explain how science works, or at least should work.</p>

<p>The textbook contains many applications of the Lotka-Volterra model to 
systems with competing resources.
There are many beautiful figures, and all the data
has been exported in <a href="https://github.com/adamtclark/gauseR/">this amazing GitHub repo</a> <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>.</p>

<p>I therefore decided to look at the Lotka-Volterra model, and I started with the
simplest example: the one specie case.
This model describes the number of individuals of a species.
When there are many resources, the individuals reproduce themselves,
and the model assumes that</p>

\[\frac{dN(t)}{dt} \approx \lambda N\]

<p>The solution of the above differential equation is</p>

\[N(t) = N_0 e^{\lambda t}\]

<p>and this diverges as $t$ grows, but since the
number of units cannot however grow indefinitely, as there is a limited amount
of space and resources.
We therefore define the maximum number of units as $K$, and we can modify
the above differential equation into the following one</p>

\[\frac{dN(t)}{dt} = \lambda N (1-\frac{N}{K})\]

<p>If $N \ll K$ we recover back the exponential growth, but if $N$
approaches $K$ then we have $\frac{dN(t)}{dt} \rightarrow 0\,,$
as required.</p>

<p>The above differential equation is known as the logistic differential equation,
and you already encountered its solution when we discussed the GLM model,
but since it’s better to start with the simplest model as possible, I first tried to implement
this model before moving to the version of the equations with more than one specie.</p>

<p>When you implement a numerical algorithm there are many things which might go
wrong, as you might have missed a factor 2, or your choice for some
parameter might have introduced some instability.
It is therefore a very good habit to verify that everything works by 
comparing the algorithm solution with the analytic one for some solvable
problem.</p>

<p>By keeping this in mind,
we will compare the numerical solution with the analytic one, and as shown
<a href="https://mathworld.wolfram.com/LogisticEquation.html">here</a>
this reads</p>

\[N(t) = \frac{k N_0 e^{\lambda t}}{k + N_0 (e^{\lambda t}-1)}\,.\]

<p>We will use the simplest numerical integration method as possible, namely the Euler method.
Given a differential equation</p>

\[\begin{cases}
&amp;
y'(x) = G(y(x), x)
\\
&amp;
y(0) = y_0
\\
\end{cases}\]

<p>and using the first order Taylor expansion of $y(x)$ around $x_n$ (we are assuming
the existence of a smooth solution around $x_n$)</p>

\[y(x_{n+1}) = y(x_n) + y'(x_n)(x_{n+1}-x_n)  + O\left( \left( x_{n+1}-x_n \right)^2 \right)\]

<p>our numerical solution will read</p>

\[y_{n+1} = y_n + (x_{n+1}-x_n)G(y_n, x_n) + O\left( \left( x_{n+1}-x_n \right)^2 \right)\,.\]

<p>There are algorithms which are much more stable and efficients,
but in order to understand how to perform the numerical integration of an ODE
with PyMC it is sufficient to start from this method.</p>

<p>There is more than one method which you might use to perform the integration,
and most of them are explained in <a href="https://www.pymc.io/projects/examples/en/latest/ode_models/ODE_Lotka_Volterra_multiple_ways.html">this very nice tutorial</a>.
We will stick to the <strong>scan</strong> method, which relies on pytensor’s <a href="https://pytensor.readthedocs.io/en/latest/library/scan.html">scan function</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pyreadr</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pytensor</span> <span class="k">as</span> <span class="n">pt</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">df_0</span> <span class="o">=</span> <span class="n">pyreadr</span><span class="p">.</span><span class="n">read_r</span><span class="p">(</span><span class="s">'data/gause_1934_book_f21.rda'</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df_0</span><span class="p">[</span><span class="s">'gause_1934_book_f21'</span><span class="p">]</span>

<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">Paper</th>
      <th style="text-align: right">Figure</th>
      <th style="text-align: left">Species</th>
      <th style="text-align: right">Time</th>
      <th style="text-align: right">Volume</th>
      <th style="text-align: right">Individuals</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">21</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">3.13485</td>
      <td style="text-align: right">nan</td>
      <td style="text-align: right">21.0211</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">21</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">4.12251</td>
      <td style="text-align: right">nan</td>
      <td style="text-align: right">20.8853</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">21</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">5.0356</td>
      <td style="text-align: right">nan</td>
      <td style="text-align: right">30.6607</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">21</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">6.0962</td>
      <td style="text-align: right">nan</td>
      <td style="text-align: right">53.6171</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">21</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">7.08101</td>
      <td style="text-align: right">nan</td>
      <td style="text-align: right">111.237</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[((</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s">'Individuals'</span><span class="p">].</span><span class="n">isna</span><span class="p">())</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium aurelia'</span><span class="p">))].</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">'Time'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Individuals'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/paramecium.webp" alt="" /></p>

<p>Le logistic behavior in the dataset is quite evident.
It looks like the time step is always close to 1, let us see if we can approximate the integration step as constant</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">].</span><span class="n">diff</span><span class="p">().</span><span class="n">dropna</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nb">max</span><span class="p">()</span>
</code></pre></div></div>

<div class="code">
0.10359150000000028
</div>

<p>It looks like assuming equally space data is not too bad.
The integration step should be small enough to ensure that the error is not too large,
we will therefore assume $h = 1/5\,.$
As we will see, this is a small enough choice, but I invite you to try with a smaller step
and verify if everything is OK.
We also scaled the data so that the fitted value is not too large for the numerical integration.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">5</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'lam'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'kappa'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'nu'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">f_update</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>  <span class="c1"># this function implements the Euler method
</span>        <span class="k">return</span> <span class="n">n</span><span class="o">+</span><span class="n">n</span><span class="o">*</span><span class="n">h</span><span class="o">*</span><span class="n">lam</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">n</span><span class="o">/</span><span class="n">kappa</span><span class="p">)</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">update</span> <span class="o">=</span> <span class="n">pt</span><span class="p">.</span><span class="n">scan</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">f_update</span><span class="p">,</span>  <span class="c1"># The updating function
</span>                     <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">nu</span><span class="p">],</span>  <span class="c1"># The initial condition
</span>                    <span class="n">non_sequences</span><span class="o">=</span><span class="p">[</span><span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_steps</span><span class="p">],</span>  <span class="c1"># The list of arguments
</span>                    <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">yobs</span><span class="p">))</span>  <span class="c1"># The number of steps
</span>    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">[::</span><span class="n">n_steps</span><span class="p">],</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div></div>

<p>Since it is hard to guess a reasonable value for the parameters, it is better to take
a look at the prior predictive distribution</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">pr_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_prior_predictive</span><span class="p">()</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">az</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="n">pr_pred</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s">'prior_predictive'</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'y'</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">).</span><span class="n">T</span><span class="p">:</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">elem</span><span class="p">.</span><span class="n">values</span><span class="p">))</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/prior_predictive.webp" alt="" /></p>

<p>The parameters look fine, there is a fast enough growth, the limit number is large enough
and the initial value covers a wide enough region.
We can now fit the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/trace_0.webp" alt="" /></p>

<p>The traces look perfect, we can now inspect the posterior predictive.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata</span><span class="p">))</span>
    
<span class="k">def</span> <span class="nf">fexact</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">k</span><span class="o">*</span><span class="n">y0</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lam</span><span class="o">*</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span><span class="n">y0</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lam</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">y</span>

<span class="n">dt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">fexact</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'nu'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'lam'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'kappa'</span><span class="p">].</span><span class="n">mean</span><span class="p">().</span><span class="n">values</span><span class="p">)</span> 
               <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_data</span><span class="p">))])</span>

<span class="n">ypl</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="mi">100</span><span class="o">*</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
       <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="n">ypl</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Individuals'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/pp_0.webp" alt="" /></p>

<p>The numerical solution is identical to the analytic one, so our ODE solver does
a very good job.
The average looks fine, but the model provides a credible interval below 0,
and this makes no sense since the number of individuals is a positive quantity.
We can easily fix the above model by fitting the logarithm of the
number of individuals</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_improved</span><span class="p">:</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'lam'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'kappa'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'nu'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">f_update</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">n</span><span class="o">+</span><span class="n">n</span><span class="o">*</span><span class="n">h</span><span class="o">*</span><span class="n">lam</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">n</span><span class="o">/</span><span class="n">kappa</span><span class="p">)</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">update</span> <span class="o">=</span> <span class="n">pt</span><span class="p">.</span><span class="n">scan</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">f_update</span><span class="p">,</span> 
                     <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">nu</span><span class="p">],</span>
                    <span class="n">non_sequences</span><span class="o">=</span><span class="p">[</span><span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_steps</span><span class="p">],</span>
                    <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">yobs</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu</span><span class="p">[::</span><span class="n">n_steps</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">yobs</span><span class="o">/</span><span class="mi">100</span><span class="p">))</span>

<span class="k">with</span> <span class="n">model_improved</span><span class="p">:</span>
    <span class="n">idata_improved</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span>
                               <span class="n">draws</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_improved</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/trace_1.webp" alt="" /></p>

<p>Also in this case the trace is fine. What about the posterior predictive?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model_improved</span><span class="p">:</span>
    <span class="n">idata_improved</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata_improved</span><span class="p">))</span>

<span class="n">dt_new</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">fexact</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'nu'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'lam'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'kappa'</span><span class="p">].</span><span class="n">mean</span><span class="p">().</span><span class="n">values</span><span class="p">)</span> 
                   <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_data</span><span class="p">))])</span>

<span class="n">ypl_new</span> <span class="o">=</span> <span class="n">dt_new</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">]).</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
       <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="n">ypl_new</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Individuals'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/pp_1.webp" alt="" /></p>

<p>These error bars make much more sense than the previous ones, and we consider
this model better than the previous one.
Notice that we might decide to perform a model comparison between the two models,
but I personally don’t consider this as a necessary step, since
we didn’t modify the model because the fit was bad, but rather because
it did not fulfill the positivity constraint.</p>

<h2 id="conclusions">Conclusions</h2>

<p>With the help of pytensor’s scan function, implementing Euler algorithm has been
straightforward, and the extension to any other solver is immediate.
We applied this method to numerically integrate the logistic equation,
and we applied it to an example from Gause’s textbook.
We have also seen a little trick to impose the positivity of the solution
and make the credible intervals more reasonable.</p>

<h2 id="suggested-readings">Suggested readings</h2>

<ul>
  <li>Gause, G. F. (2019). The Struggle for Existence: A Classic of Mathematical Biology and Ecology. Dover Publications.</li>
  <li><a href="http://numerical.recipes/oldverswitcher.html">Press, W. H. (2007). Numerical Recipes 3rd Edition: The Art of Scientific Computing. Cambridge University Press.</a></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Wed Aug 28 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />

<br />
xarray : 2024.5.0
<br />
numpyro: 0.15.0
<br />
jax    : 0.4.28
<br />
jaxlib : 0.4.28
<br />

<br />
pymc      : 5.16.2
<br />
seaborn   : 0.13.2
<br />
matplotlib: 3.9.0
<br />
pyreadr   : 0.5.2
<br />
arviz     : 0.18.0
<br />
numpy     : 1.26.4
<br />
pytensor  : 2.25.3
<br />
pandas    : 2.2.2
<br />

<br />
Watermark: 2.4.3
<br />
</div>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>The Python community is amazing, but the R community is great too, especially when we talk about sharing data. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><category term="/statistics/" /><category term="/mrp/" /><summary type="html"><![CDATA[When your mathematical model cannot be explicitly solved]]></summary></entry><entry><title type="html">Dirichlet Process Mixture Models</title><link href="http://localhost:4000/statistics/dp" rel="alternate" type="text/html" title="Dirichlet Process Mixture Models" /><published>2026-02-20T00:00:00+00:00</published><updated>2026-02-20T00:00:00+00:00</updated><id>http://localhost:4000/statistics/dp</id><content type="html" xml:base="http://localhost:4000/statistics/dp"><![CDATA[<p>In <a href="/statistics/mixture">a previous post</a> we discussed parametric mixture models,
which are mixture models where the number of components are fixed.
These models are more flexible than the respective one-component model,
but there are situations in which this flexibility is not enough, since one does not
know in advance the number of components to take.</p>

<p>One could naively try and assume a large number of components in a mixture model,
unfortunately this is not a good idea, as the behavior of the Dirichlet distribution
is ill-defined as the number of components $K$ diverges.</p>

<p>Dirichlet Processes Mixture Models, or DPMMs, are the appropriate way to generalize mixture
models, as the limit $K \rightarrow \infty$ is well-defined.
Here we will only give an intuitive justification to DPs, and the interested
reader will find a more formal discussion in the bibliography.
Rather than assuming</p>

\[\pi \vert \alpha \sim \mathcal{Dir}(\alpha,\dots, \alpha)\]

<p>one simply has to assume</p>

\[\pi \vert \alpha \sim \mathcal{Dir}(\alpha/K,\dots, \alpha/K)\,.\]

<p>While this behavior is well-defined from a theoretical point of view,
it is not a good idea to implement the above formula in order to sample the
prior distribution, since this method is prone to numerical errors as $K$ grows.
The most reliable way, at the moment, to sample from a DP, is to use the <strong>stick breaking process</strong></p>

\[\begin{align*}
\theta_1,\dots,\theta_K \sim &amp; B(1, \alpha) \\
\pi_1 = &amp; \theta_1 \\
\pi_i = &amp; \theta_i \prod_{j&lt;i} (1-\theta_j)
\end{align*}\]

<p>DPMMs have been extensively applied to many fields, and they are currently very popular
in the text classification, as the number of topics is generally not previously known.</p>

<h2 id="application-to-the-in-home-geriatric-assessment-dataset">Application to the In-Home Geriatric Assessment dataset</h2>

<p>In this section we will apply DPMMs to the IHGA dataset,
as already done in <a href="https://www.cs.princeton.edu/courses/archive/fall09/cos597A/papers/KKD2008.pdf">this study</a>.
In the randomized clinical trial, a set of 572 elderly people has been
randomly assigned to one of two groups. The control group, made of 287 units,
received the standard health care, while the remaining units received the standard health care
plus an experimental preventive treatment.
The number of hospitalizations for the individuals has been therefore been monitored
for two years.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">Hospitalizations</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">Control</td>
      <td>138</td>
      <td>77</td>
      <td>46</td>
      <td>12</td>
      <td>8</td>
      <td>4</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <td style="text-align: right">Treatment</td>
      <td>147</td>
      <td>83</td>
      <td>37</td>
      <td>13</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>As in the cited document, we will use a DPMM, but we will use an uninformative Gamma prior
for the average number of hospitalizations, adapting the model
proposed in <a href="https://www.pymc.io/projects/examples/en/latest/mixture_models/dp_mix.html">this PyMC example</a>
to our needs.
We will assume two identical models for the test group and for the control one,
and we will then compare the number of hospitalizations averaged over the sample
in order to assess the effectiveness of the treatment.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">statsmodels</span> <span class="k">as</span> <span class="n">sm</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">n_control</span> <span class="o">=</span> <span class="p">[</span><span class="mi">138</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="mi">46</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="n">nhosp_control</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">elem</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">elem</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_control</span><span class="p">)],[])</span>

<span class="n">n_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">147</span><span class="p">,</span> <span class="mi">83</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">nhosp_test</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">elem</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">elem</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_test</span><span class="p">)],[])</span>

<span class="n">K</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_c</span><span class="p">:</span>
    <span class="n">alpha_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s">"alpha_c"</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">w_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">StickBreakingWeights</span><span class="p">(</span><span class="s">'w_c'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_c</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">lam_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s">"lam_c"</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">))</span>
    <span class="n">y_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Mixture</span><span class="p">(</span>
        <span class="s">"y_c"</span><span class="p">,</span> <span class="n">w_c</span><span class="p">,</span> <span class="n">pm</span><span class="p">.</span><span class="n">Poisson</span><span class="p">.</span><span class="n">dist</span><span class="p">(</span><span class="n">lam_c</span><span class="p">),</span> <span class="n">observed</span><span class="o">=</span><span class="n">nhosp_control</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_t</span><span class="p">:</span>
    <span class="n">alpha_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s">"alpha_t"</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">w_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">StickBreakingWeights</span><span class="p">(</span><span class="s">'w_t'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_t</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">lam_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s">"lam_t"</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">))</span>
    <span class="n">y_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Mixture</span><span class="p">(</span>
        <span class="s">"y_t"</span><span class="p">,</span> <span class="n">w_t</span><span class="p">,</span> <span class="n">pm</span><span class="p">.</span><span class="n">Poisson</span><span class="p">.</span><span class="n">dist</span><span class="p">(</span><span class="n">lam_t</span><span class="p">),</span> <span class="n">observed</span><span class="o">=</span><span class="n">nhosp_test</span>
    <span class="p">)</span>

<span class="k">with</span> <span class="n">model_c</span><span class="p">:</span>
    <span class="n">idata_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span>
                        <span class="n">draws</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="k">with</span> <span class="n">model_t</span><span class="p">:</span>
    <span class="n">idata_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span>
                        <span class="n">draws</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</code></pre></div></div>

<p>We can now inspect the traces of our models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_c</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/dp/trace_c.webp" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_t</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/dp/trace_t.webp" alt="" /></p>

<p>There are few divergences, but this is not a big issue.
This is quite normal, as sampling from a DP is numerically demanding
due to the large correlations of the weights.</p>

<p>We can now verify if our models can reproduce the observed data</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model_c</span><span class="p">:</span>
    <span class="n">idata_c</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata_c</span><span class="p">))</span>

<span class="k">with</span> <span class="n">model_t</span><span class="p">:</span>
    <span class="n">idata_t</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata_t</span><span class="p">))</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">az</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="n">idata_t</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s">'posterior_predictive'</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'y_t'</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">).</span><span class="n">T</span><span class="p">:</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s">'step'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
           <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">nhosp_test</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s">'step'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Test group'</span><span class="p">)</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">az</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="n">idata_c</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s">'posterior_predictive'</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'y_c'</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">).</span><span class="n">T</span><span class="p">:</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s">'step'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
           <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">nhosp_control</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s">'step'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Control group'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/dp/ppc.webp" alt="The PPC of our models" /></p>

<p>The agreement is more than satisfactory, but it is hard to assess which model
is better by simply looking at the above figures.
We can however easily compare the distributions of the number of hospitalizations
averaged over the individuals.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mu_t</span> <span class="o">=</span> <span class="n">idata_t</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y_t'</span><span class="p">].</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'y_t_dim_2'</span><span class="p">)).</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">mu_c</span> <span class="o">=</span> <span class="n">idata_c</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y_c'</span><span class="p">].</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'y_c_dim_2'</span><span class="p">)).</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">mu_t</span><span class="o">/</span><span class="n">mu_c</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">'$\mu_t/\mu_c$'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/dp/mu_ratio.webp" alt="The ratio of the average number of hospitalizations" /></p>

<p>We are therefore quite confident in concluding that the treatment group has an average number of hospitalizations
than the control group.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We have seen how DPMMs generalize Dirichlet Mixtures to an unknown number of components,
and we have seen an application of this kind of model to the IHGA dataset.</p>

<h2 id="suggested-readings">Suggested readings</h2>
<ul>
  <li><cite>Müller, P., Quintana, F. A., Jara, A., Hanson, T. (2015). Bayesian Nonparametric Data Analysis. Springer International Publishing.</cite></li>
  <li><cite>Milovan Krnjajić, Athanasios Kottas, David Draper,  Parametric and nonparametric Bayesian model specification: A case study involving models for count data,  Computational Statistics &amp; Data Analysis,  Volume 52, Issue 4,  2008,</cite></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Thu Aug 22 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />

<br />
xarray : 2024.5.0
<br />
numpyro: 0.15.0
<br />
jax    : 0.4.28
<br />
jaxlib : 0.4.28
<br />

<br />
arviz      : 0.18.0
<br />
numpy      : 1.26.4
<br />
seaborn    : 0.13.2
<br />
pandas     : 2.2.2
<br />
matplotlib : 3.9.0
<br />
pymc       : 5.15.0
<br />
statsmodels: 0.14.2
<br />

<br />
Watermark: 2.4.3
<br />
</div>]]></content><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><category term="/statistics/" /><category term="/nonparametric_intro/" /><summary type="html"><![CDATA[Mixture models with variable number of components]]></summary></entry><entry><title type="html">Bayesian Additive Regression Trees</title><link href="http://localhost:4000/statistics/bart" rel="alternate" type="text/html" title="Bayesian Additive Regression Trees" /><published>2026-02-13T00:00:00+00:00</published><updated>2026-02-13T00:00:00+00:00</updated><id>http://localhost:4000/statistics/bart</id><content type="html" xml:base="http://localhost:4000/statistics/bart"><![CDATA[<p>BART is a black box Bayesian method proposed in 2010 to approximate functions, and it can be useful when
you need to interpolate your data, but it is hard to figure out a transparent way to do so.
BART assumes</p>

\[Y \sim f(X) + \varepsilon\]

<p>where $\varepsilon$ is normally distributed, and</p>

\[f(X) = \sum_i g_i(X, T_i, M_i)\]

<p>Here $T_i$ represents a binary tree, and $M_i$ the set of means associated to $T_i$
In practice, a binary tree can be seen as a set of if-else, and an example is</p>

\[g_0 =
\begin{cases}
X &lt; c_1 &amp; \mu_1 \\
X \geq c_1 &amp; 
\begin{cases}
X &lt; c_2 &amp; \mu_2 \\
X \geq c_2 &amp; \mu_3 \\
\end{cases}
\\
\end{cases}\]

<p>Bart is a Bayesian method because both $T_i$ and $M_i$ are regularized by using priors.
For a more in-depth discussion about BARTs, you can take a look at 
<a href="https://arxiv.org/pdf/2206.03619">this preprint</a>
or at the <a href="https://www.pymc.io/projects/bart/en/latest/index.html">PyMC-BART homepage</a>.</p>

<h2 id="the-diamond-dataset">The diamond dataset</h2>

<p>We will use BART to fit the diamond dataset, which is dataset proposed
in <a href="https://www.tandfonline.com/doi/full/10.1080/10691898.2001.11910659">this article</a>
to show some of the main issues you will have to deal with when fitting
real-World datasets.
I strongly encourage you to read this article, as it is a very instructive example
of some of the issues most data scientist faced when working to real problems.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">pymc_bart</span> <span class="k">as</span> <span class="n">pmb</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Diamond.csv'</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: right">rownames</th>
      <th style="text-align: right">carat</th>
      <th style="text-align: left">colour</th>
      <th style="text-align: left">clarity</th>
      <th style="text-align: left">certification</th>
      <th style="text-align: right">price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">0.3</td>
      <td style="text-align: left">D</td>
      <td style="text-align: left">VS2</td>
      <td style="text-align: left">GIA</td>
      <td style="text-align: right">1302</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">2</td>
      <td style="text-align: right">0.3</td>
      <td style="text-align: left">E</td>
      <td style="text-align: left">VS1</td>
      <td style="text-align: left">GIA</td>
      <td style="text-align: right">1510</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">3</td>
      <td style="text-align: right">0.3</td>
      <td style="text-align: left">G</td>
      <td style="text-align: left">VVS1</td>
      <td style="text-align: left">GIA</td>
      <td style="text-align: right">1510</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">4</td>
      <td style="text-align: right">0.3</td>
      <td style="text-align: left">G</td>
      <td style="text-align: left">VS1</td>
      <td style="text-align: left">GIA</td>
      <td style="text-align: right">1260</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">5</td>
      <td style="text-align: right">0.31</td>
      <td style="text-align: left">D</td>
      <td style="text-align: left">VS1</td>
      <td style="text-align: left">GIA</td>
      <td style="text-align: right">1641</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'carat'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/bart/price.webp" alt="" /></p>

<p>As we can see, it appears that the relation between carat number and price
is non-linear, and the price also looks heteroscedastic with respect to the price.
We will use BART both the mean and the variance of a normal distribution.
First of all, let us convert the categorical variables into a meaningful way:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'colour'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
               <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'clarity'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
               <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'certification'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
               <span class="n">df</span><span class="p">[</span><span class="s">'carat'</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">yobs</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span><span class="o">/</span><span class="mi">1000</span>
</code></pre></div></div>

<p>We also scaled the observations in order to simplify the work to the algorithms.
We can now implement the model as follows</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s">'obs'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="s">'cols'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">})</span> <span class="k">as</span> <span class="n">model_carat</span><span class="p">:</span>
    <span class="n">Xv</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Data</span><span class="p">(</span><span class="s">'Xv'</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">pmb</span><span class="p">.</span><span class="n">BART</span><span class="p">(</span><span class="s">"w"</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">Xv</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">yobs</span><span class="p">),</span> <span class="n">m</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">yobs</span><span class="p">)))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">"y"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="p">)</span>

<span class="k">with</span> <span class="n">model_carat</span><span class="p">:</span>
    <span class="n">idata</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">draws</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/bart/trace.webp" alt="The trace of the BART model" /></p>

<p>It is really hard to verify if there is any numerical issue with the sampling.
It is in fact generally recommended to only use it for the non-BART part of the
model, which is absent here.
PyMC-BART comes in fact with its own routines for the convergence assessment.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pmb</span><span class="p">.</span><span class="n">plot_convergence</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">var_name</span><span class="o">=</span><span class="s">'w'</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/bart/pmb_trace.webp" alt="The trace of the BART model
using PyMC-BART" /></p>

<p>The curves in the left-hand plot are entirely above the dashed line,
while the ones in the right-hand figure are mostly below the corresponding
dashed line, and this tells us that our computation can be considered as reliable.</p>

<p>Notice that we haven’t used numpyro as usual, as we cannot use it together
with PyMC-BART.
This is however not a problem, since PyMC is fast enough.</p>

<p>We can now inspect the posterior predictive distribution</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">posterior_mean</span> <span class="o">=</span> <span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">"w"</span><span class="p">].</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">"chain"</span><span class="p">,</span> <span class="s">"draw"</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">w_hdi</span> <span class="o">=</span> <span class="n">az</span><span class="p">.</span><span class="n">hdi</span><span class="p">(</span><span class="n">ary</span><span class="o">=</span><span class="n">idata</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s">"posterior"</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">"w"</span><span class="p">],</span> <span class="n">hdi_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="k">with</span> <span class="n">model_carat</span><span class="p">:</span>
    <span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata</span><span class="p">)</span>

<span class="n">pps</span> <span class="o">=</span> <span class="n">az</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span>
    <span class="n">ppc</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s">"posterior_predictive"</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">"y"</span><span class="p">]</span>
<span class="p">).</span><span class="n">T</span>

<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">Xv</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_hdi</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'carat'</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">pps</span><span class="p">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">hdi_prob</span><span class="o">=</span><span class="mf">0.90</span><span class="p">,</span>
    <span class="n">fill_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">"alpha"</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span> <span class="s">"label"</span><span class="p">:</span> <span class="sa">r</span><span class="s">"Observations $90\%$ HDI"</span><span class="p">},</span>
<span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'carat'</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">posterior_mean</span><span class="p">.</span><span class="n">values</span><span class="p">),</span>
    <span class="n">marker</span><span class="o">=</span><span class="s">'x'</span>
<span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'carat'</span><span class="p">],</span> <span class="n">yobs</span><span class="p">)</span>
<span class="c1"># ax.plot(df["youtube"], df["sales"], "o", c="C0", label="Raw Data")
</span><span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"upper left"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/bart/ppc.webp" alt="" /></p>

<p>Except from few extreme cases, our model seems appropriate to describe the observed price.
We can also assess the variable importance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">pmb</span><span class="p">.</span><span class="n">plot_variable_importance</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">"VI"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/bart/variable_importance.webp" alt="The variable importance plot" /></p>

<p>We can finally visualize the marginal dependence of the model on the single variables</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pmb</span><span class="p">.</span><span class="n">plot_pdp</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">yobs</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">grid</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">var_discrete</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">14</span><span class="p">)))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/bart/plot_pdb.webp" alt="The marginal dependence plot" /></p>

<h2 id="conclusions">Conclusions</h2>
<p>We introduced BARTs, and we showed how to use them in PyMC by applying them
to the diamonds dataset.</p>

<h2 id="suggested-readings">Suggested readings</h2>
<ul>
  <li><cite>Quiroga, M., Garay, P.G., Alonso, J.M., Loyola, J.M., &amp; Martin, O.A. (2022). Bayesian additive regression trees for probabilistic programming.</cite></li>
  <li><cite>Chu, Singfat. (2001). Pricing the C’s of Diamond Stones. Journal of Statistics Education. 9. 10.1080/10691898.2001.11910659. </cite></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span>
</code></pre></div></div>

<div class="code">
Last updated: Wed Aug 21 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />

<br />
xarray: 2024.5.0
<br />

<br />
arviz     : 0.18.0
<br />
numpy     : 1.26.4
<br />
pandas    : 2.2.2
<br />
pymc      : 5.15.0
<br />
seaborn   : 0.13.2
<br />
matplotlib: 3.9.0
<br />
pymc_bart : 0.5.14
<br />

<br />
Watermark: 2.4.3
<br />
</div>]]></content><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><category term="/statistics/" /><category term="/nonparametric_intro/" /><summary type="html"><![CDATA[Flexible interpolation with regression trees]]></summary></entry><entry><title type="html">Splines</title><link href="http://localhost:4000/statistics/spline" rel="alternate" type="text/html" title="Splines" /><published>2026-02-06T00:00:00+00:00</published><updated>2026-02-06T00:00:00+00:00</updated><id>http://localhost:4000/statistics/spline</id><content type="html" xml:base="http://localhost:4000/statistics/spline"><![CDATA[<p>GPs are very flexible, but their implementation becomes tricky when the number of points
grows too much.
If you are experiencing this kind of issue when performing regression, a possible alternative
is to use splines.</p>

<p>Splines are piecewise-defined functions, appropriately matched in order to ensure smoothness
to the resulting function.
There are many spline families, and we will focus on B-splines, as they are very easy to implement
and numerically very stable (while this might not be true for other kind of splines such
as polynomial splines).
You will find more on this topic on the
<a href="https://www.pymc.io/projects/examples/en/latest/howto/spline.html">PyMC gallery</a>,
where the PyMC team used <a href="https://patsy.readthedocs.io/en/latest/">Patsy</a>
to implement the splines.
We will instead do it from scratch, as it might be instructive to see how
to do so.</p>

<p>Given a set of $m+1$ points named <strong>knots</strong> $t_0,t_1,\dots,t_m\,,$ B-splines
are recursively defined:</p>

\[B_{i,0}(t)
= 
\begin{cases}
1 &amp; t_i \leq t &lt; t_{i+1} \\
0 &amp; otherwise \\
\end{cases}\]

<p>One can then define higher order splines as</p>

\[B_{i,p}(t) = \frac{t-t_i}{t_{i+p}-t_i} B_{i,p-1}(t) +
\frac{t_{i+p+1}-t}{t_{i+p+1}-t_{i+1}} B_{i+1,p-1}(t)\]

<p>We can therefore search for our target function by expanding it in terms of B-splines
of order $p$</p>

\[f(t) = \sum_i  \alpha_i B_{i, p}(t)\]

<h2 id="the-fev-dataset">The FEV dataset</h2>

<p>We will use B-spline to perform non-parametric regression on the “Six Cities Study of Air Pollution and Health”
from “Applied Longitudinal Analysis”, which  can be found on <a href="https://content.sph.harvard.edu/fitzmaur/ala2e/">the book webpage</a>.
This dataset is a subsample of the measures of the Forced Expiratory Volume (FEV), expressed in liters,
for 300 girls living in the Topeka city, with age ranging from 6 to 19.
Our aim will be to determine the relation between the age and the FEV (logarithm).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_stata</span><span class="p">(</span><span class="s">'data/fev1.dta'</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">df</span><span class="p">[</span><span class="s">'id'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'id'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: right">id</th>
      <th style="text-align: right">ht</th>
      <th style="text-align: right">age</th>
      <th style="text-align: right">baseht</th>
      <th style="text-align: right">baseage</th>
      <th style="text-align: right">logfev1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">1.2</td>
      <td style="text-align: right">9.3415</td>
      <td style="text-align: right">1.2</td>
      <td style="text-align: right">9.3415</td>
      <td style="text-align: right">0.21511</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">1.28</td>
      <td style="text-align: right">10.3929</td>
      <td style="text-align: right">1.2</td>
      <td style="text-align: right">9.3415</td>
      <td style="text-align: right">0.37156</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">1.33</td>
      <td style="text-align: right">11.4524</td>
      <td style="text-align: right">1.2</td>
      <td style="text-align: right">9.3415</td>
      <td style="text-align: right">0.48858</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">1.42</td>
      <td style="text-align: right">12.46</td>
      <td style="text-align: right">1.2</td>
      <td style="text-align: right">9.3415</td>
      <td style="text-align: right">0.75142</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">1.48</td>
      <td style="text-align: right">13.4182</td>
      <td style="text-align: right">1.2</td>
      <td style="text-align: right">9.3415</td>
      <td style="text-align: right">0.83291</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'age'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'logfev1'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/splines/data.webp" alt="" /></p>

<p>Let us now implement the function to compute the splines</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">bspline</span><span class="p">(</span><span class="n">t</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span><span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="s">"""
    Returns a B-spline, defined as https://en.wikipedia.org/wiki/B-spline.

    Parameters:
    -----------
    t: np.array
    x: np.array
    i: int
    p: int

    Returns:
    np.array
    
    Raises:
    ------
    ValueError
       if i is not an integer between 0 and len(x)-p-1 (both included)
    """</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;=</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span><span class="o">&lt;</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">heaviside</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">heaviside</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">t</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fac0</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">p</span><span class="p">]</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">fac1</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">t</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">fac0</span><span class="o">*</span><span class="n">bspline</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="n">fac1</span><span class="o">*</span><span class="n">bspline</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s">'Got i=</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">, i must be an integer between 0 and len(x)-p-1=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p>Let us now take a look at the splines.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_plot</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">x_fit</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

<span class="n">basis_plot_0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">bspline</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">x_fit</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_fit</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)])</span>
<span class="n">basis_plot_1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">bspline</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">x_fit</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_fit</span><span class="p">)</span><span class="o">-</span><span class="mi">2</span><span class="p">)])</span>
<span class="n">basis_plot_2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">bspline</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">x_fit</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_fit</span><span class="p">)</span><span class="o">-</span><span class="mi">3</span><span class="p">)])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">basis_plot_0</span><span class="p">:</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">elem</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">"$p=0$"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">basis_plot_1</span><span class="p">:</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">elem</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">"$p=1$"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">basis_plot_2</span><span class="p">:</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">elem</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">"$p=2$"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/splines/basis.webp" alt="" /></p>

<p>As you can see, a B-spline of order $p$ can be differentiated $p-1$ times.
We will only assume the existence of the first derivative, so we will use
second-order splines.
The knots defined above look dense enough, we will therefore use them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p_fit</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">splines_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_fit</span><span class="p">)</span><span class="o">-</span><span class="n">p_fit</span><span class="o">-</span><span class="mi">1</span>

<span class="n">basis</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">bspline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'age'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">x_fit</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_fit</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">splines_dim</span><span class="p">)])</span>
</code></pre></div></div>

<p>We pre-computed the splines in order not to waste computational time, and we are now ready to 
implement our model. We will assume a linear plus spline model in order to easily
encode the trend which is present in for younger girls.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">spline_model</span><span class="p">:</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'w'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">splines_dim</span><span class="p">))</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span><span class="o">*</span><span class="n">df</span><span class="p">[</span><span class="s">'age'</span><span class="p">]</span> <span class="o">+</span> <span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'yhat'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'logfev1'</span><span class="p">])</span>

<span class="k">with</span> <span class="n">spline_model</span><span class="p">:</span>
    <span class="n">idata_spline</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_spline</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/splines/trace.webp" alt="" /></p>

<p>The trace looks fine, let us now inspect the predicted FEV</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">spline_model</span><span class="p">:</span>
    <span class="n">mu_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s">'mu_pred'</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span><span class="o">*</span><span class="n">x_plot</span> <span class="o">+</span> <span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">basis_plot_2</span><span class="p">))</span>
    <span class="n">yhat_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'yhat_pred'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu_pred</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>

<span class="k">with</span> <span class="n">spline_model</span><span class="p">:</span>
    <span class="n">ppc_spline</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata_spline</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'yhat_pred'</span><span class="p">,</span> <span class="s">'mu_pred'</span><span class="p">])</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span>
<span class="n">ppc_spline</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'yhat_pred'</span><span class="p">].</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">]))</span>
<span class="n">ax</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span>
<span class="n">ppc_spline</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'yhat_pred'</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">]),</span>
<span class="n">ppc_spline</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'yhat_pred'</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.975</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">]),</span>
                <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'age'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'logfev1'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">x_plot</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_plot</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/splines/ppc.webp" alt="The predicted log-FEV" /></p>

<p>As we can see, our model both reproduces the linear growth and the saturation of the FEV
which starts at about 15.</p>

<p>As a general warning, you should always keep in mind that b-splines
vanish outside from their basis domain, so if you use them to catch
some relevant behavior which is needed to appropriately describe the
desired behavior outside, you might have a bad surprise when you try and
generalize.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We introduced the concept of spline, and we have seen how to implement B-splines
in a PyMC model.
We used this model to fit the “Six Cities Study of Air Pollution and Health”
dataset.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Wed Aug 21 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />

<br />
xarray : 2024.5.0
<br />
numpyro: 0.15.0
<br />
jax    : 0.4.28
<br />
jaxlib : 0.4.28
<br />

<br />
numpy     : 1.26.4
<br />
pymc      : 5.15.0
<br />
arviz     : 0.18.0
<br />
matplotlib: 3.9.0
<br />
seaborn   : 0.13.2
<br />
pandas    : 2.2.2
<br />

<br />
Watermark: 2.4.3
<br />
</div>]]></content><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><category term="/statistics/" /><category term="/nonparametric_intro/" /><summary type="html"><![CDATA[Wisely using piecewise functions]]></summary></entry><entry><title type="html">Gaussian processes regression</title><link href="http://localhost:4000/statistics/gp_example" rel="alternate" type="text/html" title="Gaussian processes regression" /><published>2026-01-30T00:00:00+00:00</published><updated>2026-01-30T00:00:00+00:00</updated><id>http://localhost:4000/statistics/gp_example</id><content type="html" xml:base="http://localhost:4000/statistics/gp_example"><![CDATA[<p>In the last post, we introduced GPs. In this post we will see how to use them in order
to perform regression in a non-parametric fashion.
We will use the Nile dataset, which contains the Nile flow, expressed in $10^8 m^3$ measurements from
1871 to 1970.</p>

<h2 id="implementation">Implementation</h2>

<p>Let us first of all download the dataset.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">pymc_experimental.distributions</span> <span class="k">as</span> <span class="n">pmx</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/datasets/Nile.csv"</span><span class="p">)</span>

<span class="n">df</span><span class="p">[</span><span class="s">'time'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'time'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'value'</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp_example/nile.webp" alt="" /></p>

<p>The data seems almost stationary, except from a small discontinuity just before 1900,
and it also shows some auto-correlation, as they don’t look i.i.d. at all,
and it looks like there is no obvious periodicity.</p>

<p>The dataset contains 100 points, and we will use the first 85 to fit our model,
while the last 15 points will be used to assess the performances of our model in predicting
the future flow.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span> <span class="o">=</span> <span class="mi">85</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">n</span><span class="p">:]</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'time'</span><span class="p">]</span><span class="o">-</span><span class="n">df_train</span><span class="p">[</span><span class="s">'time'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">])</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="s">'time'</span><span class="p">]</span><span class="o">-</span><span class="n">df_train</span><span class="p">[</span><span class="s">'time'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">])</span>
<span class="n">x_test</span> <span class="o">/=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_train</span> <span class="o">/=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
</code></pre></div></div>

<p>We normalized the regression variables so that it is bounded between -1 and 1.
It will be convenient to have it normalized in this way, as it will simplify some
parameter estimate.</p>

<p>One of the main issues of GPs is given by their performances. 
However, when you are working with local kernels, by truncating the Fourier series expansion of 
the Kernel, you can obtain what is usually named as “Hilbert Space GPs”,
and this allows a faster implementation of the GPs.
This is not possible for all the kernels, as the Fourier series must exist.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'lam'</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">)</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s">'tau'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">rho</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'rho'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">gp</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">gp</span><span class="p">.</span><span class="n">HSGP</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="p">[</span><span class="mi">25</span><span class="p">],</span> <span class="n">L</span><span class="o">=</span><span class="p">[</span><span class="mf">1.2</span><span class="p">],</span> <span class="n">mean_func</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">gp</span><span class="p">.</span><span class="n">mean</span><span class="p">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">rho</span><span class="p">),</span><span class="n">cov_func</span><span class="o">=</span><span class="n">tau</span><span class="o">*</span><span class="n">pm</span><span class="p">.</span><span class="n">gp</span><span class="p">.</span><span class="n">cov</span><span class="p">.</span><span class="n">ExpQuad</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lam</span><span class="p">))</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">gp</span><span class="p">.</span><span class="n">prior</span><span class="p">(</span><span class="s">'mu'</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">x_train</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="s">'value'</span><span class="p">]</span><span class="o">/</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<p>We used a squared exponential kernel, where we assume that the GP fluctuations
are of the order of 0.5.
The parameter L must be chosen so that all the points are included into $[-L, L]\,,$
and this is why we normalized the regression variable as above.
We assumed that the mean of the GP has absolute value less than 2, and this seems reasonable
given the dataset.
We only kept 25 terms in the Fourier expansions, and later we will see how to verify
if we did a meaningful choice.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span>
                     <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp_example/trace.webp" alt="" /></p>

<p>It looks like there are few divergences, but this is not a big issue, as their number
is very small and the traces don’t show relevant issues.</p>

<p>Since we truncated the Fourier series, we would like that the last few coefficients
of the series expansion are close to 0, otherwise we would have an indications
that the series has been truncated too early.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'mu_hsgp_coeffs_'</span><span class="p">])</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp_example/coeffs.webp" alt="" /></p>

<p>The coefficients are almost zero starting from $i = 20\,,$
so the truncation seems ok.
We can now inspect the posterior predictive.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata</span><span class="p">))</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'time'</span><span class="p">],</span> <span class="mi">1000</span><span class="o">*</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
               <span class="mi">1000</span><span class="o">*</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
               <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s">'time'</span><span class="p">],</span> <span class="mi">1000</span><span class="o">*</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'value'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">df_train</span><span class="p">[</span><span class="s">'time'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">df_train</span><span class="p">[</span><span class="s">'time'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp_example/ppc.webp" alt="" /></p>

<p>In the “train” region we can reproduce with quite a high accuracy the observed data,
and there is no obvious sign of overfitting issues.
We can now use the remaining years to verify the performances of our model 
when predicting new data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">mu_pred</span> <span class="o">=</span> <span class="n">gp</span><span class="p">.</span><span class="n">conditional</span><span class="p">(</span><span class="s">'mu_pred'</span><span class="p">,</span> <span class="n">Xnew</span><span class="o">=</span><span class="n">x_test</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y_pred'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu_pred</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'mu_pred'</span><span class="p">,</span> <span class="s">'y_pred'</span><span class="p">])</span>

<span class="n">ypred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">20000</span><span class="p">,</span> <span class="mi">85</span><span class="p">)),</span>
<span class="n">ppc</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y_pred'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">20000</span><span class="p">,</span> <span class="mi">15</span><span class="p">))],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'time'</span><span class="p">],</span> <span class="mi">1000</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">ypred</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
               <span class="mi">1000</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">ypred</span><span class="p">,</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
               <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'time'</span><span class="p">],</span> <span class="mi">1000</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ypred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df_test</span><span class="p">[</span><span class="s">'time'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'value'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">df</span><span class="p">[</span><span class="s">'time'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'time'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp_example/ppc_pred.webp" alt="" /></p>

<p>The credible interval seems large enough to accommodate all the observed data,
and it does not explode. We can be therefore quite confident into the performances of our model.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We used GPs to perform regression over the Nile dataset. We introduced HSGPs,
and we briefly explained how to use them and how to assess the goodness of the 
approximation.</p>

<h2 id="suggested-readings">Suggested readings</h2>
<ul>
  <li><cite><a href="https://gaussianprocess.org/gpml/">Rasmussen, C. E., Williams, C. K. I. (2006). Gaussian Processes for Machine Learning. MIT Press.</a>
</cite></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Tue Aug 20 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />

<br />
xarray : 2024.5.0
<br />
numpyro: 0.15.0
<br />
jax    : 0.4.28
<br />
jaxlib : 0.4.28
<br />

<br />
seaborn          : 0.13.2
<br />
pymc_experimental: 0.1.1
<br />
pymc             : 5.15.0
<br />
numpy            : 1.26.4
<br />
arviz            : 0.18.0
<br />
pandas           : 2.2.2
<br />
matplotlib       : 3.9.0
<br />

<br />
Watermark: 2.4.3
<br />
</div>]]></content><author><name>Data-perspectives</name><email>dataperspectivesblog@gmail.com</email></author><category term="/statistics/" /><category term="/nonparametric_intro/" /><summary type="html"><![CDATA[Using GPs for flexible regression]]></summary></entry></feed>