<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-12-01T11:42:00+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Data Perspectives</title><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><entry><title type="html">Drawing is redrawing</title><link href="http://localhost:4000/gender-economist/" rel="alternate" type="text/html" title="Drawing is redrawing" /><published>2023-11-20T00:00:00+01:00</published><updated>2023-11-20T00:00:00+01:00</updated><id>http://localhost:4000/gender-economist</id><content type="html" xml:base="http://localhost:4000/gender-economist/"><![CDATA[<p>Sometimes you must deal with constraints in dataviz, and finding the most
suitable way to tackle your problem is not always easy.
This is the case of the challenge launched by Sarah Leo, a visual data journalist
working at the Economist in <a href="https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368">this post</a>.</p>

<p>Among designers there is a well know saying which states “Designing is redesigning”, and this also holds 
when you are designing a data visualization.
In the above post, Sarah critically analyzes some issues of the past visualizations of her journal,
and she explain how she would have corrected them.
When talking about dataviz, the Economist is one of my favourites journals, as their graphics are usually very clean and polished.
However, I agree with Sarah, those shown in her post are not their best works.</p>

<p>In the last example, taken from
a 2017 article titled <a href="https://www.economist.com/science-and-technology/2017/03/11/science-remains-male-dominated">“Science remains male dominated”</a>
she analyzes the following image
<img src="/docs/assets/images/gender_economist/original.webp" alt="gender economist" />
and, as you may notice from the right hand side of the figure, she decided not to redesign the chart, as the space constraints are too stringent.</p>

<p>I decided to try and redo it by myself, so first of all I analyzed the information we wanted to plot.</p>
<ul>
  <li>The first attribute is the Country, which is a categorical attribute.</li>
  <li>We then have the research field, which is another categorical attribute.</li>
  <li>We finally have the percentage of women, which is a quantitative attribute.</li>
</ul>

<p>As a “special” information we also have the percentage of inventors, which is somehow different from a research field,
and of course Sarah shows this different by using a different marker for this attribute.</p>

<p>Probably the best possible approach would be to draw a bar chart where, for each research field,
we show the percentage of women, but this would take quite a large amount of space, so I immediately discarded this idea.</p>

<p>The structure of the data itself should suggest another possible approach: why don’t we draw a matrix?
This would save some space, and by using area as
channel to encode the women percentage we could easily encode all the informations.
Here’s the result.</p>

<link rel="stylesheet" href="/docs/assets/css/gender.css" />

<script src="https://d3js.org/d3.v5.js"></script>

<script src="https://d3js.org/d3-scale-chromatic.v1.min.js"></script>

<div id="gender_area"></div>
<script src="/docs/assets/javascript/gender_economist/gender_area.js"></script>

<p>The visualization is quite clear, and less cluttered than the original one.
I don’t know which were exactly the requirements of the editor,
but comparing the size of the above image with the original one, maybe it would have
been OK.
Note that we also remarked the difference between the inventor percentage
and the research fields by using a different font weight
together with a different background color, as those
are common tricks in graphics and typography.</p>

<p>But there is some issue: how would you estimate the percentage of women
in Australia in the healthcare sector?</p>

<p>Honestly I would say about 70%, maybe even 80%.
Well, <em>it’s exactly 50%!</em>
I immediately asked myself if there was a bug in the code, so I printed
the size for 100% women and the one for 50%.
I got 60 (as expected) and 42.63, their reciprocal ratio is 0.707
which is roughly the square root of 0.5, so there’s no bug!</p>

<div class="emphbox">
The issue is that, on average, humans are very bad at estimating
areas, and we tend to use the size of the square side rather than
the square area to decode the information.
</div>

<p>This is a well known issue, and we will discuss this in a future post.
So how can we solve this issue? As we have seen when talking about
channel effectiveness, color is even worst than area to encode
quantitative information, but let us try and do that anyway.</p>

<div id="gender_color_first"></div>
<script src="/docs/assets/javascript/gender_economist/gender_color_first.js"></script>

<p>In redrawing the figure, I removed the gray background.
I did so because, as we will see in a future post,
our perception of color difference is quite strongly affected by the color background, so I considered
the information provided by the color background
not relevant enough to risk a distortion in the perception
of the color difference among the last column and the remaining columns.</p>

<p>Actually I find slightly easier to decode the information, but still
it’s hard to say if we are above or below 50%.
In order to solve this issue we must rethink our visualization, and we must do that
by keeping in mind what is the true quantity that we want to decode,
which is the gender imbalance.</p>

<p>We don’t need a channel that exactly tells us the percentage of women,
but rather we want to know how far are we from 50% and in which direction.</p>

<p>There’s a class of color palettes which is suitable for our purposes,
and it’s the family of the diverging color palettes.
Let’s take a look and see how would a diverging color palette
work for our purpose.</p>

<div id="gender_color"></div>
<script src="/docs/assets/javascript/gender_economist/gender_color.js"></script>

<p>Here it’s much easier to decode the relevant quantity, and we used exactly the same
space we used in the first visualization we made.
Now we can immediately spot that all but the firs columns are above 50%, that Japan is likely the worst
country, that Brazil and Portugal are the best ones and that the research area where it’s morel likely
to encounter women is health science.
Moreover, in health science the percentage of men and women is more or less 50-50 in most countries, where the balance is
just slightly in favour of men <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>.
We can also see that physics, engineering and math have roughly the same distribution, and that the percentage of
women inventors is almost always lower than the percentage of women researcher in any field.
This is quite a large amount of information in my opinion, so I feel quite satisfied by this solution.</p>

<div class="emphbox">
Use diverging color palettes to encode how far are your data from a certain point.
</div>

<h2 id="conclusions">Conclusions</h2>

<p>This post was about a real application, and in these situations there are many things to consider, so we touched many aspects of data visualization.
The main things I’d like to stress you about are the following:</p>

<ul>
  <li>Always make sure that there are no bugs in your visualization.</li>
  <li>Always keep in mind what you want to show, and state this information as clearly as possible.</li>
  <li>Always try different designs for your visualizations, choose the ones which look more promising and refine them, then reiterate.</li>
  <li>Data visualization is about choosing among options, and each option will have pros and cons. This is the reason why I never trust who gives me recipes, they rarely work in real life.</li>
</ul>

<p>Moreover, as secondary more practical things to keep in mind:</p>
<ul>
  <li>We are bad at estimating areas as well as at estimating color variations, so always consider using distance or length as channel to encode relevant informations, as suggested by the effectiveness principle.</li>
  <li>Use diverging color palettes to encode distances from a given relevant point.</li>
</ul>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>I preferred this color scheme with respect to the more common red-blue one because I found easier to infer if a value close to 0.5 was slightly above or below 0.5. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><category term="/dataviz/" /><category term="/redesign/" /><summary type="html"><![CDATA[How to tackle real life dataviz problems]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/docs/assets/images/gender_economist/original.webp" /><media:content medium="image" url="http://localhost:4000/docs/assets/images/gender_economist/original.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The Gestalt principles</title><link href="http://localhost:4000/gestalt/" rel="alternate" type="text/html" title="The Gestalt principles" /><published>2023-11-07T00:00:00+01:00</published><updated>2023-11-07T00:00:00+01:00</updated><id>http://localhost:4000/gestalt</id><content type="html" xml:base="http://localhost:4000/gestalt/"><![CDATA[<!-- Load d3.js -->
<script src="https://d3js.org/d3.v5.js"></script>

<p>Gestalt principles are largely used in design
in order to convey grouping among items in 
a visualization.
Here we will discuss them in order to understand
how to leverage them in dataviz.</p>

<h2 id="proximity">Proximity</h2>

<p>The proximity principle states that nearby objects are perceived as a group.</p>

<script src="/docs/assets/javascript/gestalt/proximity.js">
</script>

<div id="proximity">
</div>

<p>By looking at the above figure,
in the first case you will probably see
a grid,
in the second one a collection
of columns and in the third one a 
collection of rows.</p>

<h2 id="similarity">Similarity</h2>

<h2 id="connection">Connection</h2>

<h2 id="closure">Closure</h2>

<h2 id="enclosure">Enclosure</h2>

<h2 id="continuity">Continuity</h2>]]></content><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><category term="/dataviz/" /><category term="/gestalt/" /><summary type="html"><![CDATA[How does our brain build patterns]]></summary></entry><entry><title type="html">Channel effectiveness</title><link href="http://localhost:4000/effectiveness/" rel="alternate" type="text/html" title="Channel effectiveness" /><published>2023-11-05T00:00:00+01:00</published><updated>2023-11-05T00:00:00+01:00</updated><id>http://localhost:4000/effectiveness</id><content type="html" xml:base="http://localhost:4000/effectiveness/"><![CDATA[<!-- Load d3.js -->
<script src="https://d3js.org/d3.v5.js"></script>

<p>When we have been talking about <a href="/marks-channels">marks and channels</a>
we mentioned the concept of effectiveness, by saying it
reflects how easily we translate the visual information encoded into the
corresponding channel.</p>

<p>Effectiveness is not a fundamental quantity, but it rather summarizes a
number of possible features:</p>
<ul>
  <li>Accuracy</li>
  <li>Discriminability</li>
  <li>Salience</li>
  <li>Separability</li>
  <li>Grouping</li>
</ul>

<p>In this post we will discuss the meaning of these terms, and we will 
see how to determine which channel is the most effective for your task.</p>

<h2 id="accuracy">Accuracy</h2>
<p>Accuracy quantifies how good is a channel in conveying the value of an attribute.
Not all channels are equally accurate, as we perceive different
channels in different ways.
Research showed that, on average, there is a power law relationship between the 
change in the stimulus and the perceived change, and this law goes under the name
of <strong>Stevens’ power law</strong></p>

\[\psi_k(I) \propto I^{a_k}\]

<p>where $a_k$ is the exponent associated with the stimulus of type $k$,
$I$ is the intensity of the stimulus and $\psi$ represents the perceived
value.
Here we show the relation for some of the main channels we will use.</p>

<div id="stevens"> </div>
<script src="/docs/assets/javascript/effectiveness/stevens.js"> </script>

<p>As we see, the only quantity which we perceive linearly is the length,
while we are on average worst at estimating any other quantity.</p>

<p>As an example, try and estimate the length ratio between the two
lines and the area ratio between the two circles:</p>

<p><br />
<br /></p>

<svg height="150" width="600">
  <line x1="0" y1="40" x2="150" y2="40" style="stroke:crimson;stroke-width:10" />
  <line x1="0" y1="60" x2="450" y2="60" style="stroke:steelblue;stroke-width:10" />
</svg>

<svg height="150" width="500">
  <circle cx="150" cy="50" r="28.87" fill="crimson" />
  <circle cx="250" cy="50" r="50" fill="steelblue" />
</svg>

<p>Both the ratios are equal to 3. Was it hard to do that? How accurate
have you been?</p>

<h2 id="discriminability">Discriminability</h2>

<p>Discriminability quantifies how many different values can we encode into
a certain channel by letting them being perceived differently.
Of course, this only becomes a problem as you approach the discriminability
limit of the channel.</p>

<p>Here we show 30 different tones of
red. Can we distinguish all of them? Honestly I think it’s quite a hard task.</p>

<div id="discriminability"> </div>
<script src="/docs/assets/javascript/effectiveness/discriminability.js"> </script>

<h2 id="salience">Salience</h2>

<p>Salience tells us how easy it is for us to find differences among objects
by using a certain channel.
As we have previously seen, it’s very easy to spot a red circle between
blue circles, so color hue has good salience capabilities.
Color luminance is much worst in this task, as it is very hard to spot
objects with different color luminance, so color luminance has 
worst salience (or worst popout properties) than color hue.</p>

<h2 id="separability">Separability</h2>

<p>Channels cannot be treated independently one on the others,
but the properties of one channels depend on the other channels
used in the visualization.
There are channels among this interaction is stronger, and those
channels are called <strong>integral</strong>, as well as channels where the interaction
is almost negligible, and they are called <strong>separable</strong>.</p>

<svg height="150" width="500">
  <circle cy="50" cx="50" r="1.5" fill="crimson" />
  <circle cy="50" cx="100" r="3" fill="crimson" />
  <circle cy="50" cx="150" r="6" fill="crimson" />
  <circle cy="50" cx="200" r="12" fill="crimson" />
  <circle cy="50" cx="250" r="24" fill="crimson" />
</svg>

<p>In the above figure, do you always perceive the same color? Or do
you rather think that the color of the ball changes with the circle?
Most of the people would say that the color changes among the circles,
and they would be wrong.
This is because color interacts with size, especially for small objects.</p>

<p>The interaction also goes the other way round:</p>

<p><br /></p>
<div style="background-color:black;">
<p style="color:red;font-size:60px;">
Most people perceive this as bigger</p>
<p style="color:blue;font-size:60px;">But the two
lines have the same size</p>
</div>

<p><br />
In the first case the color was affected by the size,
in the second case the other way round happened.</p>

<h2 id="grouping">Grouping</h2>

<p>Grouping tells us how easy it is for us to spot patterns in the data.
In psychology it has been extensively studied what we perceive as grouped,
and these results are collected into the <strong>Gestalt principles</strong>.</p>

<svg height="150" width="500">
  <circle cy="50" cx="50" r="1.5" fill="crimson" />
</svg>

<p>Gestalt principles are well known to whoever studied design, and we will
discuss them into a separate post.</p>

<h2 id="our-perception-depends-on-the-context">Our perception depends on the context</h2>
<p>What we perceive strongly depends
on the context.</p>

<h2 id="conclusions">Conclusions</h2>
<p>We have seen different criteria to assess
the effectiveness of a channel.
Depending on your task, you should find
the most appropriate way to assess the effectiveness
of a visualization.
If you want to precisely compare values, you
should probably favour more accurate channels,
while if you want to check if your
clustering algorithm is doing its job, then you should consider using channels where grouping is easier.</p>]]></content><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><category term="/dataviz/" /><category term="/effectiveness/" /><summary type="html"><![CDATA[Quantifying the goodness of a channel to show an information]]></summary></entry><entry><title type="html">Evolutions of the line chart</title><link href="http://localhost:4000/linechart-evolution/" rel="alternate" type="text/html" title="Evolutions of the line chart" /><published>2023-11-03T00:00:00+01:00</published><updated>2023-11-03T00:00:00+01:00</updated><id>http://localhost:4000/linechart-evolution</id><content type="html" xml:base="http://localhost:4000/linechart-evolution/"><![CDATA[<p>In a <a href="/fundamental-charts">previous post</a> we saw some of the most fundamental charts,
which are the basic building blocks for data visualization.</p>

<p>Datasets can become very complex, and you should adapt your data visualization
depending on your needs.
Here we will take a look at how we can draw more and more complex datasets
by simply changing few details of the basic visualization, and we will
do so by using the line chart as fundamental visualization.</p>

<h2 id="the-line-chart">The line chart</h2>

<p>As we have already seen, in the line chart we have</p>
<ul>
  <li>an ordered key attribute on the $x$ axis</li>
  <li>a quantitative value attribute on the $y$ axis</li>
</ul>

<p>As an example, let us take a look at evolution over the years the Italian GDP per capita expressed in US dollars adjusted by the US inflation, which can be found
<a href="https://github.com/thestippe/thestippe.github.io/blob/main/data/gdp_per_capita_filtered.csv">here</a>.</p>

<p>The dataset is based on <a href="https://github.com/RaafatSaleh/GDP-per-capita-and-its-effect-on-the-man-life-quality/blob/master/Data/gdppercapita_us_inflation_adjusted.csv">this</a> repo.</p>

<!-- Load d3.js -->
<script src="https://d3js.org/d3.v5.js"></script>

<div id="linechart"> </div>
<script src="/docs/assets/javascript/linechart_evolution/linechart.js"> </script>

<p>This visualization allow us to see how a quantity (the GDP per capita)
changes over time, and it does that in a decent way.</p>

<h2 id="issues-with-the-line-chart">Issues with the line chart</h2>

<p>But what does it happen when we add a second categorical key attribute?
As an example, let’s try and visualize more than one Country in
a single plot.
Let us start by using color to encode the Country</p>

<div id="multiple_linechart"> </div>
<script src="/docs/assets/javascript/linechart_evolution/multiple_linechart.js"> </script>

<p>As the number of lines grows, the graph soon becomes more and more cluttered.
Already with a small number of lines it becomes difficult to catch the behavior
of a single line.</p>

<p>We have two main alternatives to the multiple line chart:</p>
<ul>
  <li>we can put one line chart per graph and we create a <strong>small multiples</strong></li>
  <li>we can use another channel to encode the value attribute
or, of course, we can combine the two techniques.</li>
</ul>

<h2 id="small-multiples">Small multiples</h2>

<p>Broadly speaking, when you build a small multiple you draw more than
one visualization, and each visualization is indexed by a label which is not
used in any of the single images.
This technique is also called faceting.</p>

<div id="sm_linechart"> </div>
<script src="/docs/assets/javascript/linechart_evolution/sm_linechart.js"> </script>

<p>Here we used small multiples to put one visualization on the right of the previous,
but you can also order them vertically or build a grid.</p>

<p>The main advantage of the small multiples is that they reduce clutter,
but it becomes more difficult to compare the single lines.</p>

<h2 id="stacked-area-chart">Stacked area chart</h2>

<p>If the value attribute is sequential as in our case (the GDP cannot become negative), another possible solution is to stack the lines one above the other one,
and this is done in the stacked area chart.</p>

<div id="stacked_chart"> </div>
<script src="/docs/assets/javascript/linechart_evolution/stacked_chart.js"> </script>

<p>The major issue with this solution is that, for all but the lowest curve,
the baseline is not constant, and this makes difficult to quantify the values.</p>

<h2 id="streamgraph">Streamgraph</h2>

<p>A stacked bar chart can become cumbersome when one has many channels, and in this
case one may use a streamgraph.</p>

<div id="steamgraph"> </div>
<script src="/docs/assets/javascript/linechart_evolution/steamgraph.js"> </script>

<p>The streamgraph is obtained by allowing the lower
line to vary, and either by making it symmetric with respect to the $x$ axis or by choosing it exact shape by minimizing some target quantity.
This method allows you to show
a large number of categories, but the main drawback
is that one needs some practice to read it.</p>

<h2 id="conclusions-and-take-home-message">Conclusions and take-home message</h2>

<p>We have seen few possible evolutions of the line chart.
Those alternatives are appropriate when you want to plot the evolution of a quantitative variable
for a set of categories.
Faceting can be combined with anyone of the visualizations we have previous discussed, while stacking can 
only be applied to bar chart or line chart.
Finally, we have seen the streamgraph,
which uses an alternative way of stacking the lines.</p>]]></content><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><category term="/dataviz/" /><category term="/linechart-evolution/" /><summary type="html"><![CDATA[When a linechart is not enough]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/docs/assets/images/linechart_evolutions/areaplot.png" /><media:content medium="image" url="http://localhost:4000/docs/assets/images/linechart_evolutions/areaplot.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Perception</title><link href="http://localhost:4000/perception/" rel="alternate" type="text/html" title="Perception" /><published>2023-11-01T00:00:00+01:00</published><updated>2023-11-01T00:00:00+01:00</updated><id>http://localhost:4000/perception</id><content type="html" xml:base="http://localhost:4000/perception/"><![CDATA[<p>Before digging into visualizations, we must understand how do we perceive
images.
Typically the human eye can detect light in the range of wavelengths going
from 380 nanometers (violet) to 700 nanometers (red).
Our eye is rather complex, but to our aim we can only consider few components:</p>
<ul>
  <li>The <strong>cornea</strong> which acts as a convergent lens and focuses the light coming to our eye.</li>
  <li>The <strong>iris</strong> which regulates the amount of light entering into our eye.</li>
  <li>The <strong>crystalline lens</strong> changes the focal length of the eye, allowing us to focus on different objects.</li>
  <li>The <strong>retina</strong> which contains the light receptors of our eye.</li>
  <li>The <strong>optic nerve</strong> which transmits the information from the retina to the brain.</li>
</ul>

<p>Into the retina we have two kind of receptors:</p>
<ul>
  <li>The <strong>rod cells</strong> which are very sensitive in low light conditions. They are roughly 90 millions and are especially used into the peripheral vision and night vision. They are especially concentrated at the outer edge of our retina</li>
  <li>The <strong>cone cells</strong> are responsible of the color vision, and are roughly 6 millions. Human eye has three kind of cone cells, and each type is more sensitive into a specific wavelengths range, corresponding approximately to <strong>red</strong>, <strong>blue</strong> and <strong>green</strong> wavelengths and named long, medium and short wavelengths cones.</li>
</ul>

<p>The red cones are approximately ten times the green or blue ones, this is why we are better in discriminating the red tones than the blue or green ones.</p>

<p><img src="/docs/assets/images/perception/Cone-absorbance-en.svg" alt="Cone absorbance" /> The typical spectrum of our light receptors, from <a href="https://en.wikipedia.org/wiki/Rod_cell">Wikipedia</a></p>

<p>The cone density is much higher in a small region located oppositely to the iris,
namely the <strong>fovea</strong>. Approximately half the nerve fibers in the optic nerve
carry information from the fovea, while the remaining half carry information
from the rest of the retina.</p>

<p>This should suggest you that the fovea is the region with the highest resolution
of the retina, and since it is very small our eye can only clearly see within
a very small region.
In fact, our high-resolution region is limited to less than 2 degrees.</p>

<p>On the other hand, on average, we have the feeling that we can clearly see most
of what surrounds us. This is because our eye makes small movements (less than 20 degrees)
named <a href="https://en.wikipedia.org/wiki/Saccade"><strong>saccadic movements</strong></a> with an average time between two movements of 225 ms.
Our brain then elaborates the images and reconstructs a map by using many movements,
giving us the feeling of a higher resolution.</p>

<p>This has a very important impact on data visualization:</p>

<div class="emphbox">
Attention plays  a major role into what we perceive.
</div>

<h2 id="preattentive-features">Preattentive features</h2>

<p>For this reason the scientific community spent a lot of energy in trying and determine
what drives our attention.
According to Colin Ware’s textbooks 
<strong>Information Visualization: Perception for Design</strong> the list of features which
drives our attention, named <strong>preattentive features</strong>, can be divided into
four kind of features: <strong>form, color, motion</strong> and <strong>spatial positioning</strong>.</p>

<p><strong>Form:</strong></p>
<ul>
  <li>Line orientation</li>
  <li>Line length</li>
  <li>Line width</li>
  <li>Line collinearity</li>
  <li>Size</li>
  <li>Curvature</li>
  <li>Spatial grouping</li>
  <li>Blur</li>
  <li>Added marks</li>
  <li>Numerosity</li>
</ul>

<p><strong>Color:</strong></p>
<ul>
  <li>Color hue</li>
  <li>Color intensity</li>
</ul>

<p><strong>Motion:</strong></p>
<ul>
  <li>Flicker</li>
  <li>Direction of motion</li>
</ul>

<p><strong>Spatial positioning:</strong></p>
<ul>
  <li>2D position</li>
  <li>Stereoscopic depth</li>
  <li>Convex/concave shape from shading</li>
</ul>

<div class="emphbox">
Whenever you want to encode a relevant information in your visualization,
you should use one of the above features.
</div>

<p>Not all of them take the same amount of time to be processed.
As an example, it takes a very short time to recognize a red circle
between many blue circles.
If you don’t trust me you can try and click on the red circle in the figure below.
Each time you will hit it a new figure will appear, and you will get visualize
the distribution of the time needed to hit it.</p>

<!-- Load d3.js -->
<script src="https://d3js.org/d3.v5.js"></script>

<div id="preattentive_color"> </div>

<!-- Create a div where the graph will take place -->

<p>I am quite sure it was quite an easy task,
as most of us can clearly see the red circle
immediately.
For this reason we say that the red circle
pops out.
You can now try and perform the same task, but this time you will be required
and hit the blue square.</p>

<div id="preattentive_size"> </div>

<p>I am quite sure it was quite easy, but not
as easy as the exercise before.
Now try and compare your time distributions.
Is the first one typically smaller than the second one?
Do the two distributions overlap?
Here you can find the kernel density estimate for my results,
which I collected for few days, trying the exercises in different moments
and in different order.</p>

<p><img src="/docs/assets/images/perception/hist.png" alt="" /></p>

<p>The heavy tails likely correspond to some missed click, so it took some time
to click a second time.
The two distributions are similar but definitely not identical,
the one corresponding to the shape is shifted on the right with respect to
the one corresponding to the color.</p>

<p>Of course this cannot be considered an experiment, I am just trying and give you
some evidence that finding a blue square between many blue circles takes
some more time than finding a red circle between many blue circles.</p>

<h2 id="conclusion-and-future-outlook">Conclusion and future outlook</h2>

<p>We had a broad overview about how do we perceive what surrounds us, and we have
seen that there is a class of visual features, namely the preattentive
features, which govern our attention.
We can leverage them to draw the attention of our audience where we think
it’s most relevant</p>

<p>Unfortunately, as we will see, properly using the preattentive features is far from being easy, especially when
you want to combine more than one feature.
Some feature combinations are still preattentive, while other are
no more preattentive, and at the best of my knowledge there are no
exhaustive studies where these combinations are analyzed.</p>

<p>For this post we will limit our discussion about one feature at time, but
we will discuss how we can combine more than one feature to obtain different
effects.</p>

<h2 id="bonus-the-results-of-your-tests">Bonus: the results of your tests</h2>

<p>In the following are listed the results of both of your test.</p>

<div id="combined_chart"> </div>

<h3 id="color-difference">Color difference</h3>

<div id="preattentive_color_list"> </div>

<h3 id="size-difference">Size difference</h3>

<div id="preattentive_size_list"> </div>

<script src="/docs//assets/javascript/perception/preattentive_color.js"> </script>

<script src="/docs//assets/javascript/perception/preattentive_size.js"> </script>

<script src="/docs/assets/javascript/perception/combined_chart.js"> </script>]]></content><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><category term="/dataviz/" /><category term="/perception/" /><summary type="html"><![CDATA[How do we see what surrounds us]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/docs/assets/images/perception/eye.jpg" /><media:content medium="image" url="http://localhost:4000/docs/assets/images/perception/eye.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Fundamental charts</title><link href="http://localhost:4000/fundamental-charts/" rel="alternate" type="text/html" title="Fundamental charts" /><published>2023-10-30T00:00:00+01:00</published><updated>2023-10-30T00:00:00+01:00</updated><id>http://localhost:4000/fundamental-charts</id><content type="html" xml:base="http://localhost:4000/fundamental-charts/"><![CDATA[<!-- Load d3.js -->
<script src="https://d3js.org/d3.v5.js"></script>

<p>In this post we will take a look at some of the most fundamental charts
that one encounters in data visualization <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>.</p>

<h2 id="1-d-scatterplot">1-D Scatterplot</h2>

<p>Although not very common in explanatory visualization, one may decide to simply visualize
a single value attribute across some items, and in this case we 
can use a one dimensional scatterplot.
In this example we will show the distribution of the sepal width for the well known Iris dataset.</p>

<div id="my_scatterplot1d"> </div>

<script src="/docs//assets/javascript/fundamental_charts/scatterplot1d.js"> </script>

<p>The one dimensional scatterplot may be used to visualize the distribution of our attribute
across our items or to find possible outliers.</p>

<h2 id="2-d-scatterplot">2-D Scatterplot</h2>

<p>In a two dimensional scatterplot we show the distribution of two
quantities across the items.
In this case we have no key attribute.
As an example, here we show how the sepal length and the sepal width are
varying across the items of the already used Iris dataset.</p>

<div id="my_scatterplot"> </div>

<script src="/docs//assets/javascript/fundamental_charts/scatterplot.js"> </script>

<p>This visualization can be helpful to determine the underlying distribution
for our attributes, to find whether there exist some correlation among the two
variables or to look for clusters.</p>

<h2 id="bar-chart">Bar chart</h2>

<p>In a bar chart we show
the how a quantitative attribute changes across a set of categories,
which represent our key attribute.</p>

<p>Here and in the future will work under the hypothesis that there are no duplicates among the categories.
In the database language, we may say that our key is a primary key.</p>

<p>As an example, we can visualize the number of gold medals
that each country won in the 2020 Olympic games.
Here we will only plot a sub-sample of the dataset, while the full dataset
can be found <a href="https://github.com/MainakRepositor/Datasets/blob/master/Tokyo-Olympics/Medals.csv">here</a>.</p>

<!-- Create a div where the graph will take place -->
<div id="barchart"> </div>

<script src="/docs//assets/javascript/fundamental_charts/barchart.js"> </script>

<p>In this case the categorical variable is the team, while the quantitative variable
is the number of gold medals.</p>

<p>The bar chart can be rotated by 90 degrees, but the vertical version (which we used)
allows for a larger number of categories to be shown.</p>

<p>If the categories don’t have any natural order it may be a good idea to
reorder the categories with respect to the plotted quantity to improve readability.</p>

<p>A bar chart can be very useful when one wants to compare the values of
the attributes across the categories.</p>

<h2 id="line-chart">Line chart</h2>

<p>In a line chart you can visualize how does a quantitative variable,
which represent our value attribute, changes with
respect to another quantity, which is a key attribute, and it often represents time.
To better explain this graph, let us take a look at the gold
price in the period 1978-2021.</p>

<div id="linechart"> </div>
<script src="/docs//assets/javascript/fundamental_charts/linechart.js"> </script>

<p>This visualization can be useful to extract information between the
value attribute and the key attribute.</p>

<p>Line chart is often abused, as the line naturally both encodes order
and a concept of distance between the values in
the x axes, so if x is not a quantitative variable one should
never use the line chart.</p>

<h2 id="matrix-chart">Matrix chart</h2>

<p>In a matrix we want to visualize how does a quantity (our value)
distributes across two categorical variables, which are our key attributes.
As an example, here we visualize how many points each team of the Six Nations Championship
performed against each opponent in the period 2016-2023.</p>

<div id="my_matrix_chart"> </div>

<script src="/docs//assets/javascript/fundamental_charts/matrix.js"> </script>

<p>As we will discuss in a future post, this representation is never optimal,
as the two spatial dimensions are already encoding the categorical
variables, so one must rely on another channel, typically area or color,
to encode the quantitative variable. 
The issue is that our perception of scale variations in both channels
are prone to errors, so one may find difficulties to correctly
decode the quantitative informations.</p>

<p>Matrix charts are typically used to find outliers or clusters.</p>

<h2 id="symbol-map">Symbol map</h2>
<p>The fifth and last type of visualization we will discuss here is the
symbol map, where we show how a quantity varies across two spatial
coordinates.</p>

<p>As an example, here I plot some of the places where I lived, where the area is proportional to the
time I lived in each location.</p>

<script src="https://d3js.org/d3-geo-projection.v2.min.js"></script>

<div id="my_symbol_chart"></div>

<script src="/docs/assets/javascript/fundamental_charts/symbol.js"> </script>

<p>Symbol maps can be used to determine the spatial distribution of a certain quantities.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Here we will follow Enrico Bertini’s Coursera lecture on fundamental graphs, which I suggest you to watch together with his entire <a href="https://www.coursera.org/specializations/information-visualization">specialization in data visualization</a>. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Well, to be honest this post is also an excuse to try and see how to draw charts with <a href="https://d3js.org/">D3.js</a>, and up to the moment it looks an amazing tool! <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><category term="/dataviz/" /><category term="/fundamental_charts/" /><summary type="html"><![CDATA[An overview to some of the most common data visualizations]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/docs/assets/images/charts/charttypes.png" /><media:content medium="image" url="http://localhost:4000/docs/assets/images/charts/charttypes.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Beer and the Beta-Binomial model</title><link href="http://localhost:4000/beta-binom/" rel="alternate" type="text/html" title="Beer and the Beta-Binomial model" /><published>2023-10-22T00:00:00+02:00</published><updated>2023-10-22T00:00:00+02:00</updated><id>http://localhost:4000/beta-binom</id><content type="html" xml:base="http://localhost:4000/beta-binom/"><![CDATA[<p>I love beer, and whenever I have a free day I brew. As you probably know, beer is made
with water, malt, hop and yeast. One of the most important things to do in order
to produce a good beer is to have a good quality yeast, and one of the metrics
used to quantify the goodness of the yeast is the <strong>yeast viability</strong>, which corresponds to the percentage of alive cells in your yeast.
This procedure is time consuming, as you must count by hand the number of dead
and alive cells in a sample, so it is usually performed with small samples. It is therefore important to quantify the uncertainties in your estimate.</p>

<p>Unfortunately, most home-brew textbooks will only give you a way to
estimate the mean yeast viability, and you may get fooled by your count and think that
you are working with a good yeast while you simply overestimated the yeast viability.
If you want to know more about how to experimentally count the yeast cells,
you can take a look to <a href="https://escarpmentlabs.com/blogs/resources/crop-pray-count-yeast-counting-guide">this</a>
link, where the procedure to count the yeast cells is illustrated.</p>

<p>In the standard procedure, one has a $5\times 5$ grid and one counts the alive
cells and the death ones, where one can distinguish the cells thanks to the
Trypan Blu which will color the death cells.
A simulated example of what one will see is shown below:</p>

<p><img src="/docs/assets/images/beta_binom/yeast_count.jpg" alt="Alt text" /></p>

<p>Since counting all the cells would require a lot of time, one usually counts
five well separated squares, usually the four corner squares and the center one.
In the figure shown above:</p>

<table>
  <thead>
    <tr>
      <th>square</th>
      <th>alive</th>
      <th>death</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>top left</td>
      <td>15</td>
      <td>2</td>
    </tr>
    <tr>
      <td>top right</td>
      <td>11</td>
      <td>2</td>
    </tr>
    <tr>
      <td>bottom left</td>
      <td>10</td>
      <td>2</td>
    </tr>
    <tr>
      <td>bottom right</td>
      <td>14</td>
      <td>2</td>
    </tr>
    <tr>
      <td>center</td>
      <td>22</td>
      <td>1</td>
    </tr>
    <tr>
      <td><strong>total</strong></td>
      <td>72</td>
      <td>9</td>
    </tr>
  </tbody>
</table>

<p>Let us see how can we estimate the viability.
In the following, we will indicate with $n_a$ the number of alive cells (which is 72)
and with $n_d$ the number of death cells (9).
In order to do this, let us first open our Jupyter notebook, import some libraries
and define the data</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="n">arviz</span> <span class="k">as</span> <span class="n">az</span>

<span class="c1"># Let us improve the graphics a little bit
</span><span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">"</span><span class="s">seaborn-v0_8-darkgrid</span><span class="sh">"</span><span class="p">)</span>

<span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">(</span><span class="sh">"</span><span class="s">rocket</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># For reproducibility
</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">alive</span> <span class="o">=</span> <span class="mi">72</span>
<span class="n">death</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">alive</span> <span class="o">+</span> <span class="n">death</span>
</code></pre></div></div>

<h2 id="the-home-brewers-textbook-way">The home-brewer’s textbook way</h2>
<p>The home-brewer’s solution is fast and simple: if we have 72
alive cells out of 81 cells, then the probability of having
and alive cell is simply</p>

\[\theta_{hb} = \frac{n_a}{n_a + n_d}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">theta_hb</span> <span class="o">=</span> <span class="n">alive</span> <span class="o">/</span> <span class="n">total</span>
</code></pre></div></div>
<blockquote>
  <p>0.88889</p>
</blockquote>

<p>This is a quick solution, however we cannot associate any uncertainty to this number
for the moment.</p>

<h2 id="the-frequentist-statisticians-way">The frequentist statistician’s way</h2>

<p>A frequentist statistician would first of all setup a model for this problem.
The state of each cell can take two values:</p>

\[y_i = 
\begin{cases}
1 \text{ (alive) } &amp; \text{ with probability } \theta \\
0 \text{ (death) } &amp; \text{ with probability } 1-\theta
\end{cases}\]

<p>If we assume that the probability of being alive of each cell is independent on the probability of the remaining cells
of being alive and that the probability is the same for each cell, we have that the probability of finding $y$ alive cells out of $n$ total counted cells must follow a binomial distribution:</p>

\[p(y|p, n) \propto \theta^{y} (1-\theta)^{n-y}\]

<p>which can be written as</p>

\[y \sim Binomial(\theta, n)\]

<p>where the binomial distribution has probability mass</p>

\[p(y | p, n) = \binom{n}{y} \theta^y (1-\theta)^{n-y}\]

<p>and</p>

\[y = \sum_{i=1}^n y_i\]

<p>and $ \binom{n}{y} = \frac{n!}{y!(n-y)!}$ is a multiplicative normalization factor.
Once the model is built, we want to find $p$ such that the $p(y | \theta, n)$ is maximum, namely the <em>Maximum Likelihood Estimator</em> or MLE for the
sake of brevity.
$p(y | p, n)$ is a positive quantity for $\theta \in (0, 1)$, and this allows us to take its logarithm, which is a monotone increasing function, and 
this implies that the maximum of $\log p$ is the maximum of $p\,.$</p>

\[\log p(y | \theta, n) \propto y \log \theta + (n-y) \log(1-\theta)\]

\[\frac{\partial \log p(y | \theta, n)}{\partial \theta} = \frac{y}{\theta} + \frac{n-y}{\theta-1}\]

\[\left. \frac{\partial \log p(y | \theta, n)}{\partial \theta}\right|_{\theta=\hat{\theta}} = 0 \Rightarrow \frac{y}{\hat{\theta}} = \frac{n-y}{1-\hat{\theta}} \Rightarrow \hat{\theta}(n-y) = (1-\hat{\theta}) y
\Rightarrow \hat{\theta} n = y\]

<p>Which gives us, again, $\hat{\theta} = \frac{y}{n}\,,$ which is the same value that we got by using the home-brewer textbook’s way.</p>

<p>We can easily verify that it is a maximum:</p>

\[\frac{\partial^2 \log p(y | \theta, n)}{\partial \theta^2} = -(n - y)/(\theta - 1)^2 - y/\theta^2\]

\[\left. \frac{\partial^2 \log p(y | \theta, n)}{\partial \theta^2}\right|_{\theta=\hat{\theta}} =
-\frac{n^3}{y (n - y) }\]

<p>and the last quantity is always negative, for $0&lt;y&lt;n\,.$</p>

<p>The frequentist statistician, however, knows that his estimate for the alive cell
fraction is not exact, and he would like to provide an uncertainty interval
associated to the estimate.
He can use the central limit theorem, which says that, if $n$ is large, then the binomial distribution can be approximated with the normal distribution
with the same mean and variance of the binomial distribution, which corresponds to $\mu = n\hat{\theta}$ and $\sigma^2= n\hat{\theta}(1-\hat{\theta})\,.$
He would use this theorem to provide the $95\%$ Confidence Interval for this distribution.</p>

<p>For a normal distribution with mean $\mu$ and variance $\sigma$ the $95\%$ CI
is given by</p>

\[\mu \pm z_{1-0.05/2}\sigma\]

<p>where $z_{1-0.05/2}=1.96$ is the $0.975$ normal quantile.
So we can easily obtain the $95\%$ confidence interval for $\theta$ as</p>

\[\frac{\mu \pm \sigma}{n} = \hat{\theta} \pm  z_{1-0.05/2} \sqrt{\frac{\hat{\theta}(1-\hat{\theta})}{n}} 
 = \hat{\theta} \pm  1.96 \sqrt{\frac{\hat{\theta}(1-\hat{\theta})}{n}}  = [0.84, 0.94]\]

<p>The calculation is quite straightforward, but one should pay a lot of attention in giving the correct interpretation to this interval.
In the frequentist paradigm, one imagines to repeat the experiment many times, and what one can say is that, by doing this,
if the confidence interval is constructed with the procedure given above, in the $95\%$ of the repetitions it will contain the true
fraction of alive cells.
However, it doesn’t tell us anything about the confidence we have that the fraction of alive cells is in the interval $[0.84, 0.94]\,.$</p>

<p><strong>For the frequentist statistician, the probability that the true value lies inside [0.84, 0.94] is either 1 if it is inside 
or 0 if it is not inside, but he cannot say which one is correct!</strong></p>

<p>This fact is often misinterpreted, even by many researchers and data scientists.</p>

<h2 id="the-bayesian-rookies-way">The Bayesian rookie’s way</h2>

<p>The Bayesian statistician would take the same likelihood for the model, however in his framework the parameter $\theta$ is
simply another random variable, and it is described by some other probability distribution $p(\theta)$ namely by the <strong>prior</strong> associated
to the parameter $\theta\,.$</p>

<p>$\theta$ can take any value between 0 and 1, but he has no preference about any value, so he assumes that $\theta$ is distributed
according to the uniform distribution over $[0, 1]\,.$</p>

\[\theta \sim Uniform(0, 1)\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">beta_binom_model</span><span class="p">:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Uniform</span><span class="p">(</span><span class="sh">'</span><span class="s">theta</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Binomial</span><span class="p">(</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">total</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">alive</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="nf">plot_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/beta_binom/trace_bb.jpg" alt="Alt text" /></p>

<p>He used PyMC to sample $p$ many times according to its posterior probability distribution,
obtained by using the Bayes theorem</p>

\[p(\theta | y, n) \propto p(y | \theta, n) p(\theta)\]

<p>and the sampled values are those shown in the figure.
The details about how does PyMC’s sampler works will be explained in a future post,
as well as the main methods to exclude problems in the sampling procedure.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="nf">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</code></pre></div></div>
<p><img src="/docs/assets/images/beta_binom/posterior_bb.jpg" alt="Alt text" /></p>

<p>We can see that the mean is very close to the MLE value, and the (Bayesian)
$95\%$ CI (which corresponds to the two printed numbers) is close to
 the frequentist one too.
However in this case the interpretation is straightforward:</p>

<p><strong>the Bayesian statistic simply updated his/her initial guess for $p$ by means of Bayes’ theorem.</strong></p>

<p>For the Bayesian statistician there is the $95\%$ of chance that the true
value of $p$ lies inside the $95\%$ CI associated to $\theta$.</p>

<p>Another major advantage of the Bayesian approach is that we did not had to rely
on the Central Limit Theorem, which only holds if the sample is large enough.
The Bayesian approach is always valid, regardless on the size of the sample.</p>

<h2 id="the-wise-bayesians-way">The wise Bayesian’s way</h2>

<p>The wise Bayesian would follow an analogous procedure, he would however
take the less informative prior as possible, where a strongly informative
prior is a prior which influences a lot the posterior probability distribution.
The uniform distribution is not a very informative distribution.
However, as we will show, we can even choose a less informative prior, namely
the <strong>Jeffreys’ prior</strong> for the binomial distribution</p>

\[\theta \sim Beta(1/2, 1/2)\]

<p>where the Beta has pdf</p>

\[p(\theta | \alpha, \beta) = \frac{1}{B(\alpha, \beta) } \theta^\alpha (1-\theta)^\beta\]

<p>and $B(x, y)$ is the Beta function.
However, he knows he knows he must pay a lot of attention, as often -but not
in this case- the Jeffreys’ prior is not a proper prior
(it cannot be integrated to one) <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">beta_binom_model_wise</span><span class="p">:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Beta</span><span class="p">(</span><span class="sh">'</span><span class="s">theta</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nc">Binomial</span><span class="p">(</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">total</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">alive</span><span class="p">)</span>
    <span class="n">trace_wise</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="nf">plot_trace</span><span class="p">(</span><span class="n">trace_wise</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/beta_binom/trace_bb_wise.jpg" alt="Alt text" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="nf">plot_posterior</span><span class="p">(</span><span class="n">trace_wise</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/beta_binom/posterior_bb_wise.jpg" alt="Alt text" /></p>

<p>As we can see, this result is almost identical to the previous one.
In the Bayesian framework one can, and should, investigate the goodness
of his results by trying out different priors and assess how
much does the results on his/her inference depend on the choice of the priors.</p>

<h2 id="conclusions-and-take-home-message">Conclusions and take-home message</h2>

<ul>
  <li>PyMC allows you to easily implement Bayesian models.</li>
  <li>In many cases Bayesian statistics offers results which are more transparent than their frequentist counterparts. We have seen this for a very simple model, but this becomes even more evident as the complexity of the model grows.</li>
  <li>You can apply Bayesian statistics to any kind of problem, even home-brewing!</li>
</ul>

<p>In the <a href="/count/">next</a> example we will apply Bayesian statistics to study
data which can take more than two values.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>This topic will be discussed in a future post. For the moment, if you are curious, you can take a look at the <a href="https://en.wikipedia.org/wiki/Jeffreys_prior#">Wikipedia</a> page. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><category term="course/intro/" /><category term="/beta-binom/" /><summary type="html"><![CDATA[How to describe dichotomous variables]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/docs/assets/images/beta_binom/bar-209148_960_720.jpg" /><media:content medium="image" url="http://localhost:4000/docs/assets/images/beta_binom/bar-209148_960_720.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Why (and when) should you go for Bayesian</title><link href="http://localhost:4000/intro-when-go-bayesian/" rel="alternate" type="text/html" title="Why (and when) should you go for Bayesian" /><published>2023-10-20T00:00:00+02:00</published><updated>2023-10-20T00:00:00+02:00</updated><id>http://localhost:4000/intro-when-go-bayesian</id><content type="html" xml:base="http://localhost:4000/intro-when-go-bayesian/"><![CDATA[<p>I feel I am quite a pragmatic person, so I prefer choosing my tools depending on my needs rather than by relying on some personal believes.
Bayesian statistics allows you to build custom and structured models by simply specifying the data generating process.
The model can be divided into two parts:</p>
<ul>
  <li>The likelihood $p(y \vert \theta)$, which determines how the data you want to model $y$ are generated given the parameter(s) $\theta$.</li>
  <li>The priors $p(\theta)$, which specifies your initial hypothesis about the distribution of the parameters of the model.</li>
</ul>

<p>The only mathematical requirements for both the likelihood and for the priors is that they are non-negative and sum up to one.
There is a huge literature about the model building, and you can easily start by using one of the already available models and adapt it
to your problem.</p>

<p>Once that the model is specified you can use $PyMC$ or any other Probabilistic Programming Language
sample the entire posterior probability distribution,
which is determined by means of Bayes theorem.</p>

\[p(\theta \vert y) = \frac{p(y \vert \theta) p(\theta)}{p(y)} \propto  p(y \vert \theta) p(\theta)\]

<p>Here $\propto$ means proportional to, which means equal up to some multiplicative positive constant,
where by constant we mean independent on $\theta$.
The constant $p(y)$ can be fixed by requiring that $p(\theta \vert y)$ is normalized to one:</p>

\[1 = \int d\theta p(\theta | y) = \frac{1}{p(y)}\int d\theta p(y \vert \theta) p(\theta)\]

<p>so</p>

\[p(y) = \int d\theta p(y|\theta)p(\theta)\,.\]

<p>The fact that you sample the entire probability distribution $p(\theta \vert y)$
makes Bayesian statistics very attractive if you are building a statistical
model to make a decision, as you can easily make inference about any kind of quantity
regarding your model.
This is rarely possible if you only have a point estimate or an interval estimate, as it happens in Machine Learning.</p>

<p>Moreover, Bayesian statistics is easily interpretable: what you are doing
is simply to use the data to update your initial believes.
In fact, in the Bayesian interpretation, $p(\theta)$ represents your opinion about the possible
values that $\theta$ may take before you make an experiment and observe $y\,.$
On the other hand $p(\theta \vert y)$ represents your updated opinion about the value of $\theta$
after the experiment.</p>

<p>So why is not everyone using it? In my experience there are multiple reasons, some of them
are historical, others are more pragmatic.</p>

<p>First of all, the possibility to easily implement a numerical simulation
and to run it within a reasonable amount of time is relatively recent and not
yet spread outside the statistical community.
Bayesian statistics was the only available framework up to the end of the nineteenth 
century, and in has been largely abandoned at the beginning of the last century,
when Fisher and his collaborators developed frequentist statistics.
People in fact considered Bayesian statistics very difficult,
as the normalization factor $p(y)$
can only be computed for a very limited number of models
(the so-called <em>conjugate</em> models).
De Finetti, Savage, Jeffreys and others tried to convince
people to abandon the frequentist framework as they did not considered the
frequentist interpretation satisfactory, but they never managed to convince
the majority of the community.
Things changed when, during the Manhattan project, Metropolis, Von Neumann, Ulam and
others invented the
Markov Chain Monte Carlo methods, and this allowed physicists and later statisticians
too to 
draw random samples from an arbitrary probability distribution.
Moreover, nowadays, the misuse and misinterpretation of tools of frequentist statistics is considered 
one of the main reason for the so-called <em>reproducibility crisis in science</em>
and a <strong>proper</strong> use of Bayesian methods is considered a valid alternative to those
tools <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>.
Of course, Bayesian statistics can be misused too, but there are few very clear guidelines from the academic community which will make this less likely to happen.
Moreover, in most cases, a problem in your model will show up in a problem in your simulation, and this makes Bayesian inference less error-prone than frequentist inference.
In fact, when talking about frequentist statistics or machine learning, most of the time what you are computing
is either an optimization problem or the average of some quantity.
Since what you obtain from this kind of procedure is a number rather than a sample,
in this kind of task may be quite hard to spot.</p>

<p>However, the major practical drawback of Bayesian statistics is that you need to run your
simulation thousands of times, and this may take some time if the number
of parameters in your model is large.
Thus, I do not reccomend you to use Bayesian statistics if your task is a simple
and fast fit-predict problem.</p>

<p>There is another drawback, and this is where these notes come into play:
building a model without a basic knowledge about model building and assessment
is not an easy task. There are many beautiful online courses about Bayesian
statistics in R, which is the most common programming language between statisticians.
The choice of the programming language implies that either you already know R, or you need to learn Bayesian
statistics <em>and</em> R.
This blog is written to make this task simpler for anyone who has a basic knowledge
about Python, and since Python is the most widely spread programming language
in the World, I hope I will help a lot of people.</p>

<p>I hope you enjoyed,</p>

<p>Stefano</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>This is somehow a misleading name, as this crisis is not only affecting academia, but it is a problem in industry too. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>See <a href="https://www.nature.com/articles/533452a">this article on Nature</a> <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>See <a href="https://www.nature.com/articles/520612a">this other article of Nature</a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><summary type="html"><![CDATA[Because there is no silver bullet]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/docs/assets/images/intro/doubt.jpg" /><media:content medium="image" url="http://localhost:4000/docs/assets/images/intro/doubt.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Marks and channels</title><link href="http://localhost:4000/marks-channels/" rel="alternate" type="text/html" title="Marks and channels" /><published>2023-10-14T00:00:00+02:00</published><updated>2023-10-14T00:00:00+02:00</updated><id>http://localhost:4000/marks-channels</id><content type="html" xml:base="http://localhost:4000/marks-channels/"><![CDATA[<p>When we build a data visualization we are building vocabulary
to translate our data into a message, and this vocabulary can be decomposed in 
a certain number of elements.
We always do that, even if you may not conscious about it.
Being aware of this helps us to think about how to better build this vocabulary
and, ultimately, how to make your message more effective.</p>

<p>Here we will discuss these components, together with the
fundamental design principles of data visualization, which are a set of 
guidelines to help us finding the most appropriate representation for our data.</p>

<h2 id="marks-and-channels">Marks and channels</h2>

<p>Marks and channels are the first two fundamental building blocks of a
data visualization.</p>

<h3 id="marks">Marks</h3>
<p>Marks are the geometric elements that we use to identify the items
of our dataset <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>.
Since we are plotting on a two dimensional surface, we can use any geometric entity
with dimensionality less or equal to two to represent our items, so we can use:</p>

<svg height="180" width="95%" style="margin:2%; font-weight: bold">
<text x="30" y="15"> POINTS </text>
  <circle cx="20" cy="40" r="10" fill="steelblue" />
  <circle cx="45" cy="45" r="10" fill="steelblue" />
  <circle cx="70" cy="55" r="10" fill="steelblue" />
  <rect x="100" y="25" width="20" height="20" fill="steelblue" />
  <rect x="100" y="50" width="20" height="20" fill="steelblue" />

<text x="315" y="15"> LINES </text>
<line x1="270" y1="40" x2="420" y2="40" style="color:black; width:20px; stroke:black; stroke-width:3px" />
<line x1="270" y1="80" x2="420" y2="60" style="color:black; width:20px; stroke:black; stroke-width:3px" />
<line x1="270" y1="100" x2="420" y2="120" style="color:black; width:20px; stroke:black; stroke-width:3px" />


<text x="630" y="15"> AREAS </text>
<rect x="600" y="25" width="120" height="80" fill="steelblue" style="stroke:black; stroke-width:3px" />
<rect x="600" y="25" width="80" height="80" fill="steelblue" style="stroke:black; stroke-width:3px" />
<rect x="600" y="25" width="80" height="40" fill="steelblue" style="stroke:black; stroke-width:3px" />
</svg>

<div class="emphbox">
Someone also uses three dimensional objects as markers.
Please, don't! 
<br />
Their encoding implies that we must model the perspective,
and this causes a distortion into our perceived values, making them not suitable
for data visualization.
</div>

<h3 id="channels">Channels</h3>
<p>We then have the channels, and they encode the values of the data associated to our items.</p>

<p>The most commonly channels used to encode quantitative information are</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">Channel</th>
      <th style="text-align: left">Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">Position on aligned axis</td>
      <td style="text-align: left"><svg height="50" width="200"><line x1="10" y1="10" x2="200" y2="10" style="color:black; width:20px; stroke:black; stroke-width:3px"></line> <circle cx="45" cy="10" r="10" fill="grey"></circle> <line x1="10" y1="30" x2="200" y2="30" style="color:black; width:20px; stroke:black; stroke-width:3px"></line> <circle cx="125" cy="30" r="10" fill="grey"></circle></svg></td>
    </tr>
    <tr>
      <td style="text-align: right">Position on unaligned axis</td>
      <td style="text-align: left"><svg height="50" width="200"><line x1="10" y1="10" x2="160" y2="10" style="color:black; width:20px; stroke:black; stroke-width:3px"></line> <circle cx="45" cy="10" r="10" fill="grey"></circle> <line x1="50" y1="30" x2="200" y2="30" style="color:black; width:20px; stroke:black; stroke-width:3px"></line> <circle cx="125" cy="30" r="10" fill="grey"></circle></svg></td>
    </tr>
    <tr>
      <td style="text-align: right">Length</td>
      <td style="text-align: left"><svg height="50" width="200"><line x1="10" y1="10" x2="200" y2="10" style="color:black; width:20px; stroke:black; stroke-width:3px"></line>  <line x1="10" y1="30" x2="150" y2="30" style="color:black; width:20px; stroke:black; stroke-width:3px"></line> </svg></td>
    </tr>
    <tr>
      <td style="text-align: right">Width</td>
      <td style="text-align: left"><svg height="50" width="200"><line x1="10" y1="10" x2="200" y2="10" style="color:black; width:20px; stroke:black; stroke-width:3px"></line>  <line x1="10" y1="30" x2="200" y2="30" style="color:black; width:30px; stroke:black; stroke-width:5px"></line> </svg></td>
    </tr>
    <tr>
      <td style="text-align: right">Angle/Slope</td>
      <td style="text-align: left"><svg height="50" width="200"><line x1="10" y1="10" x2="70" y2="10" style="color:black; width:20px; stroke:black; stroke-width:3px"></line>  <line x1="10" y1="10" x2="70" y2="30" style="color:black; width:20px; stroke:black; stroke-width:3px"></line> <line x1="150" y1="10" x2="200" y2="10" style="color:black; width:20px; stroke:black; stroke-width:3px"></line>  <line x1="150" y1="10" x2="200" y2="40" style="color:black; width:20px; stroke:black; stroke-width:3px"></line></svg></td>
    </tr>
    <tr>
      <td style="text-align: right">Area</td>
      <td style="text-align: left"><svg height="50" width="200"> <circle cx="20" cy="20" r="10" fill="grey"></circle> <circle cx="100" cy="20" r="15" fill="grey"></circle> <circle cx="180" cy="20" r="20" fill="grey"></circle> </svg></td>
    </tr>
    <tr>
      <td style="text-align: right">Color luminance</td>
      <td style="text-align: left"><svg height="50" width="200"> <rect x="5" y="5" height="40" width="40" fill="lightgray"></rect> <rect x="85" y="5" height="40" width="40" fill="gray"></rect><rect x="160" y="5" height="40" width="40" fill="black"></rect>  </svg></td>
    </tr>
    <tr>
      <td style="text-align: right">Color saturation</td>
      <td style="text-align: left"><svg height="50" width="200"> <rect x="5" y="5" height="40" width="40" fill="#61679e"></rect> <rect x="85" y="5" height="40" width="40" fill="#3644c9"></rect><rect x="160" y="5" height="40" width="40" fill="#0019ff"></rect>  </svg></td>
    </tr>
  </tbody>
</table>

<p>On the other hand, if we want to encode a categorical information, we have the following
channels:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">Channel</th>
      <th style="text-align: left">Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">Spatial region</td>
      <td style="text-align: left"><svg height="60" width="200"> <rect x="5" y="5" height="40" width="40" fill="gray"></rect> <rect x="85" y="15" height="40" width="40" fill="gray"></rect><rect x="160" y="5" height="30" width="30" fill="gray"></rect>  </svg></td>
    </tr>
    <tr>
      <td style="text-align: right">Color hue</td>
      <td style="text-align: left"><svg height="50" width="200"> <rect x="5" y="5" height="40" width="40" fill="#a31919"></rect> <rect x="85" y="5" height="40" width="40" fill="#19a319"></rect><rect x="160" y="5" height="40" width="40" fill="#1919a3"></rect>  </svg></td>
    </tr>
    <tr>
      <td style="text-align: right">Shape/Texture</td>
      <td style="text-align: left"><svg height="50" width="200"> <rect x="5" y="5" height="40" width="40" fill="grey"></rect> <circle cx="105" cy="25" r="20" fill="grey"></circle> <polygon points="180,45 160,5 200,5" fill="grey"></polygon> </svg></td>
    </tr>
  </tbody>
</table>

<p>The order of the items in the above tables is not random, but it reflects how easily we
translate the visual information either into a quantity or into different categories,
and this property is called <strong>effectiveness</strong>.</p>

<h3 id="other-components">Other components</h3>

<p>Marks and channels are the components which encode information about our data, but
they are not the only components which constitute a data visualization.
Other components are the ones which allow us to interpret, compare and give context
to our data.</p>

<ul>
  <li>axis</li>
  <li>grids</li>
  <li>annotations</li>
  <li>legends</li>
  <li>labels</li>
  <li>ticks</li>
  <li>reference lines</li>
</ul>

<div class="emphbox"> Annotations may also be used to draw attention to patterns of interest.</div>

<p>Use this components only if they really help your reader.
Remember that, most of the time, you want the reader to easily compare the values of your data, not to be able to assess the exact value of
your data.
You should keep your visualization as clean as possible, and in order to do so:</p>

<ul>
  <li>Avoid useless boxes.</li>
  <li>Don’t use grids if they don’t help understanding the data.</li>
  <li>Avoid too many ticks <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>.</li>
</ul>

<h2 id="design-principles">Design principles</h2>

<p>The above mentioned concept should be applied, as much as possible, according to the
principles of data visualization design.
These principles, that we will discuss in the rest of this post, will allow the reader
to easily understand and decode the visualization, reducing the risk of a misinterpretation and so making the communication between you and your reader clearer.</p>

<h3 id="expressiveness-principle">Expressiveness principle</h3>
<p>The expressiveness principle essentially states that we should make the message
as clear as possible, without neglecting information and, probably most important,
without adding, either implicitly or explicitly, information.</p>

<div class="emphbox">
The visual representation should represent all and
only the relations that exist in the data.
</div>

<p>Some examples of violation to this principle are:</p>
<ul>
  <li>Line chart used to represent categorical data</li>
  <li>Different color intensities to encode different categories</li>
  <li>A diverging color map to represent a quantity that does not have an origin (a zero).</li>
  <li>Using a channel that don’t encode any data.</li>
</ul>

<h3 id="effectiveness-principle">Effectiveness principle</h3>
<p>The effectiveness principle is another principle that
helps us finding the most appropriate channel for each variable.</p>

<div class="emphbox">
The relevance of the information should match the effectiveness of the channel.
</div>

<p>The first obvious consequence of this principle is that the most important variable
should always be encoded by using a spatial dimension.
On the other hand, one should not rely on color to effectively communicate
relevant quantities.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We have first seen what are the main components of any data visualization.
We have then mentioned two important recommendations on how to translate our dataset into
a graph.</p>

<p>You should always keep them in mind, but you should also balance them by taking
into account your audience and your message.</p>

<!-- 
Train!

Establish visual hierarchy (play with contrast, brightness)
data pops, legends and rest of frame supports
put the accent on the relevant data points
don's put boxes. Work with alignments and grids
choose right font

Let you go
Use your hands/easy sketching software (at the beginning you want speed, not perfection)

Review critically
-->

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>If we are representing a network rather than a tabular dataset, they are used to represents the links too. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>The ticks are the graphical components that are used to mark the values of the axis. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><category term="/dataviz/" /><category term="/marks-channels/" /><summary type="html"><![CDATA[The building blocks of data visualization]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/docs/assets/images/markers_channels/markers.png" /><media:content medium="image" url="http://localhost:4000/docs/assets/images/markers_channels/markers.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Data abstraction</title><link href="http://localhost:4000/data-types/" rel="alternate" type="text/html" title="Data abstraction" /><published>2023-10-13T00:00:00+02:00</published><updated>2023-10-13T00:00:00+02:00</updated><id>http://localhost:4000/data-types</id><content type="html" xml:base="http://localhost:4000/data-types/"><![CDATA[<p>Data can come into many different flavors, and in this post we will take a look at how
we can classify them depending on their qualities and on our previous knowledge.</p>

<p>In the simplest case our dataset will consist into a collection of
<strong>items</strong>, and each item will have a set of <strong>attribute</strong>.</p>

<p>In this case we are dealing with a <strong>tabular</strong> dataset.
A more involved case is the one we also have <strong>relationships</strong> between the
items, and in this case we are working with a <strong>network</strong>.</p>

<p>There are also more involved kinds of datasets, which we won’t discuss here for now.
Some examples are field datasets, where one displays the value
of a certain quantity for each point of a discretized space,
or geometry dataset, where one has a collection of shapes belonging to some space.
Field datasets are very common when one deals with weather maps or topography maps, while an example
of geometry dataset is given by a street map or by the map of the regions or of the cities of a certain country.</p>

<p>For the moment we will only focus on tabular datasets.
A tabular dataset can be represented, as the name suggests, with a table:</p>

<table>
  <thead>
    <tr>
      <th>item</th>
      <th>attribute 1</th>
      <th>attribute 2</th>
      <th>…</th>
      <th>attribute N</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>$a_1$</td>
      <td>$b_1$</td>
      <td>…</td>
      <td>$z_1$</td>
    </tr>
    <tr>
      <td>2</td>
      <td>$a_2$</td>
      <td>$b_2$</td>
      <td>…</td>
      <td>$z_2$</td>
    </tr>
    <tr>
      <td>3</td>
      <td>$a_3$</td>
      <td>$b_3$</td>
      <td>…</td>
      <td>$z_3$</td>
    </tr>
    <tr>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
    </tr>
    <tr>
      <td>M</td>
      <td>$a_M$</td>
      <td>$b_M$</td>
      <td>…</td>
      <td>$z_M$</td>
    </tr>
  </tbody>
</table>

<p>Each attribute can be classified in a large number of ways, and here we will only
discuss the main ones.</p>

<p>Here we will mostly follow Tamara Munzner’s textbook
<a href="https://www.cs.ubc.ca/~tmm/vadbook/">Visualization Analysis and Design</a>.</p>

<h2 id="attribute-types">Attribute types</h2>

<p>Attribute types define the mathematical operations that makes sense to do
on an attribute.</p>

<p>If an attribute doesn’t have a natural order we call it <strong>categorical</strong>
or <strong>nominal</strong>.</p>

<p>Examples of nominal attributes are</p>
<ul>
  <li>City names</li>
  <li>Gender (assuming it’s a discrete quantity).</li>
  <li>Eye color</li>
</ul>

<p>If an attribute has a natural order but we can’t define
a distance between their values we say it’s <strong>ordinal</strong>.</p>

<p>Ordinal attributes are</p>
<ul>
  <li>Grade</li>
  <li>Education level</li>
  <li>Sport ranking</li>
</ul>

<p>In this case, it doesn’t makes sense to sum, subtract or do any other
arithmetic operations over the attribute.</p>

<p>If our attribute comes with a concept of distance we have
<strong>quantitative</strong> attributes.</p>

<p>Quantitative attributes can be further sub-classified depending if they
have a natural zero or not.
Attributes which don’t have a natural zero are called <strong>interval</strong> attributes,
while those which have are named <strong>ratio</strong> attributes.</p>

<p>Example of interval attributes are</p>

<ul>
  <li>Temperatures expressed in Fahrenheit or Celsius degrees</li>
  <li>pH</li>
</ul>

<p>While ratio attributes are:</p>

<ul>
  <li>Temperatures expressed in Kelvin degrees</li>
  <li>Length</li>
  <li>Mass</li>
  <li>Any percentage</li>
  <li>Earnings (where negative earning means loss)</li>
</ul>

<p>Moreover, we can also classify any ordered attribute attribute depending on the possible range of values it can take.</p>
<ul>
  <li>A <strong>sequential</strong> attribute is an attribute which can take any value between a minimum and a maximum. Examples of sequential attributes are the day of the week as well as height or weight.</li>
  <li>A <strong>diverging</strong> attribute is an attribute which can be decomposed into two directions, a positive one and a negative one. Examples of diverging attributes are hours of the day (AM/PM), latitude (North/South) or elevation (above or below the sea level).</li>
</ul>

<p>Finally, a <strong>cyclic</strong> attribute is an attribute where the minimum possible value corresponds to the maximum possible value. Examples of cyclic attributes are longitude, hour of the day and day of the week.</p>

<p>From our examples you may have noticed that
a cyclic attribute can be either sequential,
as the hour of the day, or diverging,
as the longitude.</p>

<h2 id="attribute-semantics">Attribute semantics</h2>

<p>The mathematical operations we can perform with an attribute
isn’t of course the only meaningful way we can classify the data.
Another very important aspect of an attribute that we should
consider when choosing how to visualize an attribute is its meaning.
The semantic classification I found more useful in my personal experience is the one used by Tamara Munzner 
in her textbook .</p>

<table>
  <thead>
    <tr>
      <th>Semantic</th>
      <th>Meaning</th>
      <th>Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Key vs Value</td>
      <td>A key attribute is used to identify an element, a value attribute does not</td>
      <td>City name vs city population, date vs temperature</td>
    </tr>
    <tr>
      <td>Spatial</td>
      <td>Our attribute has a geographical connotation</td>
      <td>zip code, latitude, city name</td>
    </tr>
    <tr>
      <td>Temporal</td>
      <td>Our attribute is associated with time</td>
      <td>seconds, day of the week</td>
    </tr>
    <tr>
      <td>Hierarchical</td>
      <td>Two or more attributes have a natural hierarchy</td>
      <td>year, month, day, hour but also continent, country, city</td>
    </tr>
  </tbody>
</table>

<h2 id="conclusions">Conclusions</h2>

<p>Before deciding how to visualize your dataset you must first of all consider
what are the types of the attribute you want to visualize and
whether they have some special connotation.
Here we have seen how to determine the attribute type and the most
common attribute semantic.
In the next post we will discuss some of the most common visualizations
associated with each data type.</p>]]></content><author><name>Stippe</name><email>smaurizio87@protonmail.com</email></author><category term="/dataviz/" /><category term="/data-types/" /><summary type="html"><![CDATA[Thinking about data]]></summary></entry></feed>