<!DOCTYPE html>
<html lang="en"><head>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Causal inference: a general introduction | Data Perspectives</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Causal inference: a general introduction" />
<meta name="author" content="Stippe" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="When association implies causation" />
<meta property="og:description" content="When association implies causation" />
<link rel="canonical" href="http://localhost:4000/causal-intro/" />
<meta property="og:url" content="http://localhost:4000/causal-intro/" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:image" content="http://localhost:4000/docs/assets/images/causal_graphs/dominoes-4020617_960_720.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-09-02T00:00:00+02:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://localhost:4000/docs/assets/images/causal_graphs/dominoes-4020617_960_720.jpg" />
<meta property="twitter:title" content="Causal inference: a general introduction" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Stippe"},"dateModified":"2023-09-02T00:00:00+02:00","datePublished":"2023-09-02T00:00:00+02:00","description":"When association implies causation","headline":"Causal inference: a general introduction","image":"http://localhost:4000/docs/assets/images/causal_graphs/dominoes-4020617_960_720.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/causal-intro/"},"url":"http://localhost:4000/causal-intro/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
</head>
<body><header class="site-header">

<div>
  <div class="wrapper" style="display:flex;"><a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" /></a><nav class="site-nav" style="display:flex;">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about">About me</a><a class="page-link" href="/index">Home</a><a class="page-link" href="/notes">List of the notes</a><a class="page-link" href="/links">Some useful resources</a></div>
      </nav></div>
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Causal inference: a general introduction</h1>
    <p class="post-meta"><time class="dt-published" datetime="2023-09-02T00:00:00+02:00" itemprop="datePublished">
        Sep 2, 2023
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="causality-as-counterfactual-evidence">Causality as counterfactual evidence</h2>

<p>In the last years causal inference gained a lot of attention, both from academia and outside from it.
Of course, you heard that <em>association does not imply causation</em>, as you will find an association
between ice-cream consumption and the number of deaths by drowing.
However, outside from the classes for statisticians, the very important question <em>when does association imply causation</em>
is rarely discussed.
We should first try and clarify what do we mean by causation, as the popular concept of causation
is too vague for any rigorous discussion.
This topic has been debated is philosophy since centuries, and if you are interested about this aspect
I found <a href="https://iep.utm.edu/causation/">this</a> introductory article very helpful.</p>

<p>We won’t dig into the philosophical debate, and simply use the <strong>counterfactual</strong> approach:
we say that an action $T$, which is usually called treatment or intervention,
causes $Y$ if, $T$ changes, then $Y$ changes, so then when the cause $T$ disappears, then the effect $Y$ disappears too.
Our definition implies that we must switch off $T$ so,
in order for our definition to be meaningful, we must be able <em>at least hypothetically</em>
to manipulate $T$, and in this case we say that $T$ is <strong>manipulable</strong>.</p>

<p>A meaningful question is if a medicine cures the illness, as we may or may not take the medicine,
but we cannot ask whether age causes heart attack, as we can hardly imagine to change one person’s age.
The concept of manipulability depends on the context, as we may ask if increasing age causes a reduction
in the chances to be considered for a certain working position. In this case we may manipulate the age by simply
changing it on the CV and check if the company calls for a job interview.</p>

<p>The counterfactual definition is not precise enough,
as it may happen that $Y$ appears only when both $T$ and $Z$ appears, so in this
case an obvious question is whether $T$ or $Z$ is the cause of $Y$.
We will always assume that we want to investigate only one cause at time, so either we want to determine
if, given $T$, then $Z$ is a cause of $Y$ or vice versa if, given $Z$, then $T$ causes $Y$.
This imply that, when we investigate causality, we must change the hypothetical cause
by keeping everything else unchanged.</p>

<p>A very common source of confusion is the question causal inference tries and answer:
as explained in Gelman’s preprint <a href="https://arxiv.org/pdf/1003.2619.pdf">Causality and Statistical Learning</a>
when talking about causality, there are two main questions one could ask:</p>
<ul>
  <li>backward causal inference: what are the causes of a given effect?</li>
  <li>forward causal inference: what are the effects of a given cause?</li>
</ul>

<p>While there are many accepted methods to investigate the forward causal inference,
backward causal inference is a slippery terrain, as one could also 
say that the cause of the cause is the cause.
In fact, it is not uncommon to have that $A$ causes $B$, $B$ causes $C$ and $C$ causes $D$,
and in this case we will consider both $A$, $B$ and $C$ as causes of $D$.</p>

<h2 id="the-fundamental-problem-of-causal-inference">The fundamental problem of causal inference</h2>

<p>Let us assume for now that $T$ is a binary quantity with values $0$ and $1$, and let us indicate
the value of $Y$ when $T=0$ as $y_0$ while $y_1$ is the value of $Y$ whet $T=1$.
In order to assess whether $T$ causes $Y$ we must compare $y_1$ with $y_0$.</p>

<p>The exact way we want to compare these two quantities depends on the context.
Most of the time what one wants to quantify is the so called effect, defined as $\delta = y_1-y_0$, but in some cases one may prefer to
obtain informations about the relative risk $y_1/y_0$.
In any case, what we want to do is to compare both quantities and verify if they differ.</p>

<p>In most textbooks one defines the function</p>

\[Y(\tau) = \tau y_1 + (1-\tau) y_0\]

<p>so</p>

\[\delta = Y(1) - Y(0)\]

<p>One generally refers to the quantities $Y(0)$ and $Y(1)$ as the potential outcomes.
More precisely, the potential outcome is represented by the previous quantities before the experiment,
while during the experiment one measures the observed outcome, and the remaining quantity is the counterfactual outcome.
Since we assume that these quantities are the same, we will always refer to the potential outcomes.</p>

<p>As we previously stated, $y_1$ and $y_0$ represent $Y$ when $T=1$ or $0$ respectively, but everything else is
unchanged. This makes always impossible to measure the causal effect, as we cannot simultaneously realize $T=0$
and $T=1$ by keeping everything else, included the moment and the individual, unchanged,
and this is called the <strong>fundamental problem of causal inference</strong>.</p>

<p>In order to better understand why this is a problem, let us assume that we have a population,
and that we somehow split the population into two subpopulation.
The first subpopulation is then treated, so they are assigned to the $T=1$ group,
while the second one is not, and for them $T=0$.
We then take the average on each subpopulation what we are estimating is
$\mathbb{E}[Y | T=1]$ and $\mathbb{E}[Y | T=0]$ respectively.
On the other hand, what we really want to quantify in order to assess the average effect over the entire population is</p>

\[\mathbb{E}[\delta] = \mathbb{E}[Y(1) - Y(0)] = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]\]

<p>This quantity is called the <strong>average treatment effect</strong> (ATE).</p>

<p>Let us indicate with $y^i_\tau$ the observed outcome on the individual $i$ of the population
when this undergoes to treatment $\tau$.
We generally have that the outcome will both on the treatment and on some set of
relevant covariate (auxiliary quantities) $X$, that we assumed we measured for each individual.</p>

<table>
  <thead>
    <tr>
      <th>i</th>
      <th>T</th>
      <th>Y</th>
      <th>Y(0)</th>
      <th>Y(1)</th>
      <th>X</th>
      <th>Y(1) - Y(0)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>$y^1_0$</td>
      <td>$y^1_0$</td>
      <td>$y^1_1=?$</td>
      <td>$x^1$</td>
      <td>$y^1_1-y^1_0=?$</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>$y^2_0$</td>
      <td>$y^2_0$</td>
      <td>$y^2_1=?$</td>
      <td>$x^2$</td>
      <td>$y^2_1-y^2_0=?$</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>$y^3_0$</td>
      <td>$y^3_0$</td>
      <td>$y^3_1=?$</td>
      <td>$x^3$</td>
      <td>$y^3_1-y^3_0=?$</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1</td>
      <td>$y^4_1$</td>
      <td>$y^4_0=?$</td>
      <td>$y^4_1$</td>
      <td>$x^4$</td>
      <td>$y^4_1-y^4_0=?$</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1</td>
      <td>$y^5_1$</td>
      <td>$y^5_0=?$</td>
      <td>$y^5_1$</td>
      <td>$x^5$</td>
      <td>$y^5_1-y^5_0=?$</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1</td>
      <td>$y^6_1$</td>
      <td>$y^6_0=?$</td>
      <td>$y^6_1$</td>
      <td>$x^6$</td>
      <td>$y^6_1-y^6_0=?$</td>
    </tr>
  </tbody>
</table>

<p>Let us stuck for a moment to the frequentist framework, we have that</p>

\[\begin{aligned}
&amp;
\mathbb{E}[Y | T=0] = \frac{y^1_0 + y^2_0 + y^3_0}{3}
\\
&amp;
\mathbb{E}[Y | T=1] = \frac{y^4_1 + y^5_1 + y^6_1}{3}
\end{aligned}\]

<p>on the other hand</p>

\[\begin{aligned}
&amp;
\mathbb{E}[Y(0)] = \frac{y^1_0 + y^2_0 + y^3_0 + y^4_0 + y^5_0 + y^6_0}{6}
\\
&amp;
\mathbb{E}[Y(1)] = \frac{y^1_1 + y^2_1 + y^3_1 + y^4_1 + y^5_1 + y^6_1}{6}
\end{aligned}\]

<p>We cannot measure the quantities marked with the question mark,
so the fundamental problem of causal inference is a missing value problem.
The different terms entering into the two expressions don’t allow us
to simply substitute the associational quantities with the causal ones,
and this is why association is not causation.</p>

<p>As we will show briefly, however, when a set of rather stringent condition
holds, we are allowed to replace the causal quantities with the associational ones.</p>

<p>The stronger condition that might hold is <strong>ignorability</strong>, also called <strong>exchangeability</strong></p>

\[Y(0), Y(1) \perp\!\!\!\!\perp T\]

<p>The same requirement can be stated as:</p>

\[p(T | Y(0), Y(1)) = p(T)\]

<p>We are thus assuming that the probability of being treated, given the potential outcomes, is both independent on the potential outcomes and on any other quantity.
This is of course a very strong assumption, and the fact that in most observational
studies this condition is not met implies a wrong estimation of the effect.
As an example, if we are performing an observational study on a medicine, usually only people which
are sick and so will benefit by the medicine, will take the medicine and, so, will be included in the
treated group, while in the untreated group we may have sick people as well as healthy people.</p>

<p>The ignorability assumption states that we must be allowed to exchange the two groups without affecting the outcome.
Under this condition we have that</p>

\[\mathbb{E}[Y | T=1] - \mathbb{E}[Y | T=0] = \mathbb{E}[Y(1) | T=1] - \mathbb{E}[Y(0) | T=0] = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)] = \mathbb{E}[Y(1)-Y(0)] = \mathbb{E}[\delta]\]

<p>In the previous equation we used another important assumption:</p>

\[\mathbb{E}[Y | T=t] = \mathbb{E}[Y(t) | T=t]\]

<p>This only holds if we assume that, if $T=t$, then $Y = Y(T=t)$.
This assumption goes under the name on <strong>consistency</strong>, and it is not only a mathematical
requirement, but an operational one.
Consistency requires that the treatment must be well specified:
the treatment must not be “get some medicine” but should rather be “take 15 mg of medicine every 8 hours for 7 days”.</p>

<p>A slightly weaker condition with respect to ignorability is <strong>conditional ignorability</strong> or <strong>unconfoundedness</strong></p>

\[Y(0), Y(1) \perp\!\!\!\!\perp T | X\]

<p>So given the confounders $X$, the treatment probability $T$ is independent on the
potential outcome.</p>

\[p(T | Y(0), Y(1), X) = p(T | X)\]

<p>Let us assume we want to quantify the blood pressure reduction of a medicine.
It is more likely that people with a high blood pressure will take it.
We furthermore assume that the effect is higher on people with a high blood pressure.</p>

<p>Since it is more likely that people with high blood pressure will take the treatment,
ignorability doesn’t generally hold in observational studies.
We can randomly sample from the population to overcome this, but it will be very hard to obtain
a representative sample of the population.
An easier way is to stratify by initial blood pressure,
and for each stratum randomly assign with a given probability
to the treatment group or to the test group, and in this way we are fulfilling conditional
ignorability.</p>

<p>Thus, unconfoundedness states that we are “controlling for” all the relevant quantities which
may affect the outcome, except the treatment.
This may only approximately hold: if the outcome depends on some genetic aspect of the individual
which is more common in a particular ethnic group, controlling for ethnicity would partially fulfill 
unconfoundedness.</p>

<p>When we assign the population we must be sure that, for each stratum,
both groups have at least one individual:</p>

\[0 &lt; P(T=t | X) &lt; 1 \, \forall t\]

<p>The previous hypothesis is named the positivity assumption.
Positivity implies that we can compare the treatment effect with the control for each value of the
covariates, since
for each subgroup we both have units which receive the treatment and units which
does not receive it.</p>

<p>If conditional ignorability holds:</p>

\[\begin{aligned}
 \mathbb{E}[Y(1)-Y(0)|X] 
 &amp; = \mathbb{E}[Y(1)|X] - \mathbb{E}[Y(0)|X] \\
 &amp; = \mathbb{E}[Y(1)| T=1, X] - \mathbb{E}[Y(0)|T=0, X] \\
 &amp; = \mathbb{E}[Y| T=1, X] - \mathbb{E}[Y|T=0, X] \\
\end{aligned}\]

<p>By taking the average over $X$</p>

\[\mathbb{E}[\delta] = \mathbb{E}[Y(1) - Y(0)] = \mathbb{E}_X[ \mathbb{E}[Y(1) - Y(0) | X] ] 
 = \mathbb{E}_X[ \mathbb{E}[Y |T=1, X] ] - \mathbb{E}_X[ \mathbb{E}[Y |T=0, X] ]\]

<p>The equality between the first and the last term of this equation is called the <strong>adjustment formula</strong>.</p>

<p>Let us now write explicitly the adjustment formula for $X$ discrete:</p>

\[\begin{align}
&amp;
\mathbb{E}_X[ \mathbb{E}[Y |T=1, X] ] - \mathbb{E}_X[ \mathbb{E}[Y |T=0, X] ]  
\\
&amp; =  \sum_{x}P(X=x) \sum_{y} y \left(P(Y=y|T=1, X=x) - P(Y=y| T=0, X=x) \right) \\
&amp; =   \sum_{x}P(X=x) \sum_{y} y \left(\frac{P(Y=y,T=1, X=x)}{P(T=1, X=x)} - \frac{P(Y=y,T=0, X=x)}{P(T=0, X=x)}\right) \\
= &amp; \sum_{x}P(X=x) \sum_{y} y \left(\frac{P(Y=y,T=1, X=x)}{P(T=1| X=x) P(X=x)} - \frac{P(Y=y,T=0, X=x)}{P(T=0| X=x) P(X=x)}\right) 
\\
&amp; = 
\sum_{x}\sum_{y} y \left(\frac{P(Y=y,T=1, X=x)}{P(T=1| X=x)} - \frac{P(Y=y,T=0, X=x)}{P(T=0| X=x)}\right) 
\end{align}\]

<p>The first equivalence comes from the definition of conditional probability,
the second one from the hypothesis that $P(T, X) = P(T | X) P(X) $ so that $T$ causally depends on $X\,.$
You should notice that the denominators are finite thanks to the positivity hypothesis.</p>

<p>There is one more hypothesis that we have hidden into our discussion:
we have been assuming all the time that the outcome of the i-th unit only depend on the i-th treatment unit,
and does not depends on the other treatment’s unit.
This requirement is of course not always satisfied, and it’s called the <strong>no interference</strong> assumptions:</p>

\[Y_i(t_1, t_2, ..., t_{i-1}, t_i, t_{i+1}, ..., t_n) = Y_i(t_i)\]

<p>So each individual’s outcome only depends on his own treatment and not on the treatment of other individuals.
This implies that, if we are checking the effect of a product in some tomato field, we must be sure that the product does not goes in another studied field by mistake.
Another case can be a study where we are studying an experimental study program in a class.
If a student is selected in the treatment group and a friend of his is not, the latter could be sad for not being selected and his outcome could be lowered.
Generally, a good strategy to enforce this requirement is to take well separated units and isolating each unit from the other units during the experiment.</p>

<h2 id="conclusion-and-take-home-message">Conclusion and take home message</h2>

<p>As we can see, under some strict assumptions we can perform causal inference in observational studies as well as in randomized studies.
However, quoting Cochran:</p>

<p><strong><em>observational studies are are interesting and challenging field which demands a good deal of humility, since our claim are groping toward the truth.</em></strong></p>

<h2 id="additional-readings">Additional readings</h2>

<p><a href="https://www.hsph.harvard.edu/wp-content/uploads/sites/1268/2022/11/hernanrobins_WhatIf_13nov22.pdf">Hernàn, Robins; <strong>Causal inference, what if</strong>, Chapman &amp; Hall/CRC (2020)</a></p>

  </div><a class="u-url" href="/causal-intro/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Stippe</li>
          <li><a class="u-email" href="mailto:smaurizio87@protonmail.com">smaurizio87@protonmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>

