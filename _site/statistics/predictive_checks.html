<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Predictive checks | Data Perspectives</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Predictive checks" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Verifying the predictions of your model" />
<meta property="og:description" content="Verifying the predictions of your model" />
<link rel="canonical" href="http://localhost:4000/statistics/predictive_checks" />
<meta property="og:url" content="http://localhost:4000/statistics/predictive_checks" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-01-22T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Predictive checks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2024-01-22T00:00:00+00:00","datePublished":"2024-01-22T00:00:00+00:00","description":"Verifying the predictions of your model","headline":"Predictive checks","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/predictive_checks"},"url":"http://localhost:4000/statistics/predictive_checks"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;"><ul hidden='hidden' id="postList"><li>
                        Introduction to this section;/statistics/other_intro;1
                </li><li>
                        Splines regression;/statistics/splines;2
                </li><li>
                        Introduction to non-parametric models;/statistics/nonparametric;3
                </li><li>
                        The autoregressive model;/statistics/autoregressive;4
                </li><li>
                        Introduction to time series modelling;/statistics/time_series;5
                </li><li>
                        Synthetic control;/statistics/synthetic_control;6
                </li><li>
                        Regression discontinuity ;/statistics/discontinuity_regression;7
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;8
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;9
                </li><li>
                        Randomized controlled trials;/statistics/randomized;10
                </li><li>
                        Causal inference;/statistics/causal_intro;11
                </li><li>
                        Random models and mixed models;/statistics/random_models;12
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;13
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;14
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;15
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;16
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;17
                </li><li>
                        Poisson regression;/statistics/poisson_regression;18
                </li><li>
                        Logistic regression;/statistics/logistic_regression;19
                </li><li>
                        Robust linear regression;/statistics/robust_regression;20
                </li><li>
                        Introduction to the linear regression;/statistics/regression;21
                </li><li>
                        Model comparison;/statistics/model_averaging;22
                </li><li>
                        Predictive checks;/statistics/predictive_checks;23
                </li><li>
                        Trace inspection;/statistics/trace_inspection;24
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;25
                </li><li>
                        Mixture models;/statistics/mixture;26
                </li><li>
                        Multidimensional distributions;/statistics/categories;27
                </li><li>
                        Exponential model, gaussian model and their evolutions;/statistics/reals;28
                </li><li>
                        The Negative Binomial model;/statistics/negbin;29
                </li><li>
                        The Poisson model;/statistics/poisson;30
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;31
                </li><li>
                        Common continuous probabilities;/statistics/common_continuous_probabilities;32
                </li><li>
                        Common discrete probabilities;/statistics/common_discrete_probabilities;33
                </li><li>
                        How does MCMC works;/statistics/mcmc_intro;34
                </li><li>
                        Introduction to Bayesian inference;/statistics/bayes_intro;35
                </li><li>
                        Design tricks;/dataviz/design-introduction;36
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;37
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;38
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;39
                </li><li>
                        Visual queries;/dataviz/visual-queries;40
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;41
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;42
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;43
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;44
                </li><li>
                        Perception;/dataviz/perception;45
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;46
                </li><li>
                        Marks and channels;/dataviz/marks-channels;47
                </li><li>
                        Data abstraction;/dataviz/data-types;48
                </li><li>
                        Data visualization;/dataviz/dataviz;49
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/trace_inspection" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/model_averaging" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">Predictive checks</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-01-22T00:00:00+00:00" itemprop="datePublished">
        Jan 22, 2024
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  4&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In this post we will collect two different
phases of the Bayesian workflow, namely the
<strong>prior predictive checks</strong> and the
<strong>posterior predictive checks</strong>.</p>

<p>The first one is aimed to ensure that your priors
are compatible with the current domain knowledge,
and it doesn’t require the comparison of the model
prediction with the true data.</p>

<p>The posterior predictive checks, instead, are focused
on clarifying if your fitted model can catch the relevant
aspects of the data.</p>

<p>While the two phases are in principle different,
they use similar methods, and for this reason
they are collected in a single post.</p>

<h2 id="prior-predictive-checks">Prior predictive checks</h2>

<p>When you are performing a prior predictive check,
you are verifying if your model is flexible
enough to include what you know about the problem.</p>

<p>There are many ways you can perform this,
and this can be done by generating fake data
according to what you know about the problem
and then fit them.</p>

<p>If you know nothing, you may decide to pick a 
dataset sub-sample and ensure that it is included
within the prior predictive. Remember,
however, that you do not want to <em>fit</em> the sub-sample,
otherwise you may end up overfitting your data.</p>

<h2 id="the-twitter-data-again">The twitter data again</h2>

<p>Let us consider again the dataset introduced
in the <a href="/statistics/negbin">post on the Negative Binomial</a>.
We already discussed some checks in that post,
and we carefully chose the value of the parameters
by making an educated guess on the order of magnitude
of the interactions.</p>

<p>Let us now assume that this time we made some
error in the procedure and we take</p>

\[\begin{align}
\theta &amp; \sim \mathcal{B}(1/2, 1/2)\\
\nu &amp; \sim \mathcal{Exp}(20)
\end{align}\]

<p>It is not rare to mess up with the parametrization,
so we may have confused $\lambda$ with its inverse
(it is more common than what you may imagine).
While the imported libraries and the data are the same,
this time the model reads as follows</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">pp0</span><span class="p">:</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s">'nu'</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Beta</span><span class="p">(</span><span class="s">'theta'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">NegativeBinomial</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">nu</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="p">)</span>
</code></pre></div></div>

<p>Let us now sample the prior predictive</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pp0</span><span class="p">:</span>
    <span class="n">prior_pred_pp0</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_prior_predictive</span><span class="p">()</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span>
<span class="n">prior_pred_pp0</span><span class="p">.</span><span class="n">prior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/predictive/prior_predictive.webp" alt="The histogram of the prior predictive distribution" /></p>

<p>We can see that the value $y=0$ has a probability
greater than the $90\%.$
Let us now compute this probability.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">prior_pred_pp0</span><span class="p">.</span><span class="n">prior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span>
    <span class="n">prior_pred_pp0</span><span class="p">.</span><span class="n">prior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<div class="code">
0.975
</div>

<p>It doesn’t really make much sense to start
from a model which predicts that the $97\%$
of our tweets have zero interaction.</p>

<p>At this point, a wise Bayesian would go back and
check again the model. Let us see what happens
to the unwise Bayesian who fits the model
despite the unreasonable conclusion which
follows from the prior.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pp0</span><span class="p">:</span>
    <span class="n">trace_pp0</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_pp0</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/predictive/trace-wrong.webp" alt="The trace plot of the unwise Bayesian" /></p>

<p>With the old model, the value of $\nu$
was peaked at $\nu = 2\,,$
while this time we have a peak at around $0.8\,.$
This means that our inference is strongly
biased by our prior.
In fact, our posterior predictive
is much worse that the one in the old post.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pp0</span><span class="p">:</span>
    <span class="n">pp</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">pp</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/predictive/posterior_predictive.webp" alt="The posterior predictive plot" /></p>

<p>While our old model gave us,
on average, the correct probability for the tweet
with the lowest interaction number,
this time we overestimate the number
of tweets with few interactions.</p>

<p>Also in this case, the wise Bayesian would
stop and go back to the model construction.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We discussed how to implement some prior predictive
and posterior predictive check,
together with the risks that comes by
not doing them.</p>

  </div><a class="u-url" href="/statistics/predictive_checks" hidden></a>

  <div>
          
          
  </div>

  <br>
  <div id='autograph'>
          Stippe Jan 22, 2024

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>

                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

