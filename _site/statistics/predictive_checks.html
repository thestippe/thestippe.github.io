<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Predictive checks | Data Perspectives</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Predictive checks" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Verifying the predictions of your model" />
<meta property="og:description" content="Verifying the predictions of your model" />
<link rel="canonical" href="http://localhost:4000/statistics/predictive_checks" />
<meta property="og:url" content="http://localhost:4000/statistics/predictive_checks" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-09-25T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Predictive checks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2024-09-25T00:00:00+00:00","datePublished":"2024-09-25T00:00:00+00:00","description":"Verifying the predictions of your model","headline":"Predictive checks","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/predictive_checks"},"url":"http://localhost:4000/statistics/predictive_checks"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;">

                
                
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    
                    
                    
                    
                    

        <ul hidden='hidden' id="postList"><li>
                        Fitting complex models;/statistics/complex_models;1
                </li><li>
                        Directional statistics;/statistics/directional;2
                </li><li>
                        Horseshoe priors;/statistics/horseshoe;3
                </li><li>
                        MRP;/statistics/mrp;4
                </li><li>
                        Application of the Lotka-Volterra model;/statistics/lotka_volterra;5
                </li><li>
                        Differential equations;/statistics/ode;6
                </li><li>
                        Dirichlet Process Mixture Models;/statistics/dp;7
                </li><li>
                        Bayesian Additive Regression Trees;/statistics/bart;8
                </li><li>
                        Splines;/statistics/spline;9
                </li><li>
                        Gaussian processes regression;/statistics/gp_example;10
                </li><li>
                        Gaussian processes;/statistics/gp;11
                </li><li>
                        Nonparametric models;/statistics/nonparametric_intro;12
                </li><li>
                        Stochastic volatility models;/statistics/stochastic_volatility;13
                </li><li>
                        Time series;/statistics/time_series;14
                </li><li>
                        Structural time series;/statistics/structural_time_series;15
                </li><li>
                        Quantile regression;/statistics/extreme_quantile;16
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;17
                </li><li>
                        Accelerated Failure Time models;/statistics/survival_example_aft;18
                </li><li>
                        Application of survival analysis with discrete times;/statistics/survival_example_2;19
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;20
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;21
                </li><li>
                        Regression discontinuity design;/statistics/rdd;22
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;23
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;24
                </li><li>
                        Randomized controlled trials;/statistics/randomized;25
                </li><li>
                        Causal inference and Bayesian networks;/statistics/causal_intro_2;26
                </li><li>
                        Causal inference;/statistics/causal_intro;27
                </li><li>
                        Nested factor;/statistics/nested_factors;28
                </li><li>
                        Repeated measures;/statistics/repeated_measures;29
                </li><li>
                        Split plot design;/statistics/split_plot;30
                </li><li>
                        Crossover design;/statistics/crossover;31
                </li><li>
                        Latin square design;/statistics/latin_square;32
                </li><li>
                        Full factorial design;/statistics/full_factorial;33
                </li><li>
                        Completely randomized design;/statistics/crd;34
                </li><li>
                        Design of experiments;/statistics/doe;35
                </li><li>
                        Validity;/statistics/validity;36
                </li><li>
                        Stratification;/statistics/stratification;37
                </li><li>
                        Random sampling;/statistics/random_sampling;38
                </li><li>
                        Data collection;/statistics/data_collection;39
                </li><li>
                        Things that could go wrong;/statistics/problem_solving_issues;40
                </li><li>
                        The problem solving workflow;/statistics/problem_solving;41
                </li><li>
                        Time_series;/time_series;42
                </li><li>
                        Survival_example_2;/survival_example_2;43
                </li><li>
                        Survival_example;/survival_example;44
                </li><li>
                        Survival_analysis;/survival_analysis;45
                </li><li>
                        Structural_time_series;/structural_time_series;46
                </li><li>
                        Spline;/spline;47
                </li><li>
                        Ode;/ode;48
                </li><li>
                        Nonparametric_intro;/nonparametric_intro;49
                </li><li>
                        Mrp;/mrp;50
                </li><li>
                        Lotka_volterra;/lotka_volterra;51
                </li><li>
                        Horseshoe;/horseshoe;52
                </li><li>
                        Gp_example;/gp_example;53
                </li><li>
                        Gp;/gp;54
                </li><li>
                        Extreme_intro;/extreme_intro;55
                </li><li>
                        Dp;/dp;56
                </li><li>
                        Bart;/bart;57
                </li><li>
                        Mixed effects models with more than two levels;/statistics/three_levels;58
                </li><li>
                        Leveraging mixed-effect models;/statistics/bambi_multilevel;59
                </li><li>
                        Rdd;/rdd;60
                </li><li>
                        Difference_in_differences;/difference_in_differences;61
                </li><li>
                        Instrumental_variable;/instrumental_variable;62
                </li><li>
                        Randomized;/randomized;63
                </li><li>
                        Causal_intro_2;/causal_intro_2;64
                </li><li>
                        Causal_intro;/causal_intro;65
                </li><li>
                        Nested_factors;/nested_factors;66
                </li><li>
                        Repeated_measures;/repeated_measures;67
                </li><li>
                        Split_plot;/split_plot;68
                </li><li>
                        Crossover Design;/crossover-design;69
                </li><li>
                        Latin_square;/latin_square;70
                </li><li>
                        Full_factorial;/full_factorial;71
                </li><li>
                        Crd;/crd;72
                </li><li>
                        Doe;/doe;73
                </li><li>
                        Validity;/validity;74
                </li><li>
                        Random_sampling;/random_sampling;75
                </li><li>
                        Data_collection;/data_collection;76
                </li><li>
                        Problem_solving_issues;/problem_solving_issues;77
                </li><li>
                        Problem_solving;/problem_solving;78
                </li><li>
                        Three_levels;/three_levels;79
                </li><li>
                        Bambi_multilevel;/bambi_multilevel;80
                </li><li>
                        Random models and mixed models;/statistics/random_models;81
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;82
                </li><li>
                        OpenEO for SAR images;/gis/openeo_sar;83
                </li><li>
                        Folium;/gis/folium;84
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;85
                </li><li>
                        OpenEO;/gis/openeo;86
                </li><li>
                        Poisson regression;/statistics/poisson_regression;87
                </li><li>
                        Open Street Map services;/gis/openstreetmap;88
                </li><li>
                        Logistic regression;/statistics/logistic_regression;89
                </li><li>
                        Open Web Consortium standards;/gis/owc_standards;90
                </li><li>
                        Robust linear regression;/statistics/robust_regression;91
                </li><li>
                        Map design;/gis/map_design;92
                </li><li>
                        Multi-linear regression;/statistics/multivariate_regression;93
                </li><li>
                        Operations on raster data;/gis/raster_ops;94
                </li><li>
                        Linear regression with binary input;/statistics/regression_binary_input;95
                </li><li>
                        Operations on vector data;/gis/vector_ops;96
                </li><li>
                        Introduction to the linear regression;/statistics/regression;97
                </li><li>
                        101 ways to reproject your data;/gis/pyproj;98
                </li><li>
                        Model comparison, cont.;/statistics/model_averaging_cont;99
                </li><li>
                        Model comparison;/statistics/model_averaging;100
                </li><li>
                        Raster data;/gis/raster_data;101
                </li><li>
                        Vector data;/gis/vector_data;102
                </li><li>
                        Choosing the right projection;/gis/projections;103
                </li><li>
                        Introduction to geographic data analysis;/gis/gis_intro;104
                </li><li>
                        Re-parametrizing your model;/statistics/reparametrization;105
                </li><li>
                        Predictive checks;/statistics/predictive_checks;106
                </li><li>
                        Trace inspection;/statistics/trace_inspection;107
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;108
                </li><li>
                        Mixture models;/statistics/mixture;109
                </li><li>
                        Multidimensional distributions;/statistics/categories;110
                </li><li>
                        The Gaussian model;/statistics/reals;111
                </li><li>
                        Bonus: counting animals in a park;/statistics/hypergeom;112
                </li><li>
                        The Negative Binomial model;/statistics/negbin;113
                </li><li>
                        The Poisson model;/statistics/poisson;114
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;115
                </li><li>
                        Section introduction;/statistics/simple_models_intro;116
                </li><li>
                        Some notation about probability;/statistics/probability_reminder;117
                </li><li>
                        How does MCMC works;/statistics/mcmc_intro;118
                </li><li>
                        Introduction to Bayesian inference;/statistics/bayes_intro;119
                </li><li>
                        An overview to statistics;/statistics/preface;120
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;121
                </li><li>
                        Design tricks;/dataviz/design-introduction;122
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;123
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;124
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;125
                </li><li>
                        Visual queries;/dataviz/visual-queries;126
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;127
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;128
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;129
                </li><li>
                        Perception;/dataviz/perception;130
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;131
                </li><li>
                        Marks and channels;/dataviz/marks-channels;132
                </li><li>
                        Data abstraction;/dataviz/data-types;133
                </li><li>
                        Data visualization;/dataviz/dataviz;134
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/trace_inspection" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/reparametrization" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">Predictive checks</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-09-25T00:00:00+00:00" itemprop="datePublished">
        Sep 25, 2024
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  6&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In this post we will collect two different
phases of the Bayesian workflow, namely the
<strong>prior predictive checks</strong> and the
<strong>posterior predictive checks</strong>.</p>

<p>The first one is aimed to ensure that your priors
are compatible with the current domain knowledge,
and it doesn’t require the comparison of the model
prediction with the true data.</p>

<p>The posterior predictive checks, instead, are focused
on clarifying if your fitted model can catch the relevant
aspects of the data.
You should always keep in mind that, even if it does a good job in
describing the known data, this does not imply that
the model will be successful in predicting future observations.</p>

<p><br /></p>

<blockquote>
  <p>I believe that it is possible to learn from experience. That is where
my faith comes in. And I think that all scientists who believe the same are consciously
or unconsciously exercising an act of faith.</p>

  <p>J. O. Irwin</p>
</blockquote>

<p><br /></p>

<p>While the two phases are in principle different,
they use similar methods, and for this reason
they are collected in a single post.</p>

<h2 id="prior-predictive-checks">Prior predictive checks</h2>

<p>When you are performing a prior predictive check,
you are verifying if your model is flexible
enough to include what you know about the problem and that you are
implementing the appropriate constraints.</p>

<p>There are many ways you can perform this,
and this can be done by generating fake data
according to what you know about the problem
and then fit them.</p>

<p>If you know nothing, you may decide to pick a 
dataset sub-sample and ensure that it is included
within the prior predictive. Remember,
however, that you do not want to <em>fit</em> the sub-sample,
otherwise you may end up overfitting your data.</p>

<h2 id="the-twitter-data-again">The twitter data again</h2>

<p>Let us consider again the dataset introduced
in the <a href="/statistics/negbin">post on the Negative Binomial</a>.
We already discussed some checks in that post,
and we carefully chose the value of the parameters
by making an educated guess on the order of magnitude
of the interactions.</p>

<p>Let us now assume that this time we made some
error in the procedure and we take</p>

\[\begin{align}
\theta &amp; \sim \mathcal{B}(1/2, 1/2)\\
\nu &amp; \sim \mathcal{Exp}(20)
\end{align}\]

<p>It is not rare to mess up with the parametrization,
so we may have confused $\lambda$ with its inverse
(it is more common than what you may imagine).
While the imported libraries and the data are the same,
this time the model reads as follows</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'./data/tweets.csv'</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">pp0</span><span class="p">:</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s">'nu'</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Beta</span><span class="p">(</span><span class="s">'theta'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">NegativeBinomial</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">nu</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="p">)</span>
</code></pre></div></div>

<p>Let us now sample the prior predictive</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pp0</span><span class="p">:</span>
    <span class="n">prior_pred_pp0</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_prior_predictive</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span>
<span class="n">prior_pred_pp0</span><span class="p">.</span><span class="n">prior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/predictive/prior_predictive.webp" alt="The histogram of the prior predictive distribution" /></p>

<p>We can see that the value $y=0$ has a probability
greater than the $90\%.$
Let us now compute this probability. This can be done by simply counting
the fraction of sampled points equal to 0, and this can be done as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">prior_pred_pp0</span><span class="p">.</span><span class="n">prior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<div class="code">
xarray.DataArray
'y'
<br />
    array(0.97648148)

<br />
<br />
<ul>
    <li> Coordinates: (0)</li>
    <li> Indexes: (0) </li>
    <li> Attributes: (0) </li>
</ul>
</div>

<p>It doesn’t really make much sense to start
from a model which predicts that the $98\%$
of our tweets have zero interaction.</p>

<p>At this point, a wise Bayesian would go back and
check again the model. Let us see what happens
to the unwise Bayesian who fits the model
despite the unreasonable conclusion which
follows from the prior.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pp0</span><span class="p">:</span>
    <span class="n">trace_pp0</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_pp0</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/predictive/trace-wrong.webp" alt="The trace plot of the unwise Bayesian" /></p>

<p>With the old model, the value of $\nu$
was peaked at $\nu = 2\,,$
while this time we have a peak at around $0.8\,.$
This means that our inference is strongly
biased by our prior.
In fact, our posterior predictive
is much worse that the one in the old post.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pp0</span><span class="p">:</span>
    <span class="n">pp</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace_pp0</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">pp</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/predictive/posterior_predictive.webp" alt="The posterior predictive plot" /></p>

<p>While our old model gave us,
on average, the correct probability for the tweet
with the lowest interaction number,
this time we overestimate the number
of tweets with few interactions.</p>

<p>Also in this case, the wise Bayesian would
stop and go back to the model construction.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We discussed how to implement some prior predictive
and posterior predictive check,
together with the risks that comes by
not doing them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">pytensor</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Wed Nov 20 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.7
<br />
IPython version      : 8.24.0
<br />

<br />
xarray  : 2024.9.0
<br />
pytensor: 2.25.5
<br />
numpyro : 0.15.0
<br />
jax     : 0.4.28
<br />
jaxlib  : 0.4.28
<br />

<br />
pymc      : 5.17.0
<br />
numpy     : 1.26.4
<br />
matplotlib: 3.9.2
<br />
arviz     : 0.20.0
<br />
pandas    : 2.2.3
<br />

<br />
Watermark: 2.4.3
<br />
</div>

  </div><a class="u-url" href="/statistics/predictive_checks" hidden></a>

  <br>
  <div id='autograph'>
          Stippe Sep 25, 2024

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>
                  Opinions are mine, mistakes too, and if you find any feel free to report it via mail or via <del>Twitter</del> <a href="https://bsky.app/profile/stippe87.bsky.social">Bluesky</a>
                  <br>
                  Most of the material in the statistics section is an adaptation to Python of some pre-existing model.
                  <br>
                  I have tried to provide the necessary credits, but if you think that a relevant contribution is missing, please let me know.
                  <br>
                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

