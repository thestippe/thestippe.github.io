<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Re-parametrizing your model | Data Perspectives</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Re-parametrizing your model" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Building equivalent models with less numerical issues" />
<meta property="og:description" content="Building equivalent models with less numerical issues" />
<link rel="canonical" href="http://localhost:4000/statistics/reparametrization" />
<meta property="og:url" content="http://localhost:4000/statistics/reparametrization" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-02-11T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Re-parametrizing your model" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2024-02-11T00:00:00+00:00","datePublished":"2024-02-11T00:00:00+00:00","description":"Building equivalent models with less numerical issues","headline":"Re-parametrizing your model","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/reparametrization"},"url":"http://localhost:4000/statistics/reparametrization"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;"><ul hidden='hidden' id="postList"><li>
                        Application of the Lotka-Volterra model;/statistics/lotka_volterra;1
                </li><li>
                        Differential equations;/statistics/ode;2
                </li><li>
                        MRP;/statistics/mrp;3
                </li><li>
                        Dirichlet Process Mixture Models;/statistics/dp;4
                </li><li>
                        Bayesian Additive Regression Trees;/statistics/bart;5
                </li><li>
                        Splines;/statistics/spline;6
                </li><li>
                        Gaussian processes regression;/statistics/gp_example;7
                </li><li>
                        Gaussian processes;/statistics/gp;8
                </li><li>
                        Nonparametric models;/statistics/nonparametric_intro;9
                </li><li>
                        Synthetic control;/statistics/synthetic_control;10
                </li><li>
                        Regression discontinuity design;/statistics/rdd;11
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;12
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;13
                </li><li>
                        Randomized controlled trials;/statistics/randomized;14
                </li><li>
                        Causal inference;/statistics/causal_intro;15
                </li><li>
                        Experiment analysis with many blocking variables;/statistics/experiment_design_cont;16
                </li><li>
                        Experiment analysis;/statistics/experiment_design;17
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;18
                </li><li>
                        Application of survival analysis with discrete times;/statistics/survival_example_2;19
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;20
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;21
                </li><li>
                        Random models and mixed models;/statistics/random_models;22
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;23
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;24
                </li><li>
                        Poisson regression;/statistics/poisson_regression;25
                </li><li>
                        Logistic regression;/statistics/logistic_regression;26
                </li><li>
                        Robust linear regression;/statistics/robust_regression;27
                </li><li>
                        Multi-linear regression;/statistics/multivariate_regression;28
                </li><li>
                        Linear regression with binary input;/statistics/regression_binary_input;29
                </li><li>
                        Introduction to the linear regression;/statistics/regression;30
                </li><li>
                        Model comparison, cont.;/statistics/model_averaging_cont;31
                </li><li>
                        Model comparison;/statistics/model_averaging;32
                </li><li>
                        Re-parametrizing your model;/statistics/reparametrization;33
                </li><li>
                        Predictive checks;/statistics/predictive_checks;34
                </li><li>
                        Trace inspection;/statistics/trace_inspection;35
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;36
                </li><li>
                        Mixture models;/statistics/mixture;37
                </li><li>
                        Multidimensional distributions;/statistics/categories;38
                </li><li>
                        The Gaussian model;/statistics/reals;39
                </li><li>
                        The Negative Binomial model;/statistics/negbin;40
                </li><li>
                        The Poisson model;/statistics/poisson;41
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;42
                </li><li>
                        Section introduction;/statistics/simple_models_intro;43
                </li><li>
                        Some notation about probability;/statistics/probability_reminder;44
                </li><li>
                        How does MCMC works;/statistics/mcmc_intro;45
                </li><li>
                        Introduction to Bayesian inference;/statistics/bayes_intro;46
                </li><li>
                        An overview to statistics;/statistics/preface;47
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;48
                </li><li>
                        Design tricks;/dataviz/design-introduction;49
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;50
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;51
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;52
                </li><li>
                        Visual queries;/dataviz/visual-queries;53
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;54
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;55
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;56
                </li><li>
                        Perception;/dataviz/perception;57
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;58
                </li><li>
                        Marks and channels;/dataviz/marks-channels;59
                </li><li>
                        Data abstraction;/dataviz/data-types;60
                </li><li>
                        Data visualization;/dataviz/dataviz;61
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/predictive_checks" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/model_averaging" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">Re-parametrizing your model</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-02-11T00:00:00+00:00" itemprop="datePublished">
        Feb 11, 2024
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  6&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Model re-parametrization is a part of the Bayesian workflow that will likely face any advanced
user. On the other hand, if you are facing Bayesian inference for the first time, you might
safely skip this (rather technical) post, which is about advanced concepts
in MCMC.</p>

<h2 id="when-you-will-encounter-this-problem">When you will encounter this problem</h2>

<p>The NUTS sampler is an amazing tool, but it is of course not perfect,
and there are circumstances when even this tool has some issue.
This is especially true in high dimensional, multiscale and highly correlated
problems, where moving into the high density region of the posterior
probability requires moving in a non-trivial space.
A typical, well known class of models where this is likely to happen is
the family of <a href="/statistics/hierarchical_models">multilevel (or hierarchical)</a> models,
where even for a moderately high number of variables the sample
space might become troublesome.
Here we will re-phrase into the PyMC language <a href="https://mc-stan.org/users/documentation/case-studies/pool-binary-trials.html">this post
</a>.
which discusses the same issue when dealing with Stan.</p>

<h2 id="fitting-the-efron-morris-dataset">Fitting the Efron-Morris dataset</h2>

<p>Here we will analyze the well known “batting average” Efron-Morris
dataset, which can be found <a href="https://raw.githubusercontent.com/pymc-devs/pymc4/master/notebooks/data/efron-morris-75-data.tsv">here</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://raw.githubusercontent.com/pymc-devs/pymc4/master/notebooks/data/efron-morris-75-data.tsv'</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<p>In order to fit this dataset we will use a hierarchical
model for the log-odds, similar to the one discussed <a href="statistics/hierarchical_models">here</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">centered_logit_model</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'mu'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">log_sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s">'log_sigma'</span><span class="p">,</span> <span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">))</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">invlogit</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Binomial</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'Hits'</span><span class="p">],</span> <span class="n">n</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'At-Bats'</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>

<span class="k">with</span> <span class="n">centered_logit_model</span><span class="p">:</span>
    <span class="n">idata_centered</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

</code></pre></div></div>

<p>By running this code I got 517 divergences, and these terrible traces</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_centered</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/docs/assets/images/statistics/reparametrization/trace_centered.webp" alt="
The trace plot of the centered parametrization" /></p>

<p>As discussed in <a href="https://arxiv.org/pdf/1312.0906">this paper</a>,
this is a common issue in hierarchical models.
We can however circumvent this issue by observing that,
if</p>

\[\alpha_i \sim \mathcal{N}(\mu, \sigma)\]

<p>then we can rewrite the above as</p>

\[\alpha_i = \mu + \sigma \phi_i\]

<p>where</p>

\[\phi_i \sim \mathcal{N}(0, 1)\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">noncentered_logit_model</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'mu'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">log_sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s">'log_sigma'</span><span class="p">,</span> <span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">))</span>
    <span class="n">alpha_std</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'alpha_std'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="n">mu</span><span class="o">+</span><span class="n">sigma</span><span class="o">*</span><span class="n">alpha_std</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">invlogit</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Binomial</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'Hits'</span><span class="p">],</span> <span class="n">n</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'At-Bats'</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>

<span class="k">with</span> <span class="n">noncentered_logit_model</span><span class="p">:</span>
    <span class="n">idata_noncentered</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_noncentered</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/reparametrization/trace_noncentered.webp" alt="
The trace plot of the non-centered parametrization" /></p>

<p>This is by far way better than the centered parametrization, and it worked
so well because now our variables are well separated.
Thanks to the re-parametrization, the sampling space
is isotropic within good approximation, and it is therefore easier
for the NUTS sampler to explore it.
We can also take a look at the different landscapes in the $\mu-\sigma$
plane</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_pair</span><span class="p">(</span><span class="n">idata_centered</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'mu'</span><span class="p">,</span> <span class="s">'log_sigma'</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/reparametrization/kde_centered.webp" alt="
The kde plot of the centered parametrization" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_pair</span><span class="p">(</span><span class="n">idata_noncentered</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'mu'</span><span class="p">,</span> <span class="s">'log_sigma'</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/reparametrization/kde_noncentered.webp" alt="
The kde plot of the non-centered parametrization" /></p>

<p>As we can see, the centered parametrization had problems
in exploring the region with a lower probability density,
while the non-centered one also explored this region.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We discussed how model re-parametrization greatly improved the MCMC
sampling procedure, by allowing you to sample clean traces even
for highly correlated models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">pytensor</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Mon Jul 08 2024
<br />
<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />
<br />
xarray  : 2024.5.0
<br />
pytensor: 2.20.0
<br />
numpyro : 0.15.0
<br />
jax     : 0.4.28
<br />
jaxlib  : 0.4.28
<br />
<br />
pandas    : 2.2.2
<br />
seaborn   : 0.13.2
<br />
numpy     : 1.26.4
<br />
matplotlib: 3.9.0
<br />
arviz     : 0.18.0
<br />
pymc      : 5.15.0
<br />
<br />
Watermark: 2.4.3
<br />
</div>

  </div><a class="u-url" href="/statistics/reparametrization" hidden></a>

  <div>
          
          
  </div>

  <br>
  <div id='autograph'>
          Stippe Feb 11, 2024

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>
                  Opinions are mine, mistakes too, and if you find any feel free to report it via mail or via Twitter.
                  <br>
                  Most of the material in the statistics section is an adaptation to Python of some pre-existing model.
                  <br>
                  I have tried to provide the necessary credits, but if you think that a relevant contribution is missing, please let me know.
                  <br>
                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

