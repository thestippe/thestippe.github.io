<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Introduction to decision theory | Data Perspectives</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Introduction to decision theory" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Making choices under uncertainty" />
<meta property="og:description" content="Making choices under uncertainty" />
<link rel="canonical" href="http://localhost:4000/statistics/decision_theory" />
<meta property="og:url" content="http://localhost:4000/statistics/decision_theory" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-01-10T00:00:00+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Introduction to decision theory" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2024-01-10T00:00:00+01:00","datePublished":"2024-01-10T00:00:00+01:00","description":"Making choices under uncertainty","headline":"Introduction to decision theory","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/decision_theory"},"url":"http://localhost:4000/statistics/decision_theory"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;"><ul hidden='hidden' id="postList"><li>
                        The autoregressive model;/statistics/autoregressive;1
                </li><li>
                        Introduction to time series modelling;/statistics/time_series;2
                </li><li>
                        Synthetic control;/statistics/synthetic_control;3
                </li><li>
                        Regression discontinuity ;/statistics/discontinuity_regression;4
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;5
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;6
                </li><li>
                        Randomized controlled trials;/statistics/randomized;7
                </li><li>
                        Causal inference;/statistics/causal_intro;8
                </li><li>
                        Random models and mixed models;/statistics/random_models;9
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;10
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;11
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;12
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;13
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;14
                </li><li>
                        Poisson regression;/statistics/poisson_regression;15
                </li><li>
                        Logistic regression;/statistics/logistic_regression;16
                </li><li>
                        Robust linear regression;/statistics/robust_regression;17
                </li><li>
                        Introduction to the linear regression;/statistics/regression;18
                </li><li>
                        Model comparison;/statistics/model_averaging;19
                </li><li>
                        Predictive checks;/statistics/predictive_checks;20
                </li><li>
                        Trace inspection;/statistics/trace_inspection;21
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;22
                </li><li>
                        Mixture models;/statistics/mixture;23
                </li><li>
                        Multidimensional distributions;/statistics/categories;24
                </li><li>
                        Exponential model, gaussian model and their evolutions;/statistics/reals;25
                </li><li>
                        The Negative Binomial model;/statistics/negbin;26
                </li><li>
                        The Poisson model;/statistics/poisson;27
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;28
                </li><li>
                        Introduction to Bayesian statistics;/statistics/bayesian_intro;29
                </li><li>
                        The central limit theorem;/statistics/central_limit;30
                </li><li>
                        Introduction to decision theory;/statistics/decision_theory;31
                </li><li>
                        Common continuous probabilities;/statistics/common_continuous_probabilities;32
                </li><li>
                        Common discrete probabilities;/statistics/common_discrete_probabilities;33
                </li><li>
                        Interpretations of probability;/statistics/probability_interpretations;34
                </li><li>
                        Kolmogorov axioms;/statistics/probability_axioms;35
                </li><li>
                        What is statistics;/statistics/statistics_intro;36
                </li><li>
                        Design tricks;/dataviz/design-introduction;37
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;38
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;39
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;40
                </li><li>
                        Visual queries;/dataviz/visual-queries;41
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;42
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;43
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;44
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;45
                </li><li>
                        Perception;/dataviz/perception;46
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;47
                </li><li>
                        Marks and channels;/dataviz/marks-channels;48
                </li><li>
                        Data abstraction;/dataviz/data-types;49
                </li><li>
                        Data visualization;/dataviz/dataviz;50
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/common_continuous_probabilities" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/central_limit" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">Introduction to decision theory</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-01-10T00:00:00+01:00" itemprop="datePublished">
        Jan 10, 2024
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  4&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In a previous post we said that, given a set of observations $X_1,\dots,X_n\,,$
and assuming that the observations have been generated by a distribution
belonging to a family of distributions
\(\mathcal{P} = \left\{P_\theta : \theta \in \Theta\right\}\,,\)
we would like to use our dataset to restrict the possible values of $\theta$
or, more generally, of some function of $\theta$ $g(\theta)\,.$</p>

<p>Notice that this is not always possible, as it may happen that, for
$\theta_1 \neq \theta_2\,,$ we have $P_{\theta_1} = P_{\theta_2}\,.$
In this case the family is said to be <strong>unidentifiable</strong>.
If a family is not unidentifiable we say it is <strong>identifiable</strong>.</p>

<h2 id="statistics-estimators-and-estimations">Statistics, estimators and estimations</h2>

<p>The first assumption that we will make is that our set of observations
is made up by $n$ independent identically distributed random variables.
In this case we say that our observation are a <strong>random sample</strong>
of a random variable $X\,.$</p>

<p>We define a <strong>statistic</strong> any real function of the sample \(T = T(X_1,\dots,X_n)\,.\)
If \(x_1,\dots,x_n\) are a realization of our random variables,
we define \(T(x_1,\dots,x_n)\) a <strong>realization of T</strong>.
In other words, a realization of a statistic is the value taken by the statistic
for a particular observed set of data.</p>

<p>We want to use our data to find a value of
our <strong>estimand</strong> \(g(\theta)\,,\)
so we want to use a statistics (a function of the sample)
and in this case $T$ is said to be an <strong>estimator</strong>  for $g(\theta)\,.$
The realized value of our estimator $T(x_1,\dots,x_n)$
is said to be an <strong>estimate</strong> of $g(\theta)\,.$</p>

<h2 id="decision-theory">Decision theory</h2>

<p>A quite general approach to solve the above problem
is given by the <strong>statistical decision theory</strong>,
which is the branch of statistics which
analyzes how to make optimal choices under
uncertainty.</p>

<p>What one does is to define a <strong>risk function</strong></p>

\[R(g(\theta), T(X))=\mathbb{E}_\theta[L(g(\theta), T(X))]\]

<p>where the risk function is the expected value,
with respect to $P_\theta\,,$
of some <strong>loss function</strong> $L\,.$</p>

<p>Depending on the problem, our loss function may
have different shapes.</p>

<p>We may look for a $T(X)$ that is as close as possible
to $g(\theta)\,,$
and in this case a reasonable choice for $L(x, y)$
would be any increasing function
of $\left|x-y\right|\,.$
Common choices are $\left|x-y\right|\,,$
which corresponds to the Mean Absolute Error (MAE),
or $(x-y)^2\,,$
which corresponds to the Mean Square Error (MSE).
In this case our aim is to determine
a <strong>point estimate</strong> for $g(\theta)\,.$</p>

<p>Let us consider, as an example, the case where
\(P_\theta\)
is a series of $n$ fixed Bernoulli trials,
and we want to find an estimate for $\theta$
choosing $(x-y)^2$ as our loss function.
Maybe we could prefer to overestimate $\theta$
rather than underestimate it,
so</p>

\[L(x, y) =
\begin{cases}
(x-y) &amp; x&gt;y \\
2(y-x) &amp; y&lt;x\\
\end{cases}\]

<p>Another possibility is that we may want to determine
whether $g(\theta)$ belongs to a particular
region $\Lambda(X)$ or not, in this
case a candidate for the loss function would be</p>

\[L(g(\theta), T(x)) = a_0 I(g(\theta) \in \Lambda(X))
+ a_1 (1-I(g(\theta) \in \Lambda(X))\]

<p>where $I$ is the indicator function</p>

\[I(x) =
\begin{cases}
&amp; 1\,  if\,  x=T\\
&amp; 0\,  if\,  x=F\\
\end{cases}\]

<p>In this case we are facing a <strong>hypothesis testing</strong>
problem.
As an example, we may want to determine
if a certain hypothesis is true,
so we may assign a positive loss
to the regions where our conclusions are
wrong (the hypothesis is true and we conclude
that it is false or vice versa).
We may even want to setup our problem in such
a way that we assign different loss
to the type of misclassification, so $\Lambda(X)$
should be divided into two subsets $\Lambda_1(X)$
and $\Lambda_2(X)\,,$
and the loss function could be different 
depending on whether $g(\theta)$
belongs to one or the other subspace.</p>

<p>From the above setup it should appear quite clear
that we constructed a subset of
\(g(\Theta)\) and that we want to assess whether
it is reasonable to conclude if
\(g(\theta)\) belongs to it.
In this case the subset is said to be a
<strong>confidence interval</strong> for our estimand.</p>

<p>To clarify the testing problem,
assume that you have a Gaussian random sample $X$
with known variance $\sigma\,,$
and you want to verify if it is reasonable to
assume that it has been generated by
a distribution with \(\left|\mu\right|&lt; c\,.\)</p>

<h2 id="frequentist-vs-bayesian-framework">Frequentist vs Bayesian framework</h2>

<p>Once we defined a risk function,
we should clarify how we want to optimize
our risk function,
as it is both a function of $\theta$
and of $T(X)\,,$ and they are both unknown.</p>

<p>The frequentist approach is to look
for a $T$ that minimizes $\max_\theta R(g(\theta), T(X))\,,$ and this leads to the <strong>minimax problem</strong>.</p>

<p>On the other hand, in the Bayesian approach,
$\theta$ is not a number but a random variable
with probability $p(\theta )\,,$
so one can minimize the expected loss</p>

\[\int d\theta p(\theta ) R(g(\theta), T(X))\]

<h2 id="conclusions">Conclusions</h2>

<p>We formulated the general inferential
problem in terms of a loss function,
and we specified how a solution should
look like both in the Bayesian and in the frequentist
perspective.</p>

<p>In the next posts we will analyze different
kinds of problems by starting from
the frequentist point of view.</p>

<!--
ADD Central Limit Theorem 
-->

  </div><a class="u-url" href="/statistics/decision_theory" hidden></a>

  <div>
          
          
  </div>

  <br>
  <div id='autograph'>
          Stippe Jan 10, 2024

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>

                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

