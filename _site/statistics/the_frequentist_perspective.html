<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>A reminder on frequentist statistics | Data Perspectives</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="A reminder on frequentist statistics" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="What the classical paradigm tells us" />
<meta property="og:description" content="What the classical paradigm tells us" />
<link rel="canonical" href="http://localhost:4000/statistics/the_frequentist_perspective" />
<meta property="og:url" content="http://localhost:4000/statistics/the_frequentist_perspective" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-01-04T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="A reminder on frequentist statistics" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2024-01-04T00:00:00+00:00","datePublished":"2024-01-04T00:00:00+00:00","description":"What the classical paradigm tells us","headline":"A reminder on frequentist statistics","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/the_frequentist_perspective"},"url":"http://localhost:4000/statistics/the_frequentist_perspective"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;"><ul hidden='hidden' id="postList"><li>
                        Philosophy of science;/statistics/on_philosophy_of_science;1
                </li><li>
                        Introduction to this section;/statistics/other_intro;2
                </li><li>
                        Splines regression;/statistics/splines;3
                </li><li>
                        Introduction to non-parametric models;/statistics/nonparametric;4
                </li><li>
                        Introduction to Gaussian processes;/statistics/gaussian_processes;5
                </li><li>
                        The autoregressive model;/statistics/autoregressive;6
                </li><li>
                        Introduction to time series modelling;/statistics/time_series;7
                </li><li>
                        Synthetic control;/statistics/synthetic_control;8
                </li><li>
                        Regression discontinuity ;/statistics/discontinuity_regression;9
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;10
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;11
                </li><li>
                        Randomized controlled trials;/statistics/randomized;12
                </li><li>
                        Causal inference;/statistics/causal_intro;13
                </li><li>
                        Experiment analysis;/statistics/experiment_design;14
                </li><li>
                        Random models and mixed models;/statistics/random_models;15
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;16
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;17
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;18
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;19
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;20
                </li><li>
                        Poisson regression;/statistics/poisson_regression;21
                </li><li>
                        Logistic regression;/statistics/logistic_regression;22
                </li><li>
                        Robust linear regression;/statistics/robust_regression;23
                </li><li>
                        Linear regression with binary input;/statistics/regression_binary_input;24
                </li><li>
                        Introduction to the linear regression;/statistics/regression;25
                </li><li>
                        Model comparison;/statistics/model_averaging;26
                </li><li>
                        Reparametrizing your model;/statistics/reparametrization;27
                </li><li>
                        Predictive checks;/statistics/predictive_checks;28
                </li><li>
                        Trace inspection;/statistics/trace_inspection;29
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;30
                </li><li>
                        Mixture models;/statistics/mixture;31
                </li><li>
                        Multidimensional distributions;/statistics/categories;32
                </li><li>
                        The Gaussian model;/statistics/reals;33
                </li><li>
                        The Negative Binomial model;/statistics/negbin;34
                </li><li>
                        The Poisson model;/statistics/poisson;35
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;36
                </li><li>
                        How does MCMC works;/statistics/mcmc_intro;37
                </li><li>
                        Introduction to Bayesian inference;/statistics/bayes_intro;38
                </li><li>
                        A reminder on frequentist statistics;/statistics/the_frequentist_perspective;39
                </li><li>
                        A gentle reminder on probability;/statistics/probabiity;40
                </li><li>
                        An overview to statistics;/statistics/preface;41
                </li><li>
                        Design tricks;/dataviz/design-introduction;42
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;43
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;44
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;45
                </li><li>
                        Visual queries;/dataviz/visual-queries;46
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;47
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;48
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;49
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;50
                </li><li>
                        Perception;/dataviz/perception;51
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;52
                </li><li>
                        Marks and channels;/dataviz/marks-channels;53
                </li><li>
                        Data abstraction;/dataviz/data-types;54
                </li><li>
                        Data visualization;/dataviz/dataviz;55
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/probabiity" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/bayes_intro" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">A reminder on frequentist statistics</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-01-04T00:00:00+00:00" itemprop="datePublished">
        Jan 4, 2024
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  5&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Before moving to Bayesian inference, let us briefly recall some basic concept of frequentist statistics.
Let us assume that we are running an experiment where the outcome $y$ is normally distributed
with mean $\mu=2$ and $\sigma=1\,.$ Let us also assume that the experimenter doesn’t know
nether $\mu$ nor $\sigma\,,$ and he is interested in $\mu\,,$ so he runs an experiment where
he measures $y$ 40 times.</p>

<p>Let us simulate this with python</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">543</span><span class="p">)</span>  <span class="c1"># for reproducibility
</span>
<span class="n">mu_true</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">sigma_true</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">40</span>

<span class="n">y_obs</span> <span class="o">=</span> <span class="n">rng</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu_true</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">sigma_true</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_obs</span><span class="p">)</span>
</code></pre></div></div>

<p>He can easily compute a point estimate<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> for both $\mu$ and $\sigma\,,$
and he gets</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mu_est</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)</span>
<span class="n">sigma_est</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mu_est</span>
</code></pre></div></div>

<div class="code">
1.9161258515048432
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sigma_est</span>
</code></pre></div></div>

<div class="code">
0.8076823501920702
</div>

<p>Those are only point estimate, but they don’t tell us anything about how far we are from the true values.
Since he is interested in $\mu\,,$ he computes a Confidence Interval for it, and he does so by using
the Central Limit theorem, which states that, in the long run, the observed sample mean $\bar{Y}_n$ obeys</p>

\[\sqrt{n}(\bar{Y}_n - \mu) \sim \mathcal{N}(0, \sigma^2)\]

<p>where $\mu$ and $\sigma$ are the true mean and standard deviation respectively.
Of course, he doesn’t know nether $\mu$ nor $\sigma\,,$ but he can use his point estimates for them.
He then uses these values to estimate the $95%$ two tail CI as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ci</span> <span class="o">=</span> <span class="p">[</span><span class="n">mu_est</span> <span class="o">+</span> <span class="n">norm</span><span class="p">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.025</span><span class="p">)</span><span class="o">*</span><span class="n">sigma_est</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)),</span>
      <span class="n">mu_est</span> <span class="o">+</span> <span class="n">norm</span><span class="p">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">)</span><span class="o">*</span><span class="n">sigma_est</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_obs</span><span class="p">))]</span>

<span class="n">ci</span>
</code></pre></div></div>
<div class="code">
[1.665827097340284, 2.1664246056694023]
</div>

<p>The main issue with CI is that it is easily misinterpreted as the probability for the parameter
$\mu$ to fall within the observed CI.
However, $\mu$ is not a random variable, but it is a number.
We therefore have either probability 1 or 0 that the true value of $\mu$ will fall within the observed CI
if $\mu$ is inside the CI or not respectively.</p>

<p>We have that, if we repeat the experiment, we have 0.95 probability that the new observed CI
will include $\mu\,.$</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">n_exp</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_exp</span><span class="p">):</span>
    <span class="n">y_obs_new</span> <span class="o">=</span> <span class="n">rng</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mu_true</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">sigma_true</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_obs</span><span class="p">)</span>
    <span class="n">mu_est_new</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_obs_new</span><span class="p">)</span>
    <span class="n">sigma_est_new</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">y_obs_new</span><span class="p">)</span>
    <span class="n">ci_new</span> <span class="o">=</span> <span class="p">[</span><span class="n">mu_est_new</span> <span class="o">+</span> <span class="n">norm</span><span class="p">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.025</span><span class="p">)</span><span class="o">*</span><span class="n">sigma_est_new</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)),</span>
              <span class="n">mu_est_new</span> <span class="o">+</span> <span class="n">norm</span><span class="p">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">)</span><span class="o">*</span><span class="n">sigma_est_new</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_obs</span><span class="p">))]</span>
    <span class="k">if</span> <span class="n">mu_true</span> <span class="o">&lt;</span> <span class="n">ci_new</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="n">mu_true</span><span class="o">&gt;</span> <span class="n">ci_new</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">k</span><span class="o">/</span><span class="n">n_exp</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="n">ci_new</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="n">ci_new</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">k</span><span class="o">/</span><span class="n">n_exp</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="n">ci_new</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="n">ci_new</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">mu_true</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'steelblue'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'steelblue'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s">"We have p=</span><span class="si">{</span><span class="n">n</span><span class="o">/</span><span class="n">n_exp</span><span class="si">}</span><span class="s"> that the </span><span class="si">{</span><span class="mi">95</span><span class="si">}</span><span class="s">% CI includes the true mean"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="n">n_exp</span><span class="p">])</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/frequentist/ci.webp" alt="" /></p>

<p>We are therefore not providing an uncertainty for our parameter $\mu\,,$
but we are rather doing so for our confidence interval itself.
This is quite reasonable, since in the “classical” paradigm the parameters are fixed,
and we have no way to associate a probability to them.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We have seen how to estimate parameters in statistics, together with some conceptual
difficulty of their interpretation.
Starting from the next post we will enter into the core of this section, namely Bayesian statistics.</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>We recall that estimating is the procedure of associating a value (the estimate) to a parameter (the estimand), and this is done by means of a statistic (any function of the sample). <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div><a class="u-url" href="/statistics/the_frequentist_perspective" hidden></a>

  <div>
          
          
  </div>

  <br>
  <div id='autograph'>
          Stippe Jan 4, 2024

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>

                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

