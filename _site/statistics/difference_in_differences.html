<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Difference in difference | Data Perspectives</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Difference in difference" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Causal inference from 1850" />
<meta property="og:description" content="Causal inference from 1850" />
<link rel="canonical" href="http://localhost:4000/statistics/difference_in_differences" />
<meta property="og:url" content="http://localhost:4000/statistics/difference_in_differences" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-06-30T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Difference in difference" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2024-06-30T00:00:00+00:00","datePublished":"2024-06-30T00:00:00+00:00","description":"Causal inference from 1850","headline":"Difference in difference","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/difference_in_differences"},"url":"http://localhost:4000/statistics/difference_in_differences"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;"><ul hidden='hidden' id="postList"><li>
                        Application of the Lotka-Volterra model;/statistics/lotka_volterra;1
                </li><li>
                        Differential equations;/statistics/ode;2
                </li><li>
                        MRP;/statistics/mrp;3
                </li><li>
                        Dirichlet Process Mixture Models;/statistics/dp;4
                </li><li>
                        Bayesian Additive Regression Trees;/statistics/bart;5
                </li><li>
                        Splines;/statistics/spline;6
                </li><li>
                        Gaussian processes regression;/statistics/gp_example;7
                </li><li>
                        Gaussian processes;/statistics/gp;8
                </li><li>
                        Nonparametric models;/statistics/nonparametric_intro;9
                </li><li>
                        Synthetic control;/statistics/synthetic_control;10
                </li><li>
                        Regression discontinuity design;/statistics/rdd;11
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;12
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;13
                </li><li>
                        Randomized controlled trials;/statistics/randomized;14
                </li><li>
                        Causal inference;/statistics/causal_intro;15
                </li><li>
                        Experiment analysis with many blocking variables;/statistics/experiment_design_cont;16
                </li><li>
                        Experiment analysis;/statistics/experiment_design;17
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;18
                </li><li>
                        Application of survival analysis with discrete times;/statistics/survival_example_2;19
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;20
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;21
                </li><li>
                        Random models and mixed models;/statistics/random_models;22
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;23
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;24
                </li><li>
                        Poisson regression;/statistics/poisson_regression;25
                </li><li>
                        Logistic regression;/statistics/logistic_regression;26
                </li><li>
                        Robust linear regression;/statistics/robust_regression;27
                </li><li>
                        Multi-linear regression;/statistics/multivariate_regression;28
                </li><li>
                        Linear regression with binary input;/statistics/regression_binary_input;29
                </li><li>
                        Introduction to the linear regression;/statistics/regression;30
                </li><li>
                        Model comparison, cont.;/statistics/model_averaging_cont;31
                </li><li>
                        Model comparison;/statistics/model_averaging;32
                </li><li>
                        Reparametrizing your model;/statistics/reparametrization;33
                </li><li>
                        Predictive checks;/statistics/predictive_checks;34
                </li><li>
                        Trace inspection;/statistics/trace_inspection;35
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;36
                </li><li>
                        Mixture models;/statistics/mixture;37
                </li><li>
                        Multidimensional distributions;/statistics/categories;38
                </li><li>
                        The Gaussian model;/statistics/reals;39
                </li><li>
                        The Negative Binomial model;/statistics/negbin;40
                </li><li>
                        The Poisson model;/statistics/poisson;41
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;42
                </li><li>
                        Section introduction;/statistics/simple_models_intro;43
                </li><li>
                        Some notation about probability;/statistics/probability_reminder;44
                </li><li>
                        How does MCMC works;/statistics/mcmc_intro;45
                </li><li>
                        Introduction to Bayesian inference;/statistics/bayes_intro;46
                </li><li>
                        An overview to statistics;/statistics/preface;47
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;48
                </li><li>
                        Design tricks;/dataviz/design-introduction;49
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;50
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;51
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;52
                </li><li>
                        Visual queries;/dataviz/visual-queries;53
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;54
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;55
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;56
                </li><li>
                        Perception;/dataviz/perception;57
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;58
                </li><li>
                        Marks and channels;/dataviz/marks-channels;59
                </li><li>
                        Data abstraction;/dataviz/data-types;60
                </li><li>
                        Data visualization;/dataviz/dataviz;61
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/instrumental_variable" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/rdd" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">Difference in difference</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-06-30T00:00:00+00:00" itemprop="datePublished">
        Jun 30, 2024
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  8&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Difference in differences is a very old technique,
and one of the first applications of
this method was done by John Snow, who’s also
popular due to the cholera outbreak data visualization.</p>

<p>In his study, he used the <strong>Difference in Difference</strong>
(DiD) method to provide some evidence that,
during the London cholera epidemic of 1866,
the cholera was caused by drinking from a water
pump.
This method has been more recently used <a href="https://davidcard.berkeley.edu/papers/njmin-aer.pdf">by 
Card and Krueger in this work</a>
to analyze the causal relationship between
minimum wage and employment.
In 1992, the New Jersey increased the minimum wage
from 4.25 dollars to 5.00 dollars.
They compared the employment in Pennsylvania
and New Jersey before and after the minimum wage increase
to assess if it caused a decrease in the New Jersey
occupation, as supply and demand theory would predict.</p>

<p>DiD assumes that, before the intervention $I$,
the untreated group and the treated one
both evolve linearly with the time $t$ with the
same slope,
while after the intervention the treated group
changes slope.
Assuming, that the intervention was applied at time
$t=0$</p>

\[\begin{align}
&amp;
Y_{P}^0 = \alpha_{P} 
\\
&amp;
Y_{P}^1 = \alpha_{P} +\beta
\\
&amp;
Y_{NJ}^0 = \alpha_{NJ} 
\\
&amp;
Y_{NJ}^1 = \alpha_{NJ} +\beta + \gamma
\end{align}\]

<p>In the above formulas, the intervention effect
is simply $\gamma\,.$</p>

<h2 id="the-implementation">The implementation</h2>

<p>We downloaded the dataset from <a href="https://www.kaggle.com/code/harrywang/difference-in-differences-in-python/input">this page</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">df_employment</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/employment.csv'</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_employment</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'state'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/difference_in_difference/pairplot.webp" alt="The dataset pairplot" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_before</span> <span class="o">=</span> <span class="n">df_employment</span><span class="p">[[</span><span class="s">'state'</span><span class="p">,</span> <span class="s">'total_emp_feb'</span><span class="p">]]</span>
<span class="n">df_after</span> <span class="o">=</span> <span class="n">df_employment</span><span class="p">[[</span><span class="s">'state'</span><span class="p">,</span> <span class="s">'total_emp_nov'</span><span class="p">]]</span>

<span class="c1"># We will assign t=0 data before treatment and t=1 after the treatment
# Analogously g=0 will be the control group, g=1 will be the test group
</span>
<span class="n">df_before</span><span class="p">[</span><span class="s">'t'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">df_after</span><span class="p">[</span><span class="s">'t'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">df_before</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'total_emp_feb'</span><span class="p">:</span> <span class="s">'Y'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df_after</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'total_emp_nov'</span><span class="p">:</span> <span class="s">'Y'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">df_before</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'state'</span><span class="p">:</span> <span class="s">'g'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df_after</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'state'</span><span class="p">:</span> <span class="s">'g'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">df_reg</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_before</span><span class="p">,</span> <span class="n">df_after</span><span class="p">])</span>

<span class="c1">## Let us build the interaction term
</span>
<span class="n">df_reg</span><span class="p">[</span><span class="s">'gt'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_reg</span><span class="p">[</span><span class="s">'g'</span><span class="p">]</span><span class="o">*</span><span class="n">df_reg</span><span class="p">[</span><span class="s">'t'</span><span class="p">]</span>

<span class="n">df_reg</span> <span class="o">=</span> <span class="n">df_reg</span><span class="p">[[</span><span class="s">'g'</span><span class="p">,</span> <span class="s">'t'</span><span class="p">,</span> <span class="s">'gt'</span><span class="p">,</span> <span class="s">'Y'</span><span class="p">]]</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">did_model</span><span class="p">:</span>
    <span class="n">beta_0</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta_0'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">beta_g</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta_g'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">beta_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta_t'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">beta_gt</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'beta_gt'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s">'nu'</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_g</span><span class="o">*</span><span class="n">df_reg</span><span class="p">[</span><span class="s">'g'</span><span class="p">]</span><span class="o">+</span> <span class="n">beta_t</span><span class="o">*</span><span class="n">df_reg</span><span class="p">[</span><span class="s">'t'</span><span class="p">]</span><span class="o">+</span> <span class="n">beta_gt</span><span class="o">*</span><span class="n">df_reg</span><span class="p">[</span><span class="s">'gt'</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">nu</span><span class="p">,</span>
                  <span class="n">observed</span><span class="o">=</span><span class="n">df_reg</span><span class="p">[</span><span class="s">'Y'</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
    <span class="n">trace_did</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                         <span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_did</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/difference_in_difference/trace.webp" alt="The model trace" /></p>

<p>The trace looks fine, let us now verify the posterior
predictive.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">did_model</span><span class="p">:</span>
    <span class="n">y00</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s">'y00'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">beta_0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">nu</span><span class="p">)</span>
    <span class="n">y10</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s">'y10'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">beta_0</span><span class="o">+</span><span class="n">beta_g</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">nu</span><span class="p">)</span>
    <span class="n">y01</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s">'y01'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">beta_0</span><span class="o">+</span><span class="n">beta_t</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">nu</span><span class="p">)</span>
    <span class="n">y11</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s">'y11'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">beta_0</span><span class="o">+</span><span class="n">beta_g</span><span class="o">+</span><span class="n">beta_t</span><span class="o">+</span><span class="n">beta_gt</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">nu</span><span class="p">)</span>
    
    <span class="n">ppc_check</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span>
        <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'y00'</span><span class="p">,</span><span class="s">'y01'</span><span class="p">,</span><span class="s">'y10'</span><span class="p">,</span><span class="s">'y11'</span><span class="p">],</span> <span class="n">trace</span><span class="o">=</span><span class="n">trace_did</span><span class="p">)</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="n">t</span><span class="p">].</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">80</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
            <span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">az</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">ppc_check</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s">"y</span><span class="si">{</span><span class="n">g</span><span class="si">}{</span><span class="n">t</span><span class="si">}</span><span class="s">"</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="s">'posterior_predictive'</span><span class="p">,</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="n">t</span><span class="p">],</span>
                       <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">)</span>
        <span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">az</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">ppc_check</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s">"y</span><span class="si">{</span><span class="n">g</span><span class="si">}{</span><span class="n">t</span><span class="si">}</span><span class="s">"</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="s">'posterior_predictive'</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="n">t</span><span class="p">])</span>
        <span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">df_reg</span><span class="p">[(</span><span class="n">df_reg</span><span class="p">[</span><span class="s">'g'</span><span class="p">]</span><span class="o">==</span><span class="n">g</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">df_reg</span><span class="p">[</span><span class="s">'t'</span><span class="p">]</span><span class="o">==</span><span class="n">t</span><span class="p">)][</span><span class="s">'Y'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="n">t</span><span class="p">])</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="n">t</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s">"g=</span><span class="si">{</span><span class="n">g</span><span class="si">}</span><span class="s">, t=</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">legend</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">legend</span><span class="p">(</span><span class="n">frameon</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/difference_in_difference/posterior_predictives.webp" alt="The comparison between the predicted
and observed distributions of Y" /></p>

<p>The posterior predictive distributions agree with the observed data. We extracted some random sub-sample to
provide an estimate of the uncertainties.</p>

<p>We can finally verify if there is any effect:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace_did</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'beta_gt'</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/difference_in_difference/effect_estimate.webp" alt="Our estimate for the minimum wage increase effect
" /></p>

<p>As you can see, the effect is compatible with 0, therefore there is no evidence
that by increasing the minimum salary there is an effect on the occupation.</p>

<p>Our model has a small issue: it allows for negative values of the occupation,
which doesn’t make sense. This problem can be easily circumvented by using 
the <a href="https://www.pymc.io/projects/docs/en/v4.4.0/api/distributions/generated/pymc.Truncated.html">truncated PyMC class</a>.</p>

<p>I suggest you to try it and verify yourself if there is any effect.
Remember that in that case $\mu$ is no more the mean for $Y$,
so you can’t use it to estimate the average effect.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We have seen how to implement the DiD method with PyMC, and we used to
re-analyze the Krueger and Card article on the relation between the minimum
salary and the occupation.</p>

<h2 id="suggested-readings">Suggested readings</h2>

<ul>
  <li><cite>Imbens, G. W., Rubin, D. B. (2015). Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. US: Cambridge University Press.<cite></cite></cite></li>
  <li><cite><a href="https://arxiv.org/pdf/2206.15460.pdf">Li, Ding, Mealli (2022). Bayesian Causal Inference: A Critical Review</a></cite></li>
  <li><cite>Ding, P. (2024). A First Course in Causal Inference. CRC Press.</cite></li>
  <li><cite>Angrist, J. D., Pischke, J. (2009). Mostly harmless econometrics : an empiricist’s companion. Princeton University Press.</cite></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Tue Aug 20 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />

<br />
xarray : 2024.5.0
<br />
numpyro: 0.15.0
<br />
jax    : 0.4.28
<br />
jaxlib : 0.4.28
<br />

<br />
numpy     : 1.26.4
<br />
seaborn   : 0.13.2
<br />
matplotlib: 3.9.0
<br />
pandas    : 2.2.2
<br />
pymc      : 5.15.0
<br />
arviz     : 0.18.0
<br />

<br />
Watermark: 2.4.3
<br />

<br />
</div>

  </div><a class="u-url" href="/statistics/difference_in_differences" hidden></a>

  <div>
          
          
  </div>

  <br>
  <div id='autograph'>
          Stippe Jun 30, 2024

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>
                  Opinions are mine, mistakes too, and if you find any feel free to report it via mail or via Twitter.
                  <br>
                  Most of the material in the statistics section is an adaptation to Python of some pre-existing model.
                  <br>
                  I have tried to provide the necessary credits, but if you think that a relevant contribution is missing, please let me know.
                  <br>
                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

