<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Introduction to Extreme Values theory | Data Perspectives</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Introduction to Extreme Values theory" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Describing rare events" />
<meta property="og:description" content="Describing rare events" />
<link rel="canonical" href="http://localhost:4000/statistics/extreme_intro" />
<meta property="og:url" content="http://localhost:4000/statistics/extreme_intro" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-05-19T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Introduction to Extreme Values theory" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2024-05-19T00:00:00+00:00","datePublished":"2024-05-19T00:00:00+00:00","description":"Describing rare events","headline":"Introduction to Extreme Values theory","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/extreme_intro"},"url":"http://localhost:4000/statistics/extreme_intro"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;"><ul hidden='hidden' id="postList"><li>
                        Introduction to this section;/statistics/other_intro;1
                </li><li>
                        Synthetic control;/statistics/synthetic_control;2
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;3
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;4
                </li><li>
                        Randomized controlled trials;/statistics/randomized;5
                </li><li>
                        Causal inference;/statistics/causal_intro;6
                </li><li>
                        Experiment analysis;/statistics/experiment_design;7
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;8
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;9
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;10
                </li><li>
                        Random models and mixed models;/statistics/random_models;11
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;12
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;13
                </li><li>
                        Poisson regression;/statistics/poisson_regression;14
                </li><li>
                        Logistic regression;/statistics/logistic_regression;15
                </li><li>
                        Robust linear regression;/statistics/robust_regression;16
                </li><li>
                        Multi-linear regression;/statistics/multivariate_regression;17
                </li><li>
                        Linear regression with binary input;/statistics/regression_binary_input;18
                </li><li>
                        Introduction to the linear regression;/statistics/regression;19
                </li><li>
                        Model comparison, cont.;/statistics/model_averaging_cont;20
                </li><li>
                        Model comparison;/statistics/model_averaging;21
                </li><li>
                        Reparametrizing your model;/statistics/reparametrization;22
                </li><li>
                        Predictive checks;/statistics/predictive_checks;23
                </li><li>
                        Trace inspection;/statistics/trace_inspection;24
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;25
                </li><li>
                        Mixture models;/statistics/mixture;26
                </li><li>
                        Multidimensional distributions;/statistics/categories;27
                </li><li>
                        The Gaussian model;/statistics/reals;28
                </li><li>
                        The Negative Binomial model;/statistics/negbin;29
                </li><li>
                        The Poisson model;/statistics/poisson;30
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;31
                </li><li>
                        Section introduction;/statistics/simple_models_intro;32
                </li><li>
                        Some notation about probability;/statistics/probability_reminder;33
                </li><li>
                        How does MCMC works;/statistics/mcmc_intro;34
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;35
                </li><li>
                        Introduction to Bayesian inference;/statistics/bayes_intro;36
                </li><li>
                        An overview to statistics;/statistics/preface;37
                </li><li>
                        Design tricks;/dataviz/design-introduction;38
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;39
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;40
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;41
                </li><li>
                        Visual queries;/dataviz/visual-queries;42
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;43
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;44
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;45
                </li><li>
                        Perception;/dataviz/perception;46
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;47
                </li><li>
                        Marks and channels;/dataviz/marks-channels;48
                </li><li>
                        Data abstraction;/dataviz/data-types;49
                </li><li>
                        Data visualization;/dataviz/dataviz;50
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/survival_example" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/experiment_design" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">Introduction to Extreme Values theory</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-05-19T00:00:00+00:00" itemprop="datePublished">
        May 19, 2024
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  10&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In some circumstances you may be not interested in modelling the distribution itself,
 but you may be interested in understanding its asymptotic behavior, and the extreme value theory is the discipline which studies this topic.</p>

<p>The EV theory is appropriate when you want to investigate the distribution
of the minimum or maximum value of some quantity,
as the maximum loss of a financial asset or the yearly maximum
volume of rain in a certain location.</p>

<p>The intuition behind the extreme value theory is that any probability distribution
function is positive and must integrate to one,
it must therefore fall to zero fast enough if $x \rightarrow \infty\,.$
This puts strong constraints to its asymptotic behavior,
and this leads to the <a href="https://en.wikipedia.org/wiki/Fisher%E2%80%93Tippett%E2%80%93Gnedenko_theorem">Fisher-Tippet-Gnedenko theorem</a>.</p>

<p>Formally if we have a continuous positive random variable $X$
with cumulative distribution function $F(x)\,,$
and we observe $X_1,…,X_n$ independent identically distributed
variables distributed according to $X\,,$
if we denote $M_n$ the maximum of $X_1,…,X_n\,,$ then</p>

<p>$P(M_n \leq x) = P(X_1 \leq x) P(X_2 \leq x) … P(X_n \leq x) = (F(x))^n$</p>

<p>However one may not know $F$ a priori, but the FTG theorem states that,
if there exist $a_n, b_n \in \mathbb{R}$ such that</p>

\[P\left( \frac{M_n - a_n}{b_n} \leq x \right) \rightarrow G(x)\]

<p>then \(G(x) \propto \exp{\left(-(1+ \xi x)^{-1/\xi}\right)}\,.\)</p>

<p>Once properly normalized and promoted to a location-scale family one arrives to the Generalized Extreme Value distribution:</p>

\[p(x) = \frac{1}{\sigma} t(x)^{\xi + 1}e^{- t(x)}\]

<p>where</p>

\[t(x) =
\begin{cases}
\left(1+ \xi \left(\frac{x-\mu}{\sigma}\right)\right)^{-1/\xi}\,&amp; if\,&amp;  \xi \neq 0 \\
e^{-\left(x-\mu\right)/\sigma}\,&amp; if\,&amp; \xi = 0\\
\end{cases}\]

<p>Notice that, if $X_1,…, X_n$ are distributed according to $G\,,$ then $\max(X_1,…,X_n)$ is distributed according to $G\,.$
This distribution is known as the <strong>Generalized Extreme Value</strong> (GEV) distribution.</p>

<h2 id="maximum-distribution-of-the-apple-stocks">Maximum distribution of the Apple stocks</h2>

<p>I have been working on financial risk assessment for a while, and
one of the central issues in this field is to determine the
risk due to extremely large fluctuations of the stock market.
EVT can be really helpful in this task, and we will show how in this post.
We will use <a href="https://pypi.org/project/yfinance/">Yahoo Finance</a> to download the values of the Apple stock
in the period from the January 1st 2020 to the December 31st 2023.</p>

<p>The Generalized Extreme Values distribution is not directly available
in PyMC, but can be found in the <a href="https://www.pymc.io/projects/experimental/en/latest/index.html">pymc_experimental</a> package.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">pymc_experimental.distributions</span> <span class="k">as</span> <span class="n">pmx</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">yfinance</span> <span class="k">as</span> <span class="n">yf</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">yf</span><span class="p">.</span><span class="n">download</span><span class="p">(</span><span class="s">'AAPL'</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="s">'2020-01-01'</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s">'2023-12-01'</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s">'Date'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Date'</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s">'LogRet'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Close'</span><span class="p">]).</span><span class="n">diff</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">()</span>
</code></pre></div></div>

<p>First of all, we converted the close values (the value of the stock at the end of
the day) into logarithmic-returns (log-returns for short).
This is a common operation in finance, since for compound interest
assets the total value is</p>

\[\prod_i (1+r_i)\]

<p>If we take the logarithm of the above formula we transform the product into a sum,
and this makes log-returns so useful.</p>

<p>We are interested in finding the distribution of the weekly minima
of the daily close.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">pd</span><span class="p">.</span><span class="n">Grouper</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'Date'</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s">'W'</span><span class="p">)])[</span><span class="s">'LogRet'</span><span class="p">].</span><span class="nb">min</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">dt</span> <span class="o">=</span> <span class="o">-</span><span class="n">data</span><span class="p">[</span><span class="s">'LogRet'</span><span class="p">].</span><span class="n">values</span>
</code></pre></div></div>

<p>Before fitting the model, let us take a look at the behavior of the data</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Date'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s">'LogRet'</span><span class="p">])</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'LogRet'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/docs/assets/images/statistics/extreme_intro/logret.webp" alt="" /></p>

<p>There is some evident time dependence. As an example, we can observe quite
a high volatility during the Covid pandemic and another high volatility
period after the Ukraine invasion.
However, for the moment, we will neglect the time dependence, and assume that
the parameters are stationary.</p>

<p>Since we have quite a large amount of data, we can safely use uninformative priors.
We do expect that both $\mu$ and $\sigma$ are typically much smaller than
one, so we will take a standard deviation of 2 for the first one and
equal to 1 for the latter.</p>

<p>From the <a href="https://en.wikipedia.org/wiki/Generalized_extreme_value_distribution">Wikipedia page</a> we observe that, if 
\(| \xi|&gt;1\,,\) the mean does not exists.
Since it is reasonable to assume that it exists, we expect that $\xi$
will be bounded into the $[-1, 1]$ region, therefore we have the following
model</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_gev</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'mu'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xi</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'xi'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">gev</span> <span class="o">=</span> <span class="n">pmx</span><span class="p">.</span><span class="n">GenExtreme</span><span class="p">(</span><span class="s">'gev'</span><span class="p">,</span><span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">xi</span><span class="o">=</span><span class="n">xi</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">tune</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/extreme_intro/trace.webp" alt="The trace of our model" /></p>

<p>Let us take a look at the joint posterior distribution.</p>

<p><img src="/docs/assets/images/statistics/extreme_intro/kde.webp" alt="The KDE plot of the posterior distribution" /></p>

<p>We can now take a look at the PPC in order to verify if our model
is able to reproduce the data</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model_gev</span><span class="p">:</span>
    <span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">ppc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'kde'</span><span class="p">,</span> <span class="n">num_pp_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/extreme_intro/ppc.webp" alt="The posterior predictive distribution" /></p>

<p>There’s a very good agreement between the observed and the predicted values,
so our estimate should be quite reliable.</p>

<h2 id="the-generalized-pareto-distribution">The Generalized Pareto distribution</h2>

<p>Keeping only the extreme values may be a waste of information. As an example, we only kept the
weekly maxima, so we trowed away four days out of five.
In some situation, instead of analyzing what is the distribution probability for the maxima,
it may be better to analyze what is the probability that your random variable exceeds some threshold.
More precisely, given $u,y&gt;0\,,$ we want to get information on</p>

\[P(X&gt;u+y | X&gt;u) = \frac{P((X&gt;u+y)\cap (X&gt;u))}{P(X&gt;u)} = \frac{P(X&gt;u+y)}{P(X&gt;u)} = \frac{1-F(u+y)}{1-F(u)}\]

<p>It can be proved (see Coles’ textbook for the outline) that, for large enough $u\,,$
the above distribution must have the form</p>

\[p(y | u, \sigma, \xi) = \left(1+\frac{\xi y}{\sigma}\right)^{-1/\xi}\]

<p>The distribution</p>

\[p(y | \mu, \sigma, \xi) = \left(1+\xi \frac{y-\mu}{\sigma}\right)^{-1/\xi}\]

<p>is named the <strong>Generalized Pareto Distribution</strong> (GPD).
For the mathematical details on the above distribution, see the
<a href="https://en.wikipedia.org/wiki/Generalized_Pareto_distribution">corresponding Wikipedia page</a>.</p>

<p>Now it comes one bad news and one good news. The bad one is that in PyMC it is only
implemented the Pareto type I distribution, which is a special case of the GPD.
The good one is that it is really easy to implement custom distributions in PyMC,
and this can be done following <a href="https://www.pymc.io/projects/examples/en/2022.12.0/howto/custom_distribution.html">this very nice tutorial</a>.
You can find my own implementation <a href="https://github.com/thestippe/thestippe.github.io/blob/main/scripts/generalized_pareto.py">on my github repo</a>.</p>

<p>Let us see how to model the tail of the Apple stocks by using it.
A reasonably high enough threshold for the log returns is $0.03\,,$
as this value is high enough to be far from the center and low enough to provide
a discrete amount of data.
We do expect $\sigma \ll 1\,,$ therefore assuming a variance of 1 for it may be enough.
$\xi$ must be lower than 1. If it is 1, then the mean
does not exists, and this doesn’t make much sense. 
If $\xi$ is negative, then the support of the GDP has an upper bound,
and it doesn’t make much sense too, so we can assume it is non-negative.
We can therefore take a half normal distribution for it, with variance 10.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">generalized_pareto</span> <span class="kn">import</span> <span class="n">GPD</span>

<span class="n">dt1</span> <span class="o">=</span> <span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="s">'LogRet'</span><span class="p">]</span><span class="o">&gt;</span><span class="n">thr</span><span class="p">][</span><span class="s">'LogRet'</span><span class="p">].</span><span class="n">values</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">pareto_model</span><span class="p">:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span><span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xi</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'xi'</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">GPD</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">thr</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">xi</span><span class="o">=</span><span class="n">xi</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">dt1</span><span class="p">)</span>
    <span class="n">trace_pareto</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">draws</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_pareto</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/extreme_intro/trace_pareto.webp" alt="The trace of the Pareto model" /></p>

<p>Notice that in our model we fixed $\mu$ to the threshold, which is fixed.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pareto_model</span><span class="p">:</span>
    <span class="n">ppc_pareto</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace_pareto</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">ppc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">thr</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/extreme_intro/ppc_pareto.webp" alt="The posterior predictive of the Pareto model" /></p>

<p>In the last figure, the mean has been removed as Arviz has some issues in computing
the mean for this posterior predictive, probably because of the heavy tails or
due to the discontinuity at the threshold.
Regardless from this, the agreement between the posterior predictive and the
data looks perfect.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We introduced the Extreme Value theory, and we first applied it by
fitting the weekly minima of the Apple stocks by using the GEV distribution.
We then showed how to fit the data above a fixed threshold by using the generalized Pareto
distribution.</p>

<h2 id="suggested-readings">Suggested readings</h2>

<ul>
  <li><cite>Haan, L. d., Ferreira, A. (2006). Extreme Value Theory: An Introduction. UK: Springer New York.</cite></li>
  <li><cite>Coles, S. (2001). An Introduction to Statistical Modeling of Extreme Values. Germany: Springer London.</cite></li>
</ul>

  </div><a class="u-url" href="/statistics/extreme_intro" hidden></a>

  <div>
          
          
  </div>

  <br>
  <div id='autograph'>
          Stippe May 19, 2024

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>

                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

