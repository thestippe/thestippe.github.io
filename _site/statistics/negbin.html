<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The Negative Binomial model | Data Perspectives</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="The Negative Binomial model" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An evolution of the Poisson model" />
<meta property="og:description" content="An evolution of the Poisson model" />
<link rel="canonical" href="http://localhost:4000/statistics/negbin" />
<meta property="og:url" content="http://localhost:4000/statistics/negbin" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-12-24T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The Negative Binomial model" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2023-12-24T00:00:00+00:00","datePublished":"2023-12-24T00:00:00+00:00","description":"An evolution of the Poisson model","headline":"The Negative Binomial model","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/negbin"},"url":"http://localhost:4000/statistics/negbin"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;"><ul hidden='hidden' id="postList"><li>
                        Nonparametric models;/statistics/nonparametric_intro;1
                </li><li>
                        Synthetic control;/statistics/synthetic_control;2
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;3
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;4
                </li><li>
                        Randomized controlled trials;/statistics/randomized;5
                </li><li>
                        Causal inference;/statistics/causal_intro;6
                </li><li>
                        Experiment analysis;/statistics/experiment_design;7
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;8
                </li><li>
                        Application of survival analysis with discrete times;/statistics/survival_example_2;9
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;10
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;11
                </li><li>
                        Random models and mixed models;/statistics/random_models;12
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;13
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;14
                </li><li>
                        Poisson regression;/statistics/poisson_regression;15
                </li><li>
                        Logistic regression;/statistics/logistic_regression;16
                </li><li>
                        Robust linear regression;/statistics/robust_regression;17
                </li><li>
                        Multi-linear regression;/statistics/multivariate_regression;18
                </li><li>
                        Linear regression with binary input;/statistics/regression_binary_input;19
                </li><li>
                        Introduction to the linear regression;/statistics/regression;20
                </li><li>
                        Model comparison, cont.;/statistics/model_averaging_cont;21
                </li><li>
                        Model comparison;/statistics/model_averaging;22
                </li><li>
                        Reparametrizing your model;/statistics/reparametrization;23
                </li><li>
                        Predictive checks;/statistics/predictive_checks;24
                </li><li>
                        Trace inspection;/statistics/trace_inspection;25
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;26
                </li><li>
                        Mixture models;/statistics/mixture;27
                </li><li>
                        Multidimensional distributions;/statistics/categories;28
                </li><li>
                        The Gaussian model;/statistics/reals;29
                </li><li>
                        The Negative Binomial model;/statistics/negbin;30
                </li><li>
                        The Poisson model;/statistics/poisson;31
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;32
                </li><li>
                        Section introduction;/statistics/simple_models_intro;33
                </li><li>
                        Some notation about probability;/statistics/probability_reminder;34
                </li><li>
                        How does MCMC works;/statistics/mcmc_intro;35
                </li><li>
                        Introduction to Bayesian inference;/statistics/bayes_intro;36
                </li><li>
                        An overview to statistics;/statistics/preface;37
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;38
                </li><li>
                        Design tricks;/dataviz/design-introduction;39
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;40
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;41
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;42
                </li><li>
                        Visual queries;/dataviz/visual-queries;43
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;44
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;45
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;46
                </li><li>
                        Perception;/dataviz/perception;47
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;48
                </li><li>
                        Marks and channels;/dataviz/marks-channels;49
                </li><li>
                        Data abstraction;/dataviz/data-types;50
                </li><li>
                        Data visualization;/dataviz/dataviz;51
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/poisson" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/reals" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">The Negative Binomial model</h1>
    <p class="post-meta"><time class="dt-published" datetime="2023-12-24T00:00:00+00:00" itemprop="datePublished">
        Dec 24, 2023
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  9&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In the last post we discussed the simplest model for count data, namely
the Poisson model.
Sometimes this model is not flexible enough, as in the Poisson distribution
the variance is fixed by the mean.
If your data is over-dispersed (or under-dispersed) the Poisson model
might be not appropriate. This usually happens when your data cannot be treated
as sampled according to an iid set of random variables.
This often happens, as an example, with dataset coming from social networks,
where each post has its own probability of interaction, depending on the
topic but also on the algorithm modifications during the time.
In this post I will explain how to deal with this kind of data
by using the Negative Binomial model.</p>

<h2 id="trying-with-the-poisson-model">Trying with the Poisson model</h2>

<p>I downloaded my own twitter data from <a href="https://analytics.twitter.com">analytics.twitter.com</a>,
and I wanted to analyze what’s the distribution of interaction
rates across my tweets, and here’s the results <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>.</p>

<table>
  <thead>
    <tr>
      <th>interactions</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>29</td>
    </tr>
    <tr>
      <td>1</td>
      <td>36</td>
    </tr>
    <tr>
      <td>2</td>
      <td>33</td>
    </tr>
    <tr>
      <td>3</td>
      <td>28</td>
    </tr>
    <tr>
      <td>4</td>
      <td>24</td>
    </tr>
    <tr>
      <td>5</td>
      <td>25</td>
    </tr>
    <tr>
      <td>6</td>
      <td>13</td>
    </tr>
    <tr>
      <td>7</td>
      <td>6</td>
    </tr>
    <tr>
      <td>8</td>
      <td>3</td>
    </tr>
    <tr>
      <td>9</td>
      <td>4</td>
    </tr>
    <tr>
      <td>10</td>
      <td>6</td>
    </tr>
    <tr>
      <td>11</td>
      <td>2</td>
    </tr>
    <tr>
      <td>12</td>
      <td>2</td>
    </tr>
    <tr>
      <td>14</td>
      <td>2</td>
    </tr>
    <tr>
      <td>16</td>
      <td>2</td>
    </tr>
    <tr>
      <td>25</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<p>we can now check if the Poisson model does a good job in fitting the data.
As before we will assume an exponential model for the Poisson mean,
but since we have a larger average we choose $\lambda=1/50$ for the exponential
parameter.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'./data/tweets.csv'</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">yobs</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'interactions'</span><span class="p">]</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">poisson</span><span class="p">:</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s">'mu'</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Poisson</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/negbin/trace_poisson.webp" alt="The Poisson trace" /></p>

<p>The trace seems OK, and for the sake of brevity we won’t perform all the
trace checks. However, keep in mind that you should always do them.
To compute the trace, we used the numpyro sampler, which is much
faster than the ordinary NUTS sampler.</p>

<p>Let us jump to the posterior predictive check and verify if our model
is capable to reproduce the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">poisson</span><span class="p">:</span>
    <span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">ppc</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/negbin/ppc_poisson.webp" alt="The Poisson posterior predictive" /></p>

<p>The average value doesn’t look at all like the observed points, and the error
bands fail to include the data.
This is definitely not a suitable model for our data.</p>

<h2 id="the-negative-binomial-model">The Negative Binomial model</h2>

<p>We will now try and build a model with a Negative Binomial likelihood.
According to Ockham’s razor principle, since
the new model will have one more parameter than the previous one,
in order to justify the increased model complexity, we should
observe a clear improvement in the performances.</p>

<p>The new model assumes</p>

\[Y \sim \mathcal{NegBin}(\theta, \nu)\]

<details class="math-details">
<summary> The negative binomial distribution</summary>
<div class="math-details-detail">

Given a set of i.i.d. Bernoulli random variables $X_i$
having success probability $p\,,$
the negative binomial model describes the number of failures $x \in \mathbb{N}$ before you get
a fixed number of successes $n&gt;0\,.$

$$
p(x | n, p) \propto p^n (1-p)^x
$$

We must now count the number of possible ways to rearrange the events.
The last event is, by construction, a success. Therefore, we
have that the number of possible ways to get $x$ failures
out of $n+x-1$ events is $\binom{n+x-1}{x}\,,$
so
$$
p(x | n, p) = \binom{x+n-1}{x} p^n (1-p)^x\,.
$$

The parameter $n$ should, in principle, be integer.
We can however extend the definition of the negative binomial
distribution by means of the Gamma function

$$
p(x | n, p) = \frac{\Gamma(x+n)}{\Gamma(x+1)\Gamma(n)} p^n (1-p)^x\,.
$$

The parameter $p$ must belong to the $[0, 1]$ interval, and it can be parametrized as

$$
p = \frac{\mu}{\mu+n}  \,, \mu \geq 0\,.
$$

When $n=1$ the negative binomial is also known as the geometric distribution, and this distribution
has

$$
p(x | p) = p (1-p)^x\,.
$$

This distribution has expected value

$$
\begin{align}
\mathbb{E}_{geom}[X] = &amp; \sum_{x=0}^\infty x p (1-p)^x = p \left(\sum_{x=1}^\infty   x q^x\right)_{q=1-p}
=  p  \left(q \sum_{x=0}^\infty   x q^{x-1}\right)_{q=1-p} \\
 = &amp; p \left(q \frac{\partial}{\partial q} \sum_{x=0}^\infty   q^{x}\right)_{q=1-p} 
= p \left(q \frac{\partial}{\partial q} \frac{1}{1-q} \right)_{q=1-p} 
= p \left( \frac{q}{(1-q)^2}\right)_{q=1-p} \\= &amp; p \frac{1-p}{p^2} = \frac{1-p}{p}
\end{align}
$$

Since the negative binomial with a general $n$ can be seen as the sum of $n$ independent
geometric random variables, it is straightforward to get

$$
\mathbb{E}[X] = n \frac{1-p}{p}\,.
$$

In the same way we can calculate

$$
Var[X] = n \frac{1-p}{p^2}\,.
$$

</div>
</details>

<p>The above distribution, in PyMC, has more than one parametrization,
but we will stick to the one already introduced,
where $\theta \in [0, 1]$ and $\nu &gt; 0\,.$</p>

<p>Since we want our guess for the parameters, we will assume</p>

\[\theta \sim \mathcal{U}(0, 1)\]

<p>We also expect $\nu$ to be somewhere between 1 and 10, as it should be roughly of
the same order of magnitude of the mean of the observed data.
Taking a mean $Y$ of 5 and $p=1/2$ we would have</p>

\[10 = \nu \frac{1/2}{1-1/2} = \nu\]

<p>so a reasonable assumption could be</p>

\[\nu \sim \mathcal{Exp}(1/10)\]

<p>We can now implement our model and verify if the trace has any problem.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">negbin</span><span class="p">:</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s">'nu'</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s">'theta'</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">NegativeBinomial</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">nu</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="p">)</span>
    <span class="n">trace_nb</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_nb</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/negbin/trace_nb.webp" alt="The Negative Binomial trace" /></p>

<p>So far so good, so let us check the performances of the new model in reproducing
the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">negbin</span><span class="p">:</span>
    <span class="n">ppc_nb</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace_nb</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">ppc_nb</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/negbin/ppc_nb.webp" alt="The Negative Binomial posterior predictive" /></p>

<p>The posterior predictive looks way better than the Poisson one.</p>

<p>A visual inspection is fundamental in checking the performances of posterior predictive
distribution in reproducing the data.
We can however use a very popular tool to have some additional information.
We will use the <a href="https://arxiv.org/abs/1507.04544"><strong>Leave One Out</strong> cross validation</a>.
This technique, which uses the Pareto smoothed importance sampling,
is equivalent to removing each datum
and verifying how unlikely is the removed point with according to the new model.
If the point is not too unlikely to appear, then the model is appropriate
in reproducing the data, otherwise you may consider to look for a new model.
This comparison requires the computation of the log likelihood,
and the entire procedure can be done as follows</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">poisson</span><span class="p">:</span>
    <span class="n">pm</span><span class="p">.</span><span class="n">compute_log_likelihood</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>

<span class="k">with</span> <span class="n">negbin</span><span class="p">:</span>
    <span class="n">pm</span><span class="p">.</span><span class="n">compute_log_likelihood</span><span class="p">(</span><span class="n">trace_nb</span><span class="p">)</span>

<span class="n">df_comp_loo</span> <span class="o">=</span> <span class="n">az</span><span class="p">.</span><span class="n">compare</span><span class="p">({</span><span class="s">"poisson"</span><span class="p">:</span> <span class="n">trace</span><span class="p">,</span> <span class="s">"negative binomial"</span><span class="p">:</span> <span class="n">trace_nb</span><span class="p">})</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_compare</span><span class="p">(</span><span class="n">df_comp_loo</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/negbin/plot_loo.webp" alt="The comparison between the two models" /></p>

<p>This method confirms our conclusions, the Negative Binomial model
performs better than the Poisson one.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We have discussed the Negative Binomial model and introduced the LOO method
to perform a model comparison.
We also saw in which situations it might be appropriate to choose a Negative
Binomial model over a Poisson one.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">pytensor</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Mon Jun 24 2024
<br />
<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />
<br />
xarray  : 2024.5.0
<br />
pytensor: 2.20.0
<br />
numpyro : 0.15.0
<br />
jax     : 0.4.28
<br />
jaxlib  : 0.4.28
<br />
<br />
pandas    : 2.2.2
<br />
arviz     : 0.18.0
<br />
pymc      : 5.15.0
<br />
matplotlib: 3.9.0
<br />
numpy     : 1.26.4
<br />
<br />
Watermark: 2.4.3
<br />
</div>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>This happened when Twitter was a decent platform, and you could access your own statistics. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div><a class="u-url" href="/statistics/negbin" hidden></a>

  <div>
          
          
  </div>

  <br>
  <div id='autograph'>
          Stippe Dec 24, 2023

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>

                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

