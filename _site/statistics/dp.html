<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Dirichlet Process Mixture Models | Data Perspectives</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Dirichlet Process Mixture Models" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Mixture models with variable number of components" />
<meta property="og:description" content="Mixture models with variable number of components" />
<link rel="canonical" href="http://localhost:4000/statistics/dp" />
<meta property="og:url" content="http://localhost:4000/statistics/dp" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-08-25T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Dirichlet Process Mixture Models" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2024-08-25T00:00:00+00:00","datePublished":"2024-08-25T00:00:00+00:00","description":"Mixture models with variable number of components","headline":"Dirichlet Process Mixture Models","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/dp"},"url":"http://localhost:4000/statistics/dp"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;">

                
                
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    
                    
                    
                    
                    

        <ul hidden='hidden' id="postList"><li>
                        Poisson regression;/statistics/poisson_regression;1
                </li><li>
                        Logistic regression;/statistics/logistic_regression;2
                </li><li>
                        Robust linear regression;/statistics/robust_regression;3
                </li><li>
                        Multi-linear regression;/statistics/multivariate_regression;4
                </li><li>
                        Linear regression with binary input;/statistics/regression_binary_input;5
                </li><li>
                        Horseshoe priors;/statistics/horseshoe;6
                </li><li>
                        Introduction to the linear regression;/statistics/regression;7
                </li><li>
                        MRP;/statistics/mrp;8
                </li><li>
                        Model comparison, cont.;/statistics/model_averaging_cont;9
                </li><li>
                        Model comparison;/statistics/model_averaging;10
                </li><li>
                        Application of the Lotka-Volterra model;/statistics/lotka_volterra;11
                </li><li>
                        Differential equations;/statistics/ode;12
                </li><li>
                        Introduction to GIS;/gis/gis_intro;13
                </li><li>
                        Re-parametrizing your model;/statistics/reparametrization;14
                </li><li>
                        Predictive checks;/statistics/predictive_checks;15
                </li><li>
                        Trace inspection;/statistics/trace_inspection;16
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;17
                </li><li>
                        Mixture models;/statistics/mixture;18
                </li><li>
                        Multidimensional distributions;/statistics/categories;19
                </li><li>
                        Dirichlet Process Mixture Models;/statistics/dp;20
                </li><li>
                        The Gaussian model;/statistics/reals;21
                </li><li>
                        Bayesian Additive Regression Trees;/statistics/bart;22
                </li><li>
                        Bonus: counting animals in a park;/statistics/hypergeom;23
                </li><li>
                        Splines;/statistics/spline;24
                </li><li>
                        The Negative Binomial model;/statistics/negbin;25
                </li><li>
                        Gaussian processes regression;/statistics/gp_example;26
                </li><li>
                        Gaussian processes;/statistics/gp;27
                </li><li>
                        The Poisson model;/statistics/poisson;28
                </li><li>
                        Nonparametric models;/statistics/nonparametric_intro;29
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;30
                </li><li>
                        Structural time series;/statistics/structural_time_series;31
                </li><li>
                        Time series;/statistics/time_series;32
                </li><li>
                        Some notation about probability;/statistics/probability_reminder;33
                </li><li>
                        Synthetic control;/statistics/synthetic_control;34
                </li><li>
                        How does MCMC works;/statistics/mcmc_intro;35
                </li><li>
                        Regression discontinuity design;/statistics/rdd;36
                </li><li>
                        Introduction to Bayesian inference;/statistics/bayes_intro;37
                </li><li>
                        An overview to statistics;/statistics/preface;38
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;39
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;40
                </li><li>
                        Randomized controlled trials;/statistics/randomized;41
                </li><li>
                        Causal inference and Bayesian networks;/statistics/causal_intro_2;42
                </li><li>
                        Causal inference;/statistics/causal_intro;43
                </li><li>
                        Experiment analysis with many blocking variables;/statistics/experiment_design_cont;44
                </li><li>
                        Experiment analysis;/statistics/experiment_design;45
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;46
                </li><li>
                        Application of survival analysis with discrete times;/statistics/survival_example_2;47
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;48
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;49
                </li><li>
                        Random models and mixed models;/statistics/random_models;50
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;51
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;52
                </li><li>
                        Drawing geographic maps;/dataviz/geography;53
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;54
                </li><li>
                        Design tricks;/dataviz/design-introduction;55
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;56
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;57
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;58
                </li><li>
                        Visual queries;/dataviz/visual-queries;59
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;60
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;61
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;62
                </li><li>
                        Perception;/dataviz/perception;63
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;64
                </li><li>
                        Marks and channels;/dataviz/marks-channels;65
                </li><li>
                        Data abstraction;/dataviz/data-types;66
                </li><li>
                        Data visualization;/dataviz/dataviz;67
                </li><li>
                        Section introduction;/statistics/simple_models_intro;68
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/reals" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/categories" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">Dirichlet Process Mixture Models</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-08-25T00:00:00+00:00" itemprop="datePublished">
        Aug 25, 2024
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  9&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In <a href="/statistics/mixture">a previous post</a> we discussed parametric mixture models,
which are mixture models where the number of components are fixed.
These models are more flexible than the respective one-component model,
but there are situations in which this flexibility is not enough, since one does not
know in advance the number of components to take.</p>

<p>One could naively try and assume a large number of components in a mixture model,
unfortunately this is not a good idea, as the behavior of the Dirichlet distribution
is ill-defined as the number of components $K$ diverges.</p>

<p>Dirichlet Processes Mixture Models, or DPMMs, are the appropriate way to generalize mixture
models, as the limit $K \rightarrow \infty$ is well-defined.
Here we will only give an intuitive justification to DPs, and the interested
reader will find a more formal discussion in the bibliography.
Rather than assuming</p>

\[\pi \vert \alpha \sim \mathcal{Dir}(\alpha,\dots, \alpha)\]

<p>one simply has to assume</p>

\[\pi \vert \alpha \sim \mathcal{Dir}(\alpha/K,\dots, \alpha/K)\,.\]

<p>While this behavior is well-defined from a theoretical point of view,
it is not a good idea to implement the above formula in order to sample the
prior distribution, since this method is prone to numerical errors as $K$ grows.
The most reliable way, at the moment, to sample from a DP, is to use the <strong>stick breaking process</strong></p>

\[\begin{align*}
\theta_1,\dots,\theta_K \sim &amp; B(1, \alpha) \\
\pi_1 = &amp; \theta_1 \\
\pi_i = &amp; \theta_i \prod_{j&lt;i} (1-\theta_j)
\end{align*}\]

<p>DPMMs have been extensively applied to many fields, and they are currently very popular
in the text classification, as the number of topics is generally not previously known.</p>

<h2 id="application-to-the-in-home-geriatric-assessment-dataset">Application to the In-Home Geriatric Assessment dataset</h2>

<p>In this section we will apply DPMMs to the IHGA dataset,
as already done in <a href="https://www.cs.princeton.edu/courses/archive/fall09/cos597A/papers/KKD2008.pdf">this study</a>.
In the randomized clinical trial, a set of 572 elderly people has been
randomly assigned to one of two groups. The control group, made of 287 units,
received the standard health care, while the remaining units received the standard health care
plus an experimental preventive treatment.
The number of hospitalizations for the individuals has been therefore been monitored
for two years.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">Hospitalizations</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">Control</td>
      <td>138</td>
      <td>77</td>
      <td>46</td>
      <td>12</td>
      <td>8</td>
      <td>4</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <td style="text-align: right">Treatment</td>
      <td>147</td>
      <td>83</td>
      <td>37</td>
      <td>13</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>As in the cited document, we will use a DPMM, but we will use an uninformative Gamma prior
for the average number of hospitalizations, adapting the model
proposed in <a href="https://www.pymc.io/projects/examples/en/latest/mixture_models/dp_mix.html">this PyMC example</a>
to our needs.
We will assume two identical models for the test group and for the control one,
and we will then compare the number of hospitalizations averaged over the sample
in order to assess the effectiveness of the treatment.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">statsmodels</span> <span class="k">as</span> <span class="n">sm</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">n_control</span> <span class="o">=</span> <span class="p">[</span><span class="mi">138</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="mi">46</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="n">nhosp_control</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">elem</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">elem</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_control</span><span class="p">)],[])</span>

<span class="n">n_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">147</span><span class="p">,</span> <span class="mi">83</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">nhosp_test</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">elem</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">elem</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_test</span><span class="p">)],[])</span>

<span class="n">K</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_c</span><span class="p">:</span>
    <span class="n">alpha_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s">"alpha_c"</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">w_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">StickBreakingWeights</span><span class="p">(</span><span class="s">'w_c'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_c</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">lam_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s">"lam_c"</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">))</span>
    <span class="n">y_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Mixture</span><span class="p">(</span>
        <span class="s">"y_c"</span><span class="p">,</span> <span class="n">w_c</span><span class="p">,</span> <span class="n">pm</span><span class="p">.</span><span class="n">Poisson</span><span class="p">.</span><span class="n">dist</span><span class="p">(</span><span class="n">lam_c</span><span class="p">),</span> <span class="n">observed</span><span class="o">=</span><span class="n">nhosp_control</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_t</span><span class="p">:</span>
    <span class="n">alpha_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s">"alpha_t"</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">w_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">StickBreakingWeights</span><span class="p">(</span><span class="s">'w_t'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_t</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">lam_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s">"lam_t"</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">))</span>
    <span class="n">y_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Mixture</span><span class="p">(</span>
        <span class="s">"y_t"</span><span class="p">,</span> <span class="n">w_t</span><span class="p">,</span> <span class="n">pm</span><span class="p">.</span><span class="n">Poisson</span><span class="p">.</span><span class="n">dist</span><span class="p">(</span><span class="n">lam_t</span><span class="p">),</span> <span class="n">observed</span><span class="o">=</span><span class="n">nhosp_test</span>
    <span class="p">)</span>

<span class="k">with</span> <span class="n">model_c</span><span class="p">:</span>
    <span class="n">idata_c</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span>
                        <span class="n">draws</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="k">with</span> <span class="n">model_t</span><span class="p">:</span>
    <span class="n">idata_t</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span>
                        <span class="n">draws</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</code></pre></div></div>

<p>We can now inspect the traces of our models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_c</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/dp/trace_c.webp" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_t</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/dp/trace_t.webp" alt="" /></p>

<p>There are few divergences, but this is not a big issue.
This is quite normal, as sampling from a DP is numerically demanding
due to the large correlations of the weights.</p>

<p>We can now verify if our models can reproduce the observed data</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model_c</span><span class="p">:</span>
    <span class="n">idata_c</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata_c</span><span class="p">))</span>

<span class="k">with</span> <span class="n">model_t</span><span class="p">:</span>
    <span class="n">idata_t</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata_t</span><span class="p">))</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">az</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="n">idata_t</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s">'posterior_predictive'</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'y_t'</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">).</span><span class="n">T</span><span class="p">:</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s">'step'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
           <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">nhosp_test</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s">'step'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Test group'</span><span class="p">)</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">az</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="n">idata_c</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s">'posterior_predictive'</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'y_c'</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">).</span><span class="n">T</span><span class="p">:</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s">'step'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
           <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">nhosp_control</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s">'step'</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Control group'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/dp/ppc.webp" alt="The PPC of our models" /></p>

<p>The agreement is more than satisfactory, but it is hard to assess which model
is better by simply looking at the above figures.
We can however easily compare the distributions of the number of hospitalizations
averaged over the individuals.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mu_t</span> <span class="o">=</span> <span class="n">idata_t</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y_t'</span><span class="p">].</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'y_t_dim_2'</span><span class="p">)).</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">mu_c</span> <span class="o">=</span> <span class="n">idata_c</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y_c'</span><span class="p">].</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'y_c_dim_2'</span><span class="p">)).</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">az</span><span class="p">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">mu_t</span><span class="o">/</span><span class="n">mu_c</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">'$\mu_t/\mu_c$'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/dp/mu_ratio.webp" alt="The ratio of the average number of hospitalizations" /></p>

<p>We are therefore quite confident in concluding that the treatment group has an average number of hospitalizations
than the control group.</p>

<h2 id="conclusions">Conclusions</h2>

<p>We have seen how DPMMs generalize Dirichlet Mixtures to an unknown number of components,
and we have seen an application of this kind of model to the IHGA dataset.</p>

<h2 id="suggested-readings">Suggested readings</h2>
<ul>
  <li><cite>Müller, P., Quintana, F. A., Jara, A., Hanson, T. (2015). Bayesian Nonparametric Data Analysis. Springer International Publishing.</cite></li>
  <li><cite>Milovan Krnjajić, Athanasios Kottas, David Draper,  Parametric and nonparametric Bayesian model specification: A case study involving models for count data,  Computational Statistics &amp; Data Analysis,  Volume 52, Issue 4,  2008,</cite></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Thu Aug 22 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />

<br />
xarray : 2024.5.0
<br />
numpyro: 0.15.0
<br />
jax    : 0.4.28
<br />
jaxlib : 0.4.28
<br />

<br />
arviz      : 0.18.0
<br />
numpy      : 1.26.4
<br />
seaborn    : 0.13.2
<br />
pandas     : 2.2.2
<br />
matplotlib : 3.9.0
<br />
pymc       : 5.15.0
<br />
statsmodels: 0.14.2
<br />

<br />
Watermark: 2.4.3
<br />
</div>

  </div><a class="u-url" href="/statistics/dp" hidden></a>

  <br>
  <div id='autograph'>
          Stippe Aug 25, 2024

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>
                  Opinions are mine, mistakes too, and if you find any feel free to report it via mail or via Twitter.
                  <br>
                  Most of the material in the statistics section is an adaptation to Python of some pre-existing model.
                  <br>
                  I have tried to provide the necessary credits, but if you think that a relevant contribution is missing, please let me know.
                  <br>
                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

