<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Gaussian processes | Data Perspectives</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Gaussian processes" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How to make the normal distribution infinite dimensional" />
<meta property="og:description" content="How to make the normal distribution infinite dimensional" />
<link rel="canonical" href="http://localhost:4000/statistics/gp" />
<meta property="og:url" content="http://localhost:4000/statistics/gp" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-08-04T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Gaussian processes" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2024-08-04T00:00:00+00:00","datePublished":"2024-08-04T00:00:00+00:00","description":"How to make the normal distribution infinite dimensional","headline":"Gaussian processes","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/gp"},"url":"http://localhost:4000/statistics/gp"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;">

                
                
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    
                    
                    
                    
                    

        <ul hidden='hidden' id="postList"><li>
                        Poisson regression;/statistics/poisson_regression;1
                </li><li>
                        Logistic regression;/statistics/logistic_regression;2
                </li><li>
                        Robust linear regression;/statistics/robust_regression;3
                </li><li>
                        Multi-linear regression;/statistics/multivariate_regression;4
                </li><li>
                        Linear regression with binary input;/statistics/regression_binary_input;5
                </li><li>
                        Horseshoe priors;/statistics/horseshoe;6
                </li><li>
                        Introduction to the linear regression;/statistics/regression;7
                </li><li>
                        MRP;/statistics/mrp;8
                </li><li>
                        Model comparison, cont.;/statistics/model_averaging_cont;9
                </li><li>
                        Model comparison;/statistics/model_averaging;10
                </li><li>
                        Application of the Lotka-Volterra model;/statistics/lotka_volterra;11
                </li><li>
                        Differential equations;/statistics/ode;12
                </li><li>
                        Introduction to GIS;/gis/gis_intro;13
                </li><li>
                        Re-parametrizing your model;/statistics/reparametrization;14
                </li><li>
                        Predictive checks;/statistics/predictive_checks;15
                </li><li>
                        Trace inspection;/statistics/trace_inspection;16
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;17
                </li><li>
                        Mixture models;/statistics/mixture;18
                </li><li>
                        Multidimensional distributions;/statistics/categories;19
                </li><li>
                        Dirichlet Process Mixture Models;/statistics/dp;20
                </li><li>
                        The Gaussian model;/statistics/reals;21
                </li><li>
                        Bayesian Additive Regression Trees;/statistics/bart;22
                </li><li>
                        Bonus: counting animals in a park;/statistics/hypergeom;23
                </li><li>
                        Splines;/statistics/spline;24
                </li><li>
                        The Negative Binomial model;/statistics/negbin;25
                </li><li>
                        Gaussian processes regression;/statistics/gp_example;26
                </li><li>
                        Gaussian processes;/statistics/gp;27
                </li><li>
                        The Poisson model;/statistics/poisson;28
                </li><li>
                        Nonparametric models;/statistics/nonparametric_intro;29
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;30
                </li><li>
                        Structural time series;/statistics/structural_time_series;31
                </li><li>
                        Time series;/statistics/time_series;32
                </li><li>
                        Some notation about probability;/statistics/probability_reminder;33
                </li><li>
                        Synthetic control;/statistics/synthetic_control;34
                </li><li>
                        How does MCMC works;/statistics/mcmc_intro;35
                </li><li>
                        Regression discontinuity design;/statistics/rdd;36
                </li><li>
                        Introduction to Bayesian inference;/statistics/bayes_intro;37
                </li><li>
                        An overview to statistics;/statistics/preface;38
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;39
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;40
                </li><li>
                        Randomized controlled trials;/statistics/randomized;41
                </li><li>
                        Causal inference and Bayesian networks;/statistics/causal_intro_2;42
                </li><li>
                        Causal inference;/statistics/causal_intro;43
                </li><li>
                        Experiment analysis with many blocking variables;/statistics/experiment_design_cont;44
                </li><li>
                        Experiment analysis;/statistics/experiment_design;45
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;46
                </li><li>
                        Application of survival analysis with discrete times;/statistics/survival_example_2;47
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;48
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;49
                </li><li>
                        Random models and mixed models;/statistics/random_models;50
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;51
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;52
                </li><li>
                        Drawing geographic maps;/dataviz/geography;53
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;54
                </li><li>
                        Design tricks;/dataviz/design-introduction;55
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;56
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;57
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;58
                </li><li>
                        Visual queries;/dataviz/visual-queries;59
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;60
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;61
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;62
                </li><li>
                        Perception;/dataviz/perception;63
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;64
                </li><li>
                        Marks and channels;/dataviz/marks-channels;65
                </li><li>
                        Data abstraction;/dataviz/data-types;66
                </li><li>
                        Data visualization;/dataviz/dataviz;67
                </li><li>
                        Section introduction;/statistics/simple_models_intro;68
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/poisson" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/gp_example" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">Gaussian processes</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-08-04T00:00:00+00:00" itemprop="datePublished">
        Aug 4, 2024
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  18&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>As explained on the <a href="https://mc-stan.org/docs/stan-users-guide/gaussian-processes.html">stan user guide</a>,
gaussian processes, for short GPs, is a powerful tool to perform regression,
and its underlying assumption is
that the variable $y$ follows a multivariate normal distribution</p>

\[y \sim \mathcal{MvN}(m(x), K(x \vert \theta))\]

<p>where $m(\cdot)$ is any function, and it represents the <strong>mean</strong>,
while $K(\cdot \vert \theta)$ is the <strong>covariance  function</strong>,
and it is a matrix-valued function.</p>

<p>Since $K(x \vert \theta)$ represents the covariance, it must be a <strong>symmetric</strong>
and <strong>positive-defined</strong> function of $x\,.$</p>

<p>Different choices of $m$ and $K$ will give different properties to the GP.
The two most common choices for $m$ are the constant function and the linear function.
The possible choices for the covariance function $K$ are much broader,
and here we will discuss some of the most popular choices.</p>

<p>Since the kernel must be a symmetric matrix, its elements must be given
by a (scalar) function $k(x, y)\,,$ where we neglect the parameter dependence.
A very versatile choice is to assume that the kernel is a function of a scalar
combination of $x$ and $y$ (which can be vector-valued), therefore
it can depend on $\lVert x-y\rVert^2$ or on $x\cdot y\,.$
In the first case you get a <strong>stationary</strong> kernel, otherwise you get
a <strong>polynomial</strong> kernel.
Stationary kernels are invariant under translation, so their value
does not depend on the absolute position on the point,
but only on the relative distance from the other points.</p>

<p>In the following, we will restrict our discussion to the one-dimensional
case, so we will replace $\lVert x-y \rVert^2$ with $(x-y)^2$
and $x\cdot y$ with $xy\,,$
but it is immediate to recover the general definition.</p>

<p>Notice that, generally, if the dependence on a parameter is multiplicative,
then in PyMC the parameter is generally dropped.
We will however discuss it since it is useful to understand what role is played
by the parameter.</p>

<h2 id="some-common-kernel-choice">Some common kernel choice</h2>

<h3 id="the-rational-quadratic-kernel">The Rational Quadratic kernel</h3>

<p>This kernel is, often, the first choice, due to its nice properties.
It has in fact some nice properties one may desire:</p>
<ul>
  <li>it vanishes as $\lVert x-y \rVert \rightarrow \infty$</li>
  <li>it is a smooth function of $\lVert x-y \rVert^2\,.$</li>
</ul>

<p>This kernel reads:</p>

\[K(x, y \vert \sigma, \ell) = \sigma^2 
\exp{\left( -\frac{(x-y)^2}{2\ell^2} \right)}\]

<p>Let us now visualize how does a function distributed according to this
kernel behave</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">xtest</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">kexpquad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="n">sigma</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">lng</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">nplot</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">sigma</span><span class="p">),</span> <span class="n">ncols</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">lng</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigma</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lng</span><span class="p">):</span>
        <span class="n">kf</span> <span class="o">=</span> <span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="n">kexpquad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nplot</span><span class="p">):</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="n">xtest</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">kf</span><span class="p">))</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">"$\sigma=$"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">+</span><span class="sa">r</span><span class="s">", $\ell=$"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">r</span><span class="s">"$K(x,y)=\sigma^2 \exp\left({-(x-y)^2/(2\ell^2)}\right)$"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp/expquadkernel.webp" alt="Some sample of a function distributed
according to the Exponential Quadratic kernel" /></p>

<h3 id="the-rational-quadratic-kernel-1">The Rational Quadratic kernel</h3>

<p>This kernel has the form
\(K(x, y) = \left(1+\frac{(x-y)^2}{2\alpha \ell^2}\right)^{-\alpha}\)</p>

<p>is a little bit more versatile than the previous one,
since, as explained in <a href="https://www.cs.toronto.edu/~duvenaud/cookbook/">this very useful reference</a>,
it is equivalent to a linear combination of squared exponential kernels with different
$l\,.$
Moreover, as $\alpha \rightarrow \infty\,,$ one recovers the previous kernel.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">kratquad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">a</span><span class="o">*</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="p">)</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">lng</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">nplot</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span> <span class="n">ncols</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">lng</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">alpha</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lng</span><span class="p">):</span>
        <span class="n">kf</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="n">kratquad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nplot</span><span class="p">):</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="n">xtest</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">kf</span><span class="p">))</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">"$\alpha=$"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="sa">r</span><span class="s">", $\ell=$"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">r</span><span class="s">"$K(x,y)=\left(1+\frac{(x-y)^2}{2\alpha \ell^2}\right)^{-\alpha}$"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp/ratquadkernel.webp" alt="Some sample of a function distributed
according to the Rational Quadratic kernel" /></p>

<h2 id="matern-kernels">Matern kernels</h2>

<p>The above kernels are $C^\infty\,,$ and they will ensure $C^\infty\,,$
functions, so they are only appropriate if the underlying data-generation
mechanism ensure smoothness.
A family of non-smooth kernels is given by the <a href="https://en.wikipedia.org/wiki/Mat%C3%A9rn_covariance_function">Matérn kernels</a>,
which is a family of kernels $K^{Matern}_\nu(x, y, \ell)$ which, in the limit
$\nu \rightarrow\infty\,,$ converges to the exponential quadratic kernel.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">kmatern</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">l</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">p</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">l</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">l</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">p</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">l</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">l</span><span class="o">+</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="n">pval</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">lng</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">nplot</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">pval</span><span class="p">),</span> <span class="n">ncols</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">lng</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pval</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lng</span><span class="p">):</span>
        <span class="n">kf</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="n">kmatern</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nplot</span><span class="p">):</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="n">xtest</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">kf</span><span class="p">))</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">"$p=$"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">+</span><span class="sa">r</span><span class="s">", $\ell=$"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">r</span><span class="s">"$K^{Matern}_{p+1/2}(x,y,\ell)$"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp/maternkernel.webp" alt="Some sample of a function distributed
according to the Matern kernel" /></p>

<p>Notice that the $p=0$ kernel is sometimes named exponential
or Ornstein-Uhlenbeck kernel, and it defines a Markov process.
An GP defined by the exponential kernel is equivalent to an AR(1) process.</p>

<h3 id="the-cosine-kernel">The cosine kernel</h3>

<p>Another property one can encode into GPs is the periodicity.
As an example, the cosine kernel gives cosine-shaped functions.</p>

\[K(x, y) = \cos\left( \frac{2 \pi \left|x-y \right|}{\ell^2} \right)\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">kcos</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">lng</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="n">nplot</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">lng</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lng</span><span class="p">):</span>
    <span class="n">kf</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="n">kcos</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nplot</span><span class="p">):</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="n">xtest</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">kf</span><span class="p">))</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">"$\ell=$"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">))</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">r</span><span class="s">"$K(x,y)=\cos\left(\frac{2\pi\left| x-y\right|}{\ell^2}\right)$"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp/cosinekernel.webp" alt="Some sample of a function distributed
according to the cosine kernel" /></p>

<h3 id="the-periodic-kernel">The periodic kernel</h3>

<p>Sometimes a cosine is not enough, and you might be interested into a more general
form of periodic function. In this case, the periodic kernel might be what you need.</p>

\[K(x, y) = 
\exp{\left( - \frac{\sin^2{\left(\pi \left(x-y\right)/T\right)}}{2\ell^2} \right)}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">kperiodic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">T</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">l</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="n">tval</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="n">lng</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">nplot</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">tval</span><span class="p">),</span> <span class="n">ncols</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">lng</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tval</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lng</span><span class="p">):</span>
        <span class="n">kf</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="n">kperiodic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nplot</span><span class="p">):</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="n">xtest</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">kf</span><span class="p">))</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">"$T=$"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="o">+</span><span class="sa">r</span><span class="s">", $\ell=$"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">))</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">r</span><span class="s">"$K(x,y)=\exp(-\frac{\sin^2(\pi(x-y)/T)}{2\ell^2})$"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp/periodickernel.webp" alt="Some sample of a function distributed
according to the periodic kernel" /></p>

<h3 id="the-polynomial-kernel">The polynomial kernel</h3>

<p>By using GPs one can also perform polynomial regression.
The kernel</p>

\[K(x, y) = ((x-c)(y-c))^k\]

<p>will sample a monomial of order $k$ with origin $c\,.$</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">lng</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">c</span><span class="p">):</span>
        <span class="n">kf</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[((</span><span class="n">x</span><span class="o">-</span><span class="n">l</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">l</span><span class="p">))</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nplot</span><span class="p">):</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="n">xtest</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">kf</span><span class="p">))</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">"$k="</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s">", c="</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)</span><span class="o">+</span><span class="s">"$"</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">r</span><span class="s">"$K(x,y)= ((x-c)(y-c))^k$"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp/polynomialkernel.webp" alt="Some sample of a function distributed
according to the polynomial kernel" /></p>

<p>Notice that, if $k=0\,,$ we simply get the constant kernel.</p>

<h2 id="the-white-noise">The white noise</h2>

<p>Another useful kernel is the white noise.
If we take</p>

\[k(x, y) = \sigma^2 I\]

<p>where $I$ is the identity matrix, we have that the $n$ dimensional multivariate
normal becomes the product of $n$ univariate gaussian distribution,
so the points $y_i$ are i.i.d. according to a normal distribution with mean 0 and variance
$\sigma\,.$</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">lng</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">sig</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sigma</span><span class="p">):</span>
    <span class="n">kf</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xtest</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">xtest</span><span class="p">))</span><span class="o">*</span><span class="n">sig</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nplot</span><span class="p">):</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="n">xtest</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">kf</span><span class="p">))</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s">"$\sigma=$"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">sig</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">r</span><span class="s">"$K(x,y)=\sigma^2 \delta_{ij}$"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp/whitenoise.webp" alt="A GP with the white noise kernel" /></p>

<p>This kernel is usually implemented to encode the fact that the measurements are noisy.</p>

<h3 id="the-brownian-motion">The Brownian motion</h3>

<p>The brownian motion can be considered a GP too, and this process is obtained
by using the following kernel:</p>

\[K(x, y) = min(x, y)\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">])</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nplot</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="n">xtest</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">kf</span><span class="p">))</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">r</span><span class="s">"$K(x,y)=min(x, y)$"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/docs/assets/images/statistics/gp/minkernel.webp" alt="The result of the min kernel" /></p>

<h2 id="building-new-kernels">Building new kernels</h2>

<p>We only showed some of the most common kernels, and you could look for new ones
by yourself.
You can however also build new ones from the previous ones, 
by only keeping in mind that the covariance matrix must be symmetric and positive-defined.
In particular, some possible ways to build new kernels are the following:</p>
<ul>
  <li>you can take any linear combination $K_1(x, y)+K_2(x, y)$</li>
  <li>you can multiply by any positive scalar $\alpha K(x, y)$</li>
  <li>you can multiply two kernels $K_1(x, y)K_2(x, y)$</li>
  <li>you can replace your variable with any function of it $K(\Phi(x), K(\Phi(y))$</li>
  <li>You can define $\Phi(x) K(x, y) \Phi(y)$ for any positive $\Phi(x)\,.$</li>
  <li>You can take the convolution of a kernel with any positive function $\int dx dy K(x, y)f(x-x_0)f(y-y_0)$</li>
</ul>

<p>As an example, if you take as kernel the superposition
of a squared exponential kernel and a periodic kernel, you will
get a periodic signal superimposed to a squared exponential GP.
On the other hand, if you multiply them, you
will get a periodic kernel with varying amplitude.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="n">kperiodic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="n">kexpquad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">])</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nplot</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="n">xtest</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">kf</span><span class="p">))</span>
<span class="c1"># fig.suptitle(r"$K(x,y)=min(x, y)$")
</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="n">kperiodic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">kexpquad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">xtest</span><span class="p">])</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nplot</span><span class="p">):</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="n">xtest</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">kf</span><span class="p">))</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/gp/kernelcombination.webp" alt="An example of kernel combination" /></p>

<h2 id="conclusions">Conclusions</h2>

<p>I home I managed to convince you that GPs can be extremely powerful to add flexibility and encod desired properties
into your models, and in the next post we will discuss some practical application.</p>

<h2 id="suggested-readings">Suggested readings</h2>
<ul>
  <li><cite><a href="https://gaussianprocess.org/gpml/">Rasmussen, C. E., Williams, C. K. I. (2006). Gaussian Processes for Machine Learning. MIT Press.</a>
</cite></li>
</ul>

  </div><a class="u-url" href="/statistics/gp" hidden></a>

  <br>
  <div id='autograph'>
          Stippe Aug 4, 2024

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>
                  Opinions are mine, mistakes too, and if you find any feel free to report it via mail or via Twitter.
                  <br>
                  Most of the material in the statistics section is an adaptation to Python of some pre-existing model.
                  <br>
                  I have tried to provide the necessary credits, but if you think that a relevant contribution is missing, please let me know.
                  <br>
                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

