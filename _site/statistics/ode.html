<!DOCTYPE html>
<html lang="en"><head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W9G73E5P44"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W9G73E5P44');
</script>
          <link rel="icon" 
                type="image/png" 
                href="/docs/assets/images/dp_icon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Differential equations | Data Perspectives</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Differential equations" />
<meta name="author" content="Data-perspectives" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="When your mathematical model cannot be explicitly solved" />
<meta property="og:description" content="When your mathematical model cannot be explicitly solved" />
<link rel="canonical" href="http://localhost:4000/statistics/ode" />
<meta property="og:url" content="http://localhost:4000/statistics/ode" />
<meta property="og:site_name" content="Data Perspectives" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-10-06T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Differential equations" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Data-perspectives"},"dateModified":"2024-10-06T00:00:00+00:00","datePublished":"2024-10-06T00:00:00+00:00","description":"When your mathematical model cannot be explicitly solved","headline":"Differential equations","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/statistics/ode"},"url":"http://localhost:4000/statistics/ode"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Data Perspectives" />


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>
<a rel="me" href="https://vis.social/@thestippe" style="display: none;">Mastodon</a>
<link rel="manifest" href="manifest.json">
</head>
<body>

        <div id='upperBar'><header class="site-header">

        <div id='upperBarr'>
        <script src="https://d3js.org/d3.v7.js"></script>
                <div class="wrapper" style="display:flex;">

                
                
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    
                    
                    
                    
                    

        <ul hidden='hidden' id="postList"><li>
                        Poisson regression;/statistics/poisson_regression;1
                </li><li>
                        Logistic regression;/statistics/logistic_regression;2
                </li><li>
                        Robust linear regression;/statistics/robust_regression;3
                </li><li>
                        Multi-linear regression;/statistics/multivariate_regression;4
                </li><li>
                        Linear regression with binary input;/statistics/regression_binary_input;5
                </li><li>
                        Horseshoe priors;/statistics/horseshoe;6
                </li><li>
                        Introduction to the linear regression;/statistics/regression;7
                </li><li>
                        MRP;/statistics/mrp;8
                </li><li>
                        Model comparison, cont.;/statistics/model_averaging_cont;9
                </li><li>
                        Model comparison;/statistics/model_averaging;10
                </li><li>
                        Application of the Lotka-Volterra model;/statistics/lotka_volterra;11
                </li><li>
                        Differential equations;/statistics/ode;12
                </li><li>
                        Introduction to GIS;/gis/gis_intro;13
                </li><li>
                        Re-parametrizing your model;/statistics/reparametrization;14
                </li><li>
                        Predictive checks;/statistics/predictive_checks;15
                </li><li>
                        Trace inspection;/statistics/trace_inspection;16
                </li><li>
                        Introduction to the Bayesian workflow;/statistics/bayesian_workflow;17
                </li><li>
                        Mixture models;/statistics/mixture;18
                </li><li>
                        Multidimensional distributions;/statistics/categories;19
                </li><li>
                        Dirichlet Process Mixture Models;/statistics/dp;20
                </li><li>
                        The Gaussian model;/statistics/reals;21
                </li><li>
                        Bayesian Additive Regression Trees;/statistics/bart;22
                </li><li>
                        Bonus: counting animals in a park;/statistics/hypergeom;23
                </li><li>
                        Splines;/statistics/spline;24
                </li><li>
                        The Negative Binomial model;/statistics/negbin;25
                </li><li>
                        Gaussian processes regression;/statistics/gp_example;26
                </li><li>
                        Gaussian processes;/statistics/gp;27
                </li><li>
                        The Poisson model;/statistics/poisson;28
                </li><li>
                        Nonparametric models;/statistics/nonparametric_intro;29
                </li><li>
                        The Beta-Binomial model;/statistics/betabin;30
                </li><li>
                        Structural time series;/statistics/structural_time_series;31
                </li><li>
                        Time series;/statistics/time_series;32
                </li><li>
                        Some notation about probability;/statistics/probability_reminder;33
                </li><li>
                        Synthetic control;/statistics/synthetic_control;34
                </li><li>
                        How does MCMC works;/statistics/mcmc_intro;35
                </li><li>
                        Regression discontinuity design;/statistics/rdd;36
                </li><li>
                        Introduction to Bayesian inference;/statistics/bayes_intro;37
                </li><li>
                        An overview to statistics;/statistics/preface;38
                </li><li>
                        Difference in difference;/statistics/difference_in_differences;39
                </li><li>
                        Instrumental variable regression;/statistics/instrumental_variable;40
                </li><li>
                        Randomized controlled trials;/statistics/randomized;41
                </li><li>
                        Causal inference and Bayesian networks;/statistics/causal_intro_2;42
                </li><li>
                        Causal inference;/statistics/causal_intro;43
                </li><li>
                        Experiment analysis with many blocking variables;/statistics/experiment_design_cont;44
                </li><li>
                        Experiment analysis;/statistics/experiment_design;45
                </li><li>
                        Introduction to Extreme Values theory;/statistics/extreme_intro;46
                </li><li>
                        Application of survival analysis with discrete times;/statistics/survival_example_2;47
                </li><li>
                        Application of survival analysis 1;/statistics/survival_example;48
                </li><li>
                        Introduction to survival analysis;/statistics/survival_analysis;49
                </li><li>
                        Random models and mixed models;/statistics/random_models;50
                </li><li>
                        Hierarchical models and meta-analysis;/statistics/hierarchical_metaanalysis;51
                </li><li>
                        Hierarchical models;/statistics/hierarchical_models;52
                </li><li>
                        Drawing geographic maps;/dataviz/geography;53
                </li><li>
                        The Gestalt principles;/dataviz/gestalt;54
                </li><li>
                        Design tricks;/dataviz/design-introduction;55
                </li><li>
                        How to choose a color map;/dataviz/palettes-introduction;56
                </li><li>
                        Introduction to color perception;/dataviz/color-introduction;57
                </li><li>
                        Drawing is redrawing;/dataviz/gender-economist;58
                </li><li>
                        Visual queries;/dataviz/visual-queries;59
                </li><li>
                        Channel effectiveness;/dataviz/effectiveness;60
                </li><li>
                        Evolutions of the line chart;/dataviz/linechart-evolution;61
                </li><li>
                        Beyond the 1D scatterplot;/dataviz/scatterplot-evolution;62
                </li><li>
                        Perception;/dataviz/perception;63
                </li><li>
                        Fundamental charts;/dataviz/fundamental-charts;64
                </li><li>
                        Marks and channels;/dataviz/marks-channels;65
                </li><li>
                        Data abstraction;/dataviz/data-types;66
                </li><li>
                        Data visualization;/dataviz/dataviz;67
                </li><li>
                        Section introduction;/statistics/simple_models_intro;68
                </li></ul>
                        <div style="display:flex">
                  <a href="/statistics/reparametrization" class="prev">&#8249;</a>
                  
                                <a href="/"><img class="site-masthead" src="/docs/assets/images/logo_dp.png" alt="Data Perspectives" id="logo" /></a><div id='searchNav' style="flex;">
                                        <input type="search" id="search_0" class="searchBar" onkeydown="searchText()" placeholder="Search">
                                </div>

                                <div hidden='hidden' id="search_focus">0</div>



                        </div><nav class="site-nav" style="display:flex;">
                                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                                <label for="nav-trigger">
                                        <span class="menu-icon">
                                                <svg viewBox="0 0 18 15" width="18px" height="15px">
                                                        <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                                                </svg>
                                        </span>
                                </label>

                                <div class="trigger"><a  class="page-link" href="/about">About me</a><a  class="page-link" href="/links">Resources</a>
                                <a href="/statistics/" class="page-link">Up</a>
                                
                                </div>
                        </nav>
                  <a href="/statistics/lotka_volterra" class="next">&#8250;</a>
                  
        </div>


        <script src="/docs/assets/javascript/search.js">
        </script>
                </div>

</header>
<div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
    </div>
        </div>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
          <div id='topPage'></div>
        <a href='/index'>
<img src="/docs/assets/images/background_resized.webp" alt="backround" style="margin:auto;display:block;width:1200px">

</a>
    <h1 class="post-title p-name" itemprop="name headline">Differential equations</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-10-06T00:00:00+00:00" itemprop="datePublished">
        Oct 6, 2024
      </time></p>
    <p class="post-meta"> Reading time: <span class="reading-time" title="Estimated read time">
  
  14&prime;
</span>
</p>
  </header>
  <br>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Few days ago I started reading
Gause’s book <a href="https://www.google.it/books/edition/The_Struggle_for_Existence/zQegDwAAQBAJ?hl=it&amp;gbpv=1&amp;dq=The+Struggle+for+Existence:+A+Classic+of+Mathematical+Biology+and+Ecology&amp;printsec=frontcover">The Struggle for Existence: A Classic of Mathematical Biology and Ecology</a>.
It’s a beautiful textbook on mathematical ecology, and even if its almost 100 years old
and some concepts might be outdated, I think it contains many useful
examples which explain how science works, or at least should work.</p>

<p>The textbook contains many applications of the Lotka-Volterra model to 
systems with competing resources.
There are many beautiful figures, and all the data
has been exported in <a href="https://github.com/adamtclark/gauseR/">this amazing GitHub repo</a> <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>.</p>

<p>I therefore decided to look at the Lotka-Volterra model, and I started with the
simplest example: the one specie case.
This model describes the number of individuals of a species.
When there are many resources, the individuals reproduce themselves,
and the model assumes that</p>

\[\frac{dN(t)}{dt} \approx \lambda N\]

<p>The solution of the above differential equation is</p>

\[N(t) = N_0 e^{\lambda t}\]

<p>and this diverges as $t$ grows, but since the
number of units cannot however grow indefinitely, as there is a limited amount
of space and resources.
We therefore define the maximum number of units as $K$, and we can modify
the above differential equation into the following one</p>

\[\frac{dN(t)}{dt} = \lambda N (1-\frac{N}{K})\]

<p>If $N \ll K$ we recover back the exponential growth, but if $N$
approaches $K$ then we have $\frac{dN(t)}{dt} \rightarrow 0\,,$
as required.</p>

<p>The above differential equation is known as the logistic differential equation,
and you already encountered its solution when we discussed the GLM model,
but since it’s better to start with the simplest model as possible, I first tried to implement
this model before moving to the version of the equations with more than one specie.</p>

<p>When you implement a numerical algorithm there are many things which might go
wrong, as you might have missed a factor 2, or your choice for some
parameter might have introduced some instability.
It is therefore a very good habit to verify that everything works by 
comparing the algorithm solution with the analytic one for some solvable
problem.</p>

<p>By keeping this in mind,
we will compare the numerical solution with the analytic one, and as shown
<a href="https://mathworld.wolfram.com/LogisticEquation.html">here</a>
this reads</p>

\[N(t) = \frac{k N_0 e^{\lambda t}}{k + N_0 (e^{\lambda t}-1)}\,.\]

<p>We will use the simplest numerical integration method as possible, namely the Euler method.
Given a differential equation</p>

\[\begin{cases}
&amp;
y'(x) = G(y(x), x)
\\
&amp;
y(0) = y_0
\\
\end{cases}\]

<p>and using the first order Taylor expansion of $y(x)$ around $x_n$ (we are assuming
the existence of a smooth solution around $x_n$)</p>

\[y(x_{n+1}) = y(x_n) + y'(x_n)(x_{n+1}-x_n)  + O\left( \left( x_{n+1}-x_n \right)^2 \right)\]

<p>our numerical solution will read</p>

\[y_{n+1} = y_n + (x_{n+1}-x_n)G(y_n, x_n) + O\left( \left( x_{n+1}-x_n \right)^2 \right)\,.\]

<p>There are algorithms which are much more stable and efficients,
but in order to understand how to perform the numerical integration of an ODE
with PyMC it is sufficient to start from this method.</p>

<p>There is more than one method which you might use to perform the integration,
and most of them are explained in <a href="https://www.pymc.io/projects/examples/en/latest/ode_models/ODE_Lotka_Volterra_multiple_ways.html">this very nice tutorial</a>.
We will stick to the <strong>scan</strong> method, which relies on pytensor’s <a href="https://pytensor.readthedocs.io/en/latest/library/scan.html">scan function</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pyreadr</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pytensor</span> <span class="k">as</span> <span class="n">pt</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">df_0</span> <span class="o">=</span> <span class="n">pyreadr</span><span class="p">.</span><span class="n">read_r</span><span class="p">(</span><span class="s">'data/gause_1934_book_f21.rda'</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df_0</span><span class="p">[</span><span class="s">'gause_1934_book_f21'</span><span class="p">]</span>

<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">Paper</th>
      <th style="text-align: right">Figure</th>
      <th style="text-align: left">Species</th>
      <th style="text-align: right">Time</th>
      <th style="text-align: right">Volume</th>
      <th style="text-align: right">Individuals</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">21</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">3.13485</td>
      <td style="text-align: right">nan</td>
      <td style="text-align: right">21.0211</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">21</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">4.12251</td>
      <td style="text-align: right">nan</td>
      <td style="text-align: right">20.8853</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">21</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">5.0356</td>
      <td style="text-align: right">nan</td>
      <td style="text-align: right">30.6607</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">21</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">6.0962</td>
      <td style="text-align: right">nan</td>
      <td style="text-align: right">53.6171</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">Gause_book_1934</td>
      <td style="text-align: right">21</td>
      <td style="text-align: left">Paramecium caudatum</td>
      <td style="text-align: right">7.08101</td>
      <td style="text-align: right">nan</td>
      <td style="text-align: right">111.237</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[((</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s">'Individuals'</span><span class="p">].</span><span class="n">isna</span><span class="p">())</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]</span><span class="o">==</span><span class="s">'Paramecium aurelia'</span><span class="p">))].</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">'Time'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Individuals'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/paramecium.webp" alt="" /></p>

<p>Le logistic behavior in the dataset is quite evident.
It looks like the time step is always close to 1, let us see if we can approximate the integration step as constant</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">].</span><span class="n">diff</span><span class="p">().</span><span class="n">dropna</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nb">max</span><span class="p">()</span>
</code></pre></div></div>

<div class="code">
0.10359150000000028
</div>

<p>It looks like assuming equally space data is not too bad.
The integration step should be small enough to ensure that the error is not too large,
we will therefore assume $h = 1/5\,.$
As we will see, this is a small enough choice, but I invite you to try with a smaller step
and verify if everything is OK.
We also scaled the data so that the fitted value is not too large for the numerical integration.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">5</span>

<span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'lam'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'kappa'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'nu'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">f_update</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>  <span class="c1"># this function implements the Euler method
</span>        <span class="k">return</span> <span class="n">n</span><span class="o">+</span><span class="n">n</span><span class="o">*</span><span class="n">h</span><span class="o">*</span><span class="n">lam</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">n</span><span class="o">/</span><span class="n">kappa</span><span class="p">)</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">update</span> <span class="o">=</span> <span class="n">pt</span><span class="p">.</span><span class="n">scan</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">f_update</span><span class="p">,</span>  <span class="c1"># The updating function
</span>                     <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">nu</span><span class="p">],</span>  <span class="c1"># The initial condition
</span>                    <span class="n">non_sequences</span><span class="o">=</span><span class="p">[</span><span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_steps</span><span class="p">],</span>  <span class="c1"># The list of arguments
</span>                    <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">yobs</span><span class="p">))</span>  <span class="c1"># The number of steps
</span>    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">[::</span><span class="n">n_steps</span><span class="p">],</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yobs</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div></div>

<p>Since it is hard to guess a reasonable value for the parameters, it is better to take
a look at the prior predictive distribution</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">pr_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample_prior_predictive</span><span class="p">()</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">az</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="n">pr_pred</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s">'prior_predictive'</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'y'</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">).</span><span class="n">T</span><span class="p">:</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">elem</span><span class="p">.</span><span class="n">values</span><span class="p">))</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/prior_predictive.webp" alt="" /></p>

<p>The parameters look fine, there is a fast enough growth, the limit number is large enough
and the initial value covers a wide enough region.
We can now fit the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/trace_0.webp" alt="" /></p>

<p>The traces look perfect, we can now inspect the posterior predictive.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">idata</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata</span><span class="p">))</span>
    
<span class="k">def</span> <span class="nf">fexact</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">k</span><span class="o">*</span><span class="n">y0</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lam</span><span class="o">*</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span><span class="n">y0</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lam</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">y</span>

<span class="n">dt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">fexact</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'nu'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'lam'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">idata</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'kappa'</span><span class="p">].</span><span class="n">mean</span><span class="p">().</span><span class="n">values</span><span class="p">)</span> 
               <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_data</span><span class="p">))])</span>

<span class="n">ypl</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="mi">100</span><span class="o">*</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">idata</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">].</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
       <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="n">ypl</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Individuals'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/pp_0.webp" alt="" /></p>

<p>The numerical solution is identical to the analytic one, so our ODE solver does
a very good job.
The average looks fine, but the model provides a credible interval below 0,
and this makes no sense since the number of individuals is a positive quantity.
We can easily fix the above model by fitting the logarithm of the
number of individuals</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">pm</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_improved</span><span class="p">:</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'lam'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'kappa'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'nu'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s">'sigma'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">f_update</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">n</span><span class="o">+</span><span class="n">n</span><span class="o">*</span><span class="n">h</span><span class="o">*</span><span class="n">lam</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">n</span><span class="o">/</span><span class="n">kappa</span><span class="p">)</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">update</span> <span class="o">=</span> <span class="n">pt</span><span class="p">.</span><span class="n">scan</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">f_update</span><span class="p">,</span> 
                     <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">nu</span><span class="p">],</span>
                    <span class="n">non_sequences</span><span class="o">=</span><span class="p">[</span><span class="n">lam</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_steps</span><span class="p">],</span>
                    <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">yobs</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="s">'y'</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">pm</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">mu</span><span class="p">[::</span><span class="n">n_steps</span><span class="p">]),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">yobs</span><span class="o">/</span><span class="mi">100</span><span class="p">))</span>

<span class="k">with</span> <span class="n">model_improved</span><span class="p">:</span>
    <span class="n">idata_improved</span> <span class="o">=</span> <span class="n">pm</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">nuts_sampler</span><span class="o">=</span><span class="s">'numpyro'</span><span class="p">,</span>
                               <span class="n">draws</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata_improved</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/trace_1.webp" alt="" /></p>

<p>Also in this case the trace is fine. What about the posterior predictive?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">model_improved</span><span class="p">:</span>
    <span class="n">idata_improved</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pm</span><span class="p">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idata_improved</span><span class="p">))</span>

<span class="n">dt_new</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">fexact</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'nu'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'lam'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior</span><span class="p">[</span><span class="s">'kappa'</span><span class="p">].</span><span class="n">mean</span><span class="p">().</span><span class="n">values</span><span class="p">)</span> 
                   <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_data</span><span class="p">))])</span>

<span class="n">ypl_new</span> <span class="o">=</span> <span class="n">dt_new</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">]).</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'lightgray'</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">idata_improved</span><span class="p">.</span><span class="n">posterior_predictive</span><span class="p">[</span><span class="s">'y'</span><span class="p">]).</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="s">'draw'</span><span class="p">,</span> <span class="s">'chain'</span><span class="p">)),</span>
       <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">':'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">],</span> <span class="n">ypl_new</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">df_data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Time'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Individuals'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/ode/pp_1.webp" alt="" /></p>

<p>These error bars make much more sense than the previous ones, and we consider
this model better than the previous one.
Notice that we might decide to perform a model comparison between the two models,
but I personally don’t consider this as a necessary step, since
we didn’t modify the model because the fit was bad, but rather because
it did not fulfill the positivity constraint.</p>

<h2 id="conclusions">Conclusions</h2>

<p>With the help of pytensor’s scan function, implementing Euler algorithm has been
straightforward, and the extension to any other solver is immediate.
We applied this method to numerically integrate the logistic equation,
and we applied it to an example from Gause’s textbook.
We have also seen a little trick to impose the positivity of the solution
and make the credible intervals more reasonable.</p>

<h2 id="suggested-readings">Suggested readings</h2>

<ul>
  <li>Gause, G. F. (2019). The Struggle for Existence: A Classic of Mathematical Biology and Ecology. Dover Publications.</li>
  <li><a href="http://numerical.recipes/oldverswitcher.html">Press, W. H. (2007). Numerical Recipes 3rd Edition: The Art of Scientific Computing. Cambridge University Press.</a></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">n</span> <span class="o">-</span><span class="n">u</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">iv</span> <span class="o">-</span><span class="n">w</span> <span class="o">-</span><span class="n">p</span> <span class="n">xarray</span><span class="p">,</span><span class="n">numpyro</span><span class="p">,</span><span class="n">jax</span><span class="p">,</span><span class="n">jaxlib</span>
</code></pre></div></div>

<div class="code">
Last updated: Wed Aug 28 2024
<br />

<br />
Python implementation: CPython
<br />
Python version       : 3.12.4
<br />
IPython version      : 8.24.0
<br />

<br />
xarray : 2024.5.0
<br />
numpyro: 0.15.0
<br />
jax    : 0.4.28
<br />
jaxlib : 0.4.28
<br />

<br />
pymc      : 5.16.2
<br />
seaborn   : 0.13.2
<br />
matplotlib: 3.9.0
<br />
pyreadr   : 0.5.2
<br />
arviz     : 0.18.0
<br />
numpy     : 1.26.4
<br />
pytensor  : 2.25.3
<br />
pandas    : 2.2.2
<br />

<br />
Watermark: 2.4.3
<br />
</div>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>The Python community is amazing, but the R community is great too, especially when we talk about sharing data. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div><a class="u-url" href="/statistics/ode" hidden></a>

  <br>
  <div id='autograph'>
          Stippe Oct 6, 2024

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>


  <div class="wrapper">
          <div class='footer-text'>
                  Opinions are mine, mistakes too, and if you find any feel free to report it via mail or via Twitter.
                  <br>
                  Most of the material in the statistics section is an adaptation to Python of some pre-existing model.
                  <br>
                  I have tried to provide the necessary credits, but if you think that a relevant contribution is missing, please let me know.
                  <br>
                  No AI were harmed in creating this blog.
                  <br>
                  This is a blog, not a bakery: there are no cookies here!
                  <br>
                  The top image has been generated with a modified version Dan Gries' code, available at <a href="http://rectangleworld.com/blog/archives/538">http://rectangleworld.com</a>.
          </div>
          <br>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Data-perspectives</li>
          <li><a class="u-email" href="mailto:dataperspectivesblog@gmail.com">dataperspectivesblog@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/SteffPy" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://stackoverflow.com/users/11065831/stefano" target="_blank" title="stackoverflow">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://github.com/thestippe/" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://vis.social/@thestippe" target="_blank" title="mastodon">
    <svg class="svg-icon grey">
      <use xlink:href="/assets/minima-social-icons.svg#mastodon"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

  <script src="/docs/assets/javascript/scroll.js">
  </script>

</html>

