<p>The randomized block design can be easily generalized to two or more
blocking factors. However, if the experimental runs are slow,
it might not be convenient to run all possible combinations for all the blocks,
since we are not interested in finding the dependence of the outcome
variable on the blocking factors.
If the number of treatment levels is equal to the number of levels
of both blocking factors, 
a popular design with two blocking factors is the latin square design.
In this design, each treatment level is tested against each
level of each blocking factor once.</p>

<h2 id="the-latin-square-design">The latin square design</h2>

<p>An $n\times n$ latin square is an $n \times n$ matrix where to each matrix
element is assigned a letter (or a number, or any unique symbol) $a_1,â€¦a_n$
and each letter only appears once for each row and each column.
As ane example, a $3 \times 3$ latin square could be</p>

\[\begin{pmatrix}
A &amp; B &amp; C \\
C &amp; A &amp; B \\
B &amp; C &amp; A \\
\end{pmatrix}\]

<p>The randomization can be achieved by first applying a random permutation
to the rows and then applying a random permutation to the columns.
The entire construction can be performed as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">latin_square</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">row</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">j</span><span class="p">:]</span><span class="o">+</span><span class="n">r</span><span class="p">[:</span><span class="n">j</span><span class="p">]</span>
        <span class="n">out</span> <span class="o">+=</span> <span class="p">[</span><span class="n">row</span><span class="p">]</span>
    <span class="n">mat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">m1</span> <span class="o">=</span> <span class="n">mat</span><span class="p">[</span><span class="n">p1</span><span class="p">]</span>
    <span class="n">m2</span> <span class="o">=</span> <span class="p">(</span><span class="n">m1</span><span class="p">.</span><span class="n">T</span><span class="p">)[</span><span class="n">p2</span><span class="p">].</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">m2</span>
</code></pre></div></div>

<p>If we only perform one repetition for each setting, we have 9
runs, and this is enough to fit a linear non-interacting model.
The interaction terms, however, cannot be estimated by using this
model.
Of course, allowing for multiple repetitions would not change the above
situation, and it only allows us to have a more precise estimate
of our parameters.
The model for the latin square can be written as</p>

\[y_{ijk} \sim \mathcal{N}(\mu_{ijk}, \sigma)\]

<p>where</p>

\[\mu_{ijk} = \alpha_i + \beta_j + \delta_k\]

<p>and \(i,j,k\in \left\{1,2,3\right\}\)
correspond to the row effect, the column effect and the treatment
effect respectively.</p>

<h2 id="our-experiment">Our experiment</h2>

<p>In the following experiment we will use a latin square
experiment to compare the training time of three algorithms by blocking
on the train-test seed and on the training order.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">ucimlrepo</span> <span class="kn">import</span> <span class="n">fetch_ucirepo</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">BernoulliNB</span><span class="p">,</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestCentroid</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">942</span><span class="p">)</span>

<span class="n">Xs</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">features</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">Xs</span>
<span class="n">dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">Xs</span><span class="p">[[</span><span class="s">'proto'</span><span class="p">,</span> <span class="s">'service'</span><span class="p">]],</span> <span class="n">drop_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'proto'</span><span class="p">,</span> <span class="s">'service'</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ys</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">targets</span>

<span class="n">yv</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">ys</span><span class="p">[</span><span class="s">'Attack_type'</span><span class="p">]).</span><span class="n">codes</span>

<span class="n">algo_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">GaussianNB</span><span class="p">,</span> <span class="n">NearestCentroid</span><span class="p">,</span> <span class="n">BernoulliNB</span><span class="p">]</span>
<span class="n">seeds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">100000</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># We sampled the following matrix
</span>
<span class="n">mat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="k">print</span><span class="p">(</span><span class="s">"i,j,k,rep,seed,algorithm,start,time"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mat</span><span class="p">):</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="n">seeds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">algos</span> <span class="o">=</span> <span class="p">[</span><span class="n">algo_list</span><span class="p">[</span><span class="n">elem</span><span class="p">]</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">row</span><span class="p">]</span>
        <span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">yv</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span>
                                                        <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">algo</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">algos</span><span class="p">):</span>
            <span class="n">regr</span> <span class="o">=</span> <span class="n">algo</span><span class="p">()</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">perf_counter</span><span class="p">()</span>
            <span class="n">regr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">perf_counter</span><span class="p">()</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">,</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s">,</span><span class="si">{</span><span class="n">mat</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s">,</span><span class="si">{</span><span class="n">rep</span><span class="si">}</span><span class="s">,</span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s">,</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">algo</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'.'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">"'"</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">,</span><span class="si">{</span><span class="n">start</span><span class="si">}</span><span class="s">,</span><span class="si">{</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p>Let us now analyze the data</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="n">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="n">az</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/home/stippe/Documents/Programs/experiments/speed_test/time_latin_square_class_new1.csv'</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right">Â </th>
      <th style="text-align: right">i</th>
      <th style="text-align: right">j</th>
      <th style="text-align: right">k</th>
      <th style="text-align: right">rep</th>
      <th style="text-align: right">seed</th>
      <th style="text-align: left">algorithm</th>
      <th style="text-align: right">start</th>
      <th style="text-align: right">time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">2</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">2498</td>
      <td style="text-align: left">BernoulliNB</td>
      <td style="text-align: right">179174</td>
      <td style="text-align: right">0.0826179</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">2498</td>
      <td style="text-align: left">NearestCentroid</td>
      <td style="text-align: right">179174</td>
      <td style="text-align: right">0.101275</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">2</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">2498</td>
      <td style="text-align: left">GaussianNB</td>
      <td style="text-align: right">179174</td>
      <td style="text-align: right">0.104436</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">23729</td>
      <td style="text-align: left">NearestCentroid</td>
      <td style="text-align: right">179174</td>
      <td style="text-align: right">0.110273</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">23729</td>
      <td style="text-align: left">GaussianNB</td>
      <td style="text-align: right">179174</td>
      <td style="text-align: right">0.0980437</td>
    </tr>
  </tbody>
</table>

<p>Since we already performed a similar analysis, we know
that using the time as variable might cause some issue, and using
its logarithm is better.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">'log_time'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'time'</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">sns</span><span class="p">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'log_time'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'algorithm'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/latin_square/violin.webp" alt="" /></p>

<p>We can now implement the model.
In principle, we could (and, in my opinion, should)
use a hierarchical model to perform the analysis.
However, the small number of groups and subgroups would make this task
hard, and we will simply use a linear model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">pmb</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="s">'log_time ~ algorithm + i + j'</span><span class="p">,</span>
                  <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">categorical</span><span class="o">=</span><span class="p">[</span><span class="s">'i'</span><span class="p">,</span> <span class="s">'j'</span><span class="p">,</span> <span class="s">'algorithm'</span><span class="p">])</span>

<span class="n">idata</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">az</span><span class="p">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">idata</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/latin_square/trace.webp" alt="" /></p>

<p>The trace looks decent, let us now take a look at our parameter
of interest</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="p">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s">'algorithm'</span><span class="p">])</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/docs/assets/images/statistics/latin_square/forest_algorithm.webp" alt="" /></p>

<p>The Bernoulli Naive Bayes classifier is clearly faster
with respect to the remaining algorithms.</p>
<h2 id="conclusions">Conclusions</h2>

<p>We have seen how to run and analyze a latin square design.
In the following posts, we will take a look at some more in-depth
question related to experiment design.</p>

<h2 id="suggested-readings">Suggested readings</h2>
<ul>
  <li><cite>Lawson,Â J.Â (2014).Â Design and Analysis of Experiments with R.Â US:Â CRC Press.</cite></li>
  <li><cite>Hinkelmann,Â K.,Â Kempthorne,Â O.Â (2008).Â Design and Analysis of Experiments Set.Â UK:Â Wiley.</cite></li>
</ul>
