---
layout: post
title: "Introduction to decision theory"
categories: /statistics/
subgategory: Introduction
tags: /decision_theory/
date: "2024-01-10"
section: 5
# image: "/docs/assets/images/perception/eye.jpg"
description: "Making choices under uncertainty"
published: false
---

In a previous post we said that, given a set of observations $X_1,\dots,X_n\,,$
and assuming that the observations have been generated by a distribution
belonging to a family of distributions
$$
\mathcal{P} = \left\{P_\theta : \theta \in \Theta\right\}\,,
$$
we would like to use our dataset to restrict the possible values of $\theta$
or, more generally, of some function of $\theta$ $g(\theta)\,.$

Notice that this is not always possible, as it may happen that, for
$\theta_1 \neq \theta_2\,,$ we have $P_{\theta_1} = P_{\theta_2}\,.$
In this case the family is said to be **unidentifiable**.
If a family is not unidentifiable we say it is **identifiable**.


## Statistics, estimators and estimations

The first assumption that we will make is that our set of observations
is made up by $n$ independent identically distributed random variables.
In this case we say that our observation are a **random sample**
of a random variable $X\,.$

We define a **statistic** any real function of the sample $$T = T(X_1,\dots,X_n)\,.$$
If $$x_1,\dots,x_n$$ are a realization of our random variables,
we define $$T(x_1,\dots,x_n)$$ a **realization of T**.
In other words, a realization of a statistic is the value taken by the statistic
for a particular observed set of data.

We want to use our data to find a value of
our **estimand** $$g(\theta)\,,$$
so we want to use a statistics (a function of the sample)
and in this case $T$ is said to be an **estimator**  for $g(\theta)\,.$
The realized value of our estimator $T(x_1,\dots,x_n)$
is said to be an **estimate** of $g(\theta)\,.$


## Decision theory

A quite general approach to solve the above problem
is given by the **statistical decision theory**,
which is the branch of statistics which
analyzes how to make optimal choices under
uncertainty.

What one does is to define a **risk function**

$$
R(g(\theta), T(X))=\mathbb{E}_\theta[L(g(\theta), T(X))]
$$

where the risk function is the expected value,
with respect to $P_\theta\,,$
of some **loss function** $L\,.$

Depending on the problem, our loss function may
have different shapes.

We may look for a $T(X)$ that is as close as possible
to $g(\theta)\,,$
and in this case a reasonable choice for $L(x, y)$
would be any increasing function
of $\left|x-y\right|\,.$
Common choices are $\left|x-y\right|\,,$
which corresponds to the Mean Absolute Error (MAE),
or $(x-y)^2\,,$
which corresponds to the Mean Square Error (MSE).
In this case our aim is to determine
a **point estimate** for $g(\theta)\,.$

Let us consider, as an example, the case where
$$
P_\theta
$$
is a series of $n$ fixed Bernoulli trials,
and we want to find an estimate for $\theta$
choosing $(x-y)^2$ as our loss function.
Maybe we could prefer to overestimate $\theta$
rather than underestimate it,
so

$$
L(x, y) =
\begin{cases}
(x-y) & x>y \\
2(y-x) & y<x\\
\end{cases}
$$

Another possibility is that we may want to determine
whether $g(\theta)$ belongs to a particular
region $\Lambda(X)$ or not, in this
case a candidate for the loss function would be

$$
L(g(\theta), T(x)) = a_0 I(g(\theta) \in \Lambda(X))
+ a_1 (1-I(g(\theta) \in \Lambda(X))
$$

where $I$ is the indicator function

$$
I(x) =
\begin{cases}
& 1\,  if\,  x=T\\
& 0\,  if\,  x=F\\
\end{cases}
$$

In this case we are facing a **hypothesis testing**
problem.
As an example, we may want to determine
if a certain hypothesis is true,
so we may assign a positive loss
to the regions where our conclusions are
wrong (the hypothesis is true and we conclude
that it is false or vice versa).
We may even want to setup our problem in such
a way that we assign different loss
to the type of misclassification, so $\Lambda(X)$
should be divided into two subsets $\Lambda_1(X)$
and $\Lambda_2(X)\,,$
and the loss function could be different 
depending on whether $g(\theta)$
belongs to one or the other subspace.

From the above setup it should appear quite clear
that we constructed a subset of
$$g(\Theta)$$ and that we want to assess whether
it is reasonable to conclude if
$$g(\theta)$$ belongs to it.
In this case the subset is said to be a
**confidence interval** for our estimand.

To clarify the testing problem,
assume that you have a Gaussian random sample $X$
with known variance $\sigma\,,$
and you want to verify if it is reasonable to
assume that it has been generated by
a distribution with $$\left|\mu\right|< c\,.$$

## Frequentist vs Bayesian framework

Once we defined a risk function,
we should clarify how we want to optimize
our risk function,
as it is both a function of $\theta$
and of $T(X)\,,$ and they are both unknown.

The frequentist approach is to look
for a $T$ that minimizes $\max_\theta R(g(\theta), T(X))\,,$ and this leads to the **minimax problem**.

On the other hand, in the Bayesian approach,
$\theta$ is not a number but a random variable
with probability $p(\theta )\,,$
so one can minimize the expected loss

$$
\int d\theta p(\theta ) R(g(\theta), T(X))
$$

## Conclusions

We formulated the general inferential
problem in terms of a loss function,
and we specified how a solution should
look like both in the Bayesian and in the frequentist
perspective.

In the next posts we will analyze different
kinds of problems by starting from
the frequentist point of view.

<!--
ADD Central Limit Theorem 
-->
