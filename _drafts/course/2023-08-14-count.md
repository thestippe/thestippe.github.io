---
layout: post
title: "Dealing with count data"
categories: course/intro/
tags: /count/
image: "/docs/assets/images/count_data/abacus-1866497_960_720.jpg"
description: "The Poisson and Beta-Binomia models"
---


In [the previous post](/beta-binom/) we have seen how we can model a two-valued variable
by using the binomial distribution. In this one we will illustrate how we can 
model count variables, that is variables which can take any non-negative
integer value $0, 1, 2,\dots$

## The Poisson model

A classical example is given by the number of hurricanes in the North Atlantic ocean by year.
The corresponding dataset can be downloaded from
 [https://ourworldindata.org/grapher/frequency-north-atlantic-hurricanes](https://ourworldindata.org/grapher/frequency-north-atlantic-hurricanes),
 and we saved the downloaded dataset in the data subfolder.

```python
import numpy as np
from scipy.stats import poisson
from matplotlib import pyplot as plt
import pandas as pd
import seaborn as sns

plt.style.use("seaborn-v0_8-darkgrid")

df_hurricanes = pd.read_csv('data/frequency-north-atlantic-hurricanes.csv')

sns.histplot(data=df_hurricanes, x="Number of US Hurricanes (HUDRAT, NOAA)",
                bins=np.arange(0, 10))
```

![Hurricanes count](/docs/assets/images/count_data/hurricanes_count.jpg)


We can assume that the number of hurricanes for each year is independent
on the number of hurricanes of the other years and that the average
number of hurricanes per year is constant.
This suggests us to use the Poisson distribution.

$$ y \sim Poisson(\mu) $$

where $\mu$ is the average, and the Poisson distribution has probability mass function
given by

$$p(y | \mu) = \frac{e^{-\mu} \mu^y}{ y! }$$

![Poisson example](/docs/assets/images/count_data/poisson_example.jpg)
*The Poisson distribution*

and $\mu$ must be a positive real quantity.

As usual, we must now provide a prior for the parameter $\mu\,,$
and our prior must be able to easily accommodate the data.
A flexible enough family of distributions is given by the Gamma distribution:

$$
\mu \sim Gamma(\alpha, \beta)
$$

where the Gamma distribution has pdf

$$
p(y | \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} y^{\alpha - 1}  e^{-\beta y} 
$$

A special case of the Gamma distribution is the Exponential distribution,
which corresponds to $Gamma(1, \lambda)\,,$ and $\lambda$ is the inverse of the mean.


![Gamma example](/docs/assets/images/count_data/gamma_example.jpg)
*The gamma distribution*

We don't want to use our prior to force the result toward a particular
region, we'd rather prefer to use our prior to **regularize** our estimate.
So we will use a weakly informative prior:

$$\mu \sim Gamma(1, 1/10)$$

```python
y_obs = df_hurricanes["Number of US Hurricanes (HUDRAT, NOAA)"].dropna().values

with pm.Model() as model_hurricanes:

    mu = pm.Gamma('mu', alpha=1, beta=1/10)

    p = pm.Poisson("y", mu, observed=y_obs)
    trace_hurricanes = pm.sample(draws=2000, tune=500, chains=4) 

```

We used PyMC to simulate 4 chains for $\mu\,,$ each chain contains
2000+500 draws, and the first 500 draws are discarded.
This is because the initial part of the simulation
may depend on the initial value and it is used by PyMC to infer the
best parameters for the simulation (we will discuss this more in detail in
a future post).
```python
az.plot_trace(trace_hurricanes)
```
![Hurricanes traces](/docs/assets/images/count_data/trace_hurricanes.jpg)

The four traces have a stationary appearance, and it looks like
the distribution is the same across the traces.
These are good signals that we had no issues during the simulations.
We can now take a look at the most important statistics regarding the trace on $\mu$:

```python
az.summary(trace_hurricanes)
```

||mean| sd| hdi_3%| hdi_97%| mcse_mean| mcse_sd| ess_bulk| ess_tail| r_hat|
|---|---|---|---|---|---|---|---|---|---|
|mu|1.748|	0.102|	1.566|	1.951|	0.002|	0.001|	3171|	5132|	1|

The results show that:
- The samples have a mean of 1.748 and a standard deviation of 0.102
- The $95\%$ Credible Interval has lower boundary 1.566 and upper boundary 1.951
- The uncertainty in the estimate of the mean due to the Monte Carlo procedure (Monte Carlo Standard Error) has been estimated to 0.002 with an uncertainty of 0.001
- The Effective Sample Size is of the same order of magnitude of the sample size (3000-5000 against 4000)
- $\hat{R} = 1$ indicates that the four traces show similar properties, and this is another indicator that there are no issues in the simulation.

Now that we are quite confident about the sampling procedure, we can compare
the prediction of our model for the distribution of the number of hurricanes
per year with the true distribution:

```python
with model_hurricanes:
        ppc_hurricanes = pm.sample_posterior_predictive(trace_hurricanes)
az.plot_ppc(ppc_hurricanes)
```
![Hurricanes ppc](/docs/assets/images/count_data/poisson_ppc.jpg)

The true values are lying well inside our error bands, and the mean estimate
is close to the observed one. We can thus consider our model satisfactory for our purposes.
We can thus use our model to make predictions.
As an example, we could ask what is the probability that, in one year, one gets
at least four hurricanes:
```python
(ppc_hurricanes.posterior_predictive['y'].values.reshape(-1)>=4).astype(int).mean()
```
> 0.10078

We can compare it with the raw historical estimate:
```python
(df_hurricanes["Number of US Hurricanes (HUDRAT, NOAA)"].dropna().values>=4).mean()
```
> 0.08982

## The negative-binomial model

The Poisson model is a one-parameter model, and this implies that the
variance is uniquely determined by the mean (in fact they are equal).
This could be a too restrictive requirement, as one would like to treat them
independently. In these cases a very common choice is the negative
binomial distribution, which represents the number of subsequent failures $k$ in a
Bernoulli process with success probability $p$ before a given number of subsequent successes $r$ occur [^1]:

$$p(k \vert p, r) \propto (1-p)^k p^r$$

As an example, I used this model to investigate the number of retweets of a particular
twitter account:

```python
df_twitter = pd.read_csv('data/data_twitter.csv')
fig = plt.figure()
ax = fig.add_subplot()
sns.histplot(data=df_tweets, x="retweets_count", ax=ax, bins = np.arange(0, 30))
ax.set_xlim([0, 30])
```

![Hurricanes ppc](/docs/assets/images/count_data/twitter_data.jpg)

Let us first of all try and see if the Poisson model is a suitable candidate to describe our data:

```python
with pm.Model() as poisson_twitter:
    mu = pm.Exponential('mu', lam=1)
    y = pm.Poisson('y', mu=mu, observed=df_count['retweets_count'])
    trace_poisson_twitter = pm.sample(draws=2000, tune=2000, chains=4)
    az.plot_trace(trace_poisson_twitter)
```

![NegativeBinomial check trace](/docs/assets/images/count_data/negbin_check_trace.jpg)

The trace looks good, so let us now sample the posterior predictive and see if it describes the data:

```python
with poisson_twitter:
    ppc_poisson_twitter = pm.sample_posterior_predictive(trace_poisson_twitter)

fig = plt.figure()
ax = fig.add_subplot()
az.plot_ppc(ppc_poisson_twitter, ax=ax, observed=False, alpha=0.5)
ax.hist(df_count['retweets_count'], color='k', alpha=0.5, density=True, bins=np.arange(0, 20), label='Observed')
ax.set_xlim([0, 20])
```

![NegativeBinomial check ppc](/docs/assets/images/count_data/negbin_check_ppc.jpg)

Our model clearly fails to reproduce the data, we should therefore try with a more appropriate one,
and we will use the negative binomial model.

```python
with pm.Model() as negbin:
    p = pm.Uniform('p', lower=0, upper=1)
    n = pm.Exponential('n', lam=0.1)
    y = pm.NegativeBinomial('y', p=p, n=n, observed=df_twitter['retweets_count'])
    trace_negbin = pm.sample(draws=2000, tune=2000, chains=4)
    az.plot_trace(trace_negbin)
```

![Hurricanes ppc](/docs/assets/images/count_data/negbin_trace.jpg)

In the trace everything looks fine, so we can go further and sample $y$.


```python
with negbin:
   ppc_negbin = pm.sample_posterior_predictive(trace_negbin)

fig = plt.figure()
ax = fig.add_subplot()
az.plot_ppc(ppc_negbin, ax=ax, observed=False)
ax.hist(df_count['retweets_count'], color='k', alpha=0.5, density=True,
         bins=np.arange(0, 20))
ax.set_xlim([0, 20])
```

![Alt text](/docs/assets/images/count_data/negbin_ppc.jpg)

Let us verify if our requirement to treat the mean and the variance
as independent quantities was needed

```python
ppc_negbin.posterior_predictive['y'].values.reshape(-1).mean()
```
> 2.2661

```python
ppc_negbin.posterior_predictive['y'].values.reshape(-1).var()
```
> 10.3115

They differ by a factor of $4\,,$ so we were right.
In fact, if we compare these quantities with the corresponding quantities obtained from the Poisson model:

```python
ppc_poisson_twitter.posterior_predictive['y'].values.reshape(-1).mean()
```
> 2.26458

```python
ppc_poisson_twitter.posterior_predictive['y'].values.reshape(-1).var()
```
> 2.26564

As expected, the Poisson model predicts equal mean and variance for $y\,,$
while our data clearly shows overdispersion, as the variance is much larger than the mean,
making the negative binomial model a better candidate to describe our data.


## Conclusions and take-home message
- You can easily fit count data.
- Bayesian statistics can be very flexible: if a model is not able to reproduce e salient feature of your data, you can easily switch to a one with allows for more structure.
- You can easily make inference about any kind of quantity, as we did by comparing the variance of the models with the variance of the data.
- A visual inspection of the posterior predictive distribution is often the first step in the assessment of the model's goodness.

We will now see how we can extend our last model and allow for more than two categories, with the
[Dirichlet-Multinomial model](/categorical/).

[^1]: The negative binomial can be also seen as the posterior predictive distribution of a Poisson likelihood with a Gamma prior, the mathematical derivation can be found [here](https://gregorygundersen.com/blog/2019/09/16/poisson-gamma-nb/)
